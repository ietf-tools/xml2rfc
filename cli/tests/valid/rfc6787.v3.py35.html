<!DOCTYPE html>
<html lang="en" class="RFC">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>Media Resource Control Protocol Version 2
    (MRCPv2)</title>
<meta content="Daniel C. Burnett" name="author">
<meta content="Saravanan Shanmugham" name="author">
<meta content='The Media Resource Control Protocol Version 2 (MRCPv2) allows client hosts to control media service
      resources such as speech synthesizers, recognizers, verifiers, and
      identifiers residing in servers on the network. MRCPv2 is not a
      "stand-alone" protocol -- it relies on other protocols, such as the Session
      Initiation Protocol (SIP), to coordinate MRCPv2 clients and servers and
      manage sessions between them, and the Session Description Protocol (SDP)
      to describe, discover, and exchange capabilities. It also depends on SIP
      and SDP to establish the media sessions and associated parameters
      between the media source or sink and the media server. Once this is
      done, the MRCPv2 exchange operates over the control session
      established above, allowing the client to control the media processing
      resources on the speech resource server.' name="description">
<meta content="xml2rfc 2.11.1" name="generator">
<meta content="mrcp, speechsc, asr, tts, speech services, speech recognition, 
speech synthesis, nlsml, speaker authentication, speaker verification, 
speaker identification" name="keyword">
<link rel="alternate" type="application/rfc+xml" href="tests/input/rfc6787.xml">
<link rel="license" href="#copyright">
<style type="text/css">/* fonts */
@import url('https://fonts.googleapis.com/css?family=Noto+Sans'); /* Sans-serif */
@import url('https://fonts.googleapis.com/css?family=Noto+Serif'); /* Serif (print) */
@import url('https://fonts.googleapis.com/css?family=Roboto+Mono'); /* Monospace */

@viewport {
  zoom: 1.0;
  width: extend-to-zoom;
}
@-ms-viewport {
  width: extend-to-zoom;
  zoom: 1.0;
}
/* general and mobile first */
html {
}
body {
  max-width: 90%;
  margin: 1.5em auto;
  color: #222;
  background-color: #fff;
  font-size: 14px;
  font-family: 'Noto Sans', Arial, Helvetica, sans-serif;
  line-height: 1.6;
  scroll-behavior: smooth;
}
.ears {
  display: none;
}

/* headings */
#title, h1, h2, h3, h4, h5, h6 {
  margin: 1em 0 0.5em;
  font-weight: bold;
  line-height: 1.3;
}
#title {
  clear: both;
  border-bottom: 1px solid #ddd;
  margin: 0 0 0.5em 0;
  padding: 1em 0 0.5em;
}
.author {
  padding-bottom: 4px;
}
h1 {
  font-size: 26px;
  margin: 1em 0;
}
h2 {
  font-size: 22px;
  margin-top: -20px;  /* provide offset for in-page anchors */
  padding-top: 33px;
}
h3 {
  font-size: 18px;
  margin-top: -36px;  /* provide offset for in-page anchors */
  padding-top: 42px;
}
h4 {
  font-size: 16px;
  margin-top: -36px;  /* provide offset for in-page anchors */
  padding-top: 42px;
}
h5, h6 {
  font-size: 14px;
}
#n-copyright-notice {
  border-bottom: 1px solid #ddd;
  padding-bottom: 1em;
  margin-bottom: 1em;
}
/* general structure */
p {
  padding: 0;
  margin: 0 0 1em 0;
  text-align: left;
}
div, span {
  position: relative;
}
div {
  margin: 0;
}
.alignRight.art-text {
  background-color: #f9f9f9;
  border: 1px solid #eee;
  border-radius: 3px;
  padding: 1em 1em 0;
  margin-bottom: 1.5em;
}
.alignRight.art-text pre {
  padding: 0;
}
.alignRight {
  margin: 1em 0;
}
.alignRight > *:first-child {
  border: none;
  margin: 0;
  float: right;
  clear: both;
}
.alignRight > *:nth-child(2) {
  clear: both;
  display: block;
  border: none;
}
svg {
  display: block;
}
.alignCenter.art-text {
  background-color: #f9f9f9;
  border: 1px solid #eee;
  border-radius: 3px;
  padding: 1em 1em 0;
  margin-bottom: 1.5em;
}
.alignCenter.art-text pre {
  padding: 0;
}
.alignCenter {
  margin: 1em 0;
}
.alignCenter > *:first-child {
  border: none;
  /* this isn't optimal, but it's an existence proof.  PrinceXML doesn't
     support flexbox yet.
  */
  display: table;
  margin: 0 auto;
}

/* lists */
ol, ul {
  padding: 0;
  margin: 0 0 1em 2em;
}
ol ol, ul ul, ol ul, ul ol {
  margin-left: 1em;
}
li {
  margin: 0 0 0.25em 0;
}
.ulCompact li {
  margin: 0;
}
ul.empty, .ulEmpty {
  list-style-type: none;
}
ul.empty li, .ulEmpty li {
  margin-top: 0.5em;
}
ul.compact, .ulCompact,
ol.compact, .olCompact {
  line-height: 100%;
  margin: 0 0 0 2em;
}

/* definition lists */
dl {
}
dl > dt {
  float: left;
  margin-right: 1em;
}
dl.nohang > dt {
  float: none;
}
dl > dd {
  margin-bottom: .8em;
  min-height: 1.3em;
}
dl.compact > dd, dlCompact > dd {
  margin-bottom: 0em;
}
dl > dd > dl {
  margin-top: 0.5em;
  margin-bottom: 0em;
}

/* links */
a {
  text-decoration: none;
}
a[href] {
  color: #3E8EDE;
}
a[href]:hover {
  background-color: #f2f2f2;
}
figcaption a[href],
a[href].selfRef {
  color: #222;
}
/* XXX probably not this:
a.selfRef:hover {
  background-color: transparent;
  cursor: default;
} */

/* Figures */
tt, code, pre, code {
  background-color: #f9f9f9;
  font-family: 'Roboto Mono', monospace;
}
pre {
  border: 1px solid #eee;
  margin: 0;
  padding: 1em;
}
img {
  max-width: 100%;
}
figure {
  margin: 0;
}
figure blockquote {
  margin: 0.8em 0.4em 0.4em;
}
figcaption {
  font-style: italic;
  margin: 0 0 1em 0;
}
@media screen {
  pre {
    overflow-x: auto;
    max-width: 100%;
    max-width: calc(100% - 22px);
  }
}

/* aside, blockquote */
aside, blockquote {
  margin-left: 0;
  padding: 1.2em 2em;
}
blockquote {
  background-color: #f9f9f9;
  border: 1px solid #ddd;
  border-radius: 3px;
  margin: 1em 0;
}
cite {
  display: block;
  text-align: right;
  font-style: italic;
}

/* tables */
table {
  width: 100%;
  margin: 0 0 1em;
  border-collapse: collapse;
  border: 1px solid #eee;
}
th, td {
  text-align: left;
  vertical-align: top;
  padding: 0.5em 0.75em;
}
th {
  text-align: left;
  background-color: #e9e9e9;
}
tr:nth-child(2n+1) > td {
  background-color: #f5f5f5;
}
table caption {
  font-style: italic;
  margin: 0;
  padding: 0;
  text-align: left;
}
table p {
  /* XXX to avoid bottom margin on table row signifiers. If paragraphs should
     be allowed within tables more generally, it would be far better to select on a class. */
  margin: 0;
}

/* pilcrow */
a.pilcrow {
  color: #777;
  text-decoration: none;
  visibility: hidden;
  user-select: none;
  -ms-user-select: none;
  -o-user-select:none;
  -moz-user-select: none;
  -khtml-user-select: none;
  -webkit-user-select: none;
  -webkit-touch-callout: none;
}
@media screen {
  aside:hover > a.pilcrow,
  p:hover > a.pilcrow,
  blockquote:hover > a.pilcrow,
  div:hover > a.pilcrow,
  li:hover > a.pilcrow,
  pre:hover > a.pilcrow {
    visibility: visible;
  }
  a.pilcrow:hover {
    background-color: transparent;
  }
}

/* misc */
hr {
  border: 0;
  border-top: 1px solid #eee;
}
.bcp14 {
  font-variant: small-caps;
}

.role {
  font-variant: all-small-caps;
}

/* info block */
#identifiers {
  margin: 0;
  font-size: 0.9em;
}
#identifiers dt {
  width: 3em;
  clear: left;
}
#identifiers dd {
  float: left;
  margin-bottom: 0;
}
#identifiers .authors .author {
  display: inline-block;
  margin-right: 1.5em;
}
#identifiers .authors .org {
  font-style: italic;
}

/* The prepared/rendered info at the very bottom of the page */
.docInfo {
  color: #999;
  font-size: 0.9em;
  font-style: italic;
  margin-top: 2em;
}
.docInfo .prepared {
  float: left;
}
.docInfo .prepared {
  float: right;
}

/* table of contents */
#toc  {
  padding: 0.75em 0 2em 0;
  margin-bottom: 1em;
}
nav.toc ul {
  margin: 0 0.5em 0 0;
  padding: 0;
  list-style: none;
}
nav.toc li {
  line-height: 1.3em;
  margin: 0.75em 0;
  padding-left: 1.2em;
  text-indent: -1.2em;
}
/* references */
.reference dt {
  text-align: right;
  font-weight: bold;
  min-width: 7em;
}
.reference dd {
  margin-left: 8em;
  overflow: auto;
}

.refInstance {
  margin-bottom: 1.25em;
}

.reference .ascii {
  margin-bottom: 0.25em;
}

/* index */
.index ul {
  margin: 0 0 0 1em;
  padding: 0;
  list-style: none;
}
.index ul ul {
  margin: 0;
}
.index li {
  margin: 0;
  text-indent: -2em;
  padding-left: 2em;
  padding-bottom: 5px;
}
.indexIndex {
  margin: 0.5em 0 1em;
}
.index a {
  font-weight: 700;
}
/* make the index two-column on all but the smallest screens */
@media (min-width: 600px) {
  .index ul {
    -moz-column-count: 2;
    -moz-column-gap: 20px;
  }
  .index ul ul {
    -moz-column-count: 1;
    -moz-column-gap: 0;
  }
}

/* authors */
address.vcard {
  font-style: normal;
  margin: 1em 0;
}

address.vcard .nameRole {
  font-weight: 700;
  margin-left: 0;
}
address.vcard .label {
  font-family: "Noto Sans",Arial,Helvetica,sans-serif;
  margin: 0.5em 0;
}
address.vcard .type {
  display: none;
}
.alternative-contact {
  margin: 1.5em 0 1em;
}
hr.addr {
  border-top: 1px dashed;
  margin: 0;
  color: #ddd;
  max-width: calc(100% - 16px);
}

/* temporary notes */
.rfcEditorRemove::before {
  position: absolute;
  top: 0.2em;
  right: 0.2em;
  padding: 0.2em;
  content: "The RFC Editor will remove this note";
  color: #b76427;
  background-color: rgba(249, 232, 105, 0.3);
}
.rfcEditorRemove {
  position: relative;
  padding-top: 1.8em;
  background-color: rgba(249, 232, 105, 0.3);
  border-radius: 3px;
}
.cref {
  background-color: rgba(249, 232, 105, 0.3);
  padding: 2px 4px;
}
.crefSource {
  font-style: italic;
}
/* alternative layout for smaller screens */
@media screen and (max-width: 1023px) {
  body {
    padding-top: 2em;
  }
  #title {
    padding: 1em 0;
  }
  h1 {
    font-size: 24px;
  }
  h2 {
    font-size: 20px;
    margin-top: -18px;  /* provide offset for in-page anchors */
    padding-top: 38px;
  }
  #identifiers dd {
    max-width: 60%;
  }
  #toc {
    position: fixed;
    z-index: 2;
    top: 0;
    right: 0;
    padding: 0;
    margin: 0;
    background-color: inherit;
    border-bottom: 1px solid #ccc;
  }
  #toc h2 {
    margin: -1px 0 0 0;
    padding: 4px 0 4px 6px;
    padding-right: 1em;
    min-width: 190px;
    font-size: 1.1em;
    text-align: right;
    background-color: #444;
    color: white;
    cursor: pointer;
  }
  #toc h2::before { /* css hamburger */
    float: right;
    position: relative;
    width: 1em;
    height: 1px;
    left: -164px;
    margin: 6px 0 0 0;
    background: white none repeat scroll 0 0;
    box-shadow: 0 4px 0 0 white, 0 8px 0 0 white;
    content: "";
  }
  #toc nav {
    display: none;
    padding: 0.5em 1em 1em;
    overflow: auto;
    height: calc(100vh - 48px);
    border-left: 1px solid #ddd;
  }
}

/* alternative layout for wide screens */
@media screen and (min-width: 1024px) {
  body {
    max-width: 724px;
    margin: 42px auto;
    padding-left: 1.5em;
    padding-right: 29em;
  }
  #toc {
    position: fixed;
    top: 42px;
    right: 42px;
    width: 25%;
    margin: 0;
    padding: 0 1em;
    z-index: 1;
  }
  #toc h2 {
    border-top: none;
    border-bottom: 1px solid #ddd;
    font-size: 1em;
    font-weight: normal;
    margin: 0;
    padding: 0.25em 1em 1em 0;
  }
  #toc nav {
    display: block;
    height: calc(90vh - 84px);
    bottom: 0;
    padding: 0.5em 0 0;
    overflow: auto;
  }
  img { /* future proofing */
    max-width: 100%;
    height: auto;
  }
}

/* pagination */
@media print {
  body {
    font-family: 'Noto Serif', "Times New Roman", Times, serif;
    width: 100%;
  }
  p {
    orphans: 3;
    widows: 3;
  }
  #n-copyright-notice {
    border-bottom: none;
  }
  #toc, #n-introduction {
    page-break-before: always;
  }
  #toc {
    border-top: none;
    padding-top: 0;
  }
  figure, pre {
    page-break-inside: avoid;
  }
  figure {
    overflow: scroll;
  }
  h1, h2, h3, h4, h5, h6 {
    page-break-after: avoid;
  }
  h2+*, h3+*, h4+*, h5+*, h6+* {
    page-break-before: avoid;
  }
  pre {
    white-space: pre-wrap;
    word-wrap: break-word;
    font-size: 10pt;
  }
  table {
    border: 1px solid #ddd;
  }
  td {
    border-top: 1px solid #ddd;
  }
}

.ears thead .left {
  string-set: ears-top-left content();
}

.ears thead .center {
  string-set: ears-top-center content();
}

.ears thead .right {
  string-set: ears-top-right content();
}

.ears tfoot .left {
  string-set: ears-bottom-left content();
}

.ears tfoot .center {
  string-set: ears-bottom-center content();
}

.ears tfoot .right {
  string-set: ears-bottom-right content();
}

@page :first {
  padding-top: 0;
  @top-left {
    content: normal;
    border: none;
  }
  @top-center {
    content: normal;
    border: none;
  }
  @top-right {
    content: normal;
    border: none;
  }
}

@page {
  size: A4;
  margin-bottom: 45mm;
  padding-top: 20px;
  @top-left {
    content: 'Internet-Draft';
    vertical-align: bottom;
    border-bottom: solid 1px #ccc;
  }
  @top-left {
    content: string(ears-top-left);
    vertical-align: bottom;
    border-bottom: solid 1px #ccc;
  }
  @top-center {
    content: string(ears-top-center);
    vertical-align: bottom;
    border-bottom: solid 1px #ccc;
  }
  @top-right {
    content: string(ears-top-right);
    vertical-align: bottom;
    border-bottom: solid 1px #ccc;
  }
  @bottom-left {
    content: string(ears-bottom-left);
    vertical-align: top;
    border-top: solid 1px #ccc;
  }
  @bottom-center {
    content: string(ears-bottom-center);
    vertical-align: top;
    border-top: solid 1px #ccc;
  }
  @bottom-right {
      content: '[Page ' counter(page) ']';
      vertical-align: top;
      border-top: solid 1px #ccc;
  }
}

/* Changes introduced to fix issues found during implementation */

/* Separate body from document info even without intervening H1 */
section {
  clear: both;
}


/* Top align author divs, to avoid names without organization dropping level with org names */
.author {
  vertical-align: top;
}

/* Leave room in document info to show Internet-Draft on one line */
#identifiers dt {
  width: 8em;
}

/* Don't waste quite as much whitespace between label and value in doc info */
#identifiers dd {
  margin-left: 1em;
}

/* Give floating toc a background color (needed when it's a div inside section */
#toc {
  background-color: white;
}

/* Make the collapsed ToC header render white on gray also when it's a link */
@media screen and (max-width: 1023px) {
  #toc h2 a,
  #toc h2 a:link,
  #toc h2 a:focus,
  #toc h2 a:hover,
  #toc a.toplink,
  #toc a.toplink:hover {
    color: white;
    background-color: #444;
    text-decoration: none;
  }
}

/* Give the bottom of the ToC some whitespace */
@media screen and (min-width: 1024px) {
  #toc {
    padding: 0 0 1em 1em;
  }
}

/* Style section numbers with more space between number and title */
.section-number {
  padding-right: 0.5em;
}

/* prevent monospace from becoming overly large */
tt, code, pre, code {
  font-size: 95%;
}

/* Fix the height/width aspect for ascii art*/
.art-text pre {
  line-height: 1.12;
}

/* Add styling for a link in the ToC that points to the top of the document */
a.toplink {
  float: right;
  margin-right: 0.5em;
}
</style>
<link href="rfc-local.css" type="text/css" rel="stylesheet">
<link href="https://dx.doi.org/10.17487/rfc6787" rel="describedBy">
<link href="urn:issn:2070-1721" rel="item">
<link href="https://datatracker.ietf.org/doc/draft-ietf-speechsc-mrcpv2" rel="convertedFrom">
</head>
<body>
<div class="document-information"><dl id="identifiers">
<dt class="label-stream">Stream:</dt>
<dd class="stream">Internet Engineering Task Force (IETF)</dd>
<dt class="label-rfc">RFC:</dt>
<dd class="rfc"><a href="https://www.rfc-editor.org/rfc/rfc6787.txt" class="eref">6787</a></dd>
<dt class="label-category">Category:</dt>
<dd class="category">Standards Track</dd>
<dt class="label-published">Published:</dt>
<dd class="published"><time datetime="2012-11" class="published">November 2012</time></dd>
<dt class="label-issn">ISSN:</dt>
<dd class="issn">2070-1721</dd>
<dt class="label-authors">Authors:</dt>
<dd class="authors">
<div class="author">
<div class="author-name">D. Burnett</div>
<div class="org">Voxeo</div>
</div>
<div class="author">
<div class="author-name">S. Shanmugham</div>
<div class="org">Cisco Systems, Inc.</div>
</div>
</dd>
</dl></div>
<h1 id="title">Media Resource Control Protocol Version 2
    (MRCPv2)</h1>
<section id="section-abstract"><h2 id="abstract"><a href="#abstract" class="selfRef">Abstract</a></h2>
<p id="section-abstract-1">The Media Resource Control Protocol Version 2 (MRCPv2) allows client hosts to control media service
      resources such as speech synthesizers, recognizers, verifiers, and
      identifiers residing in servers on the network. MRCPv2 is not a
      "stand-alone" protocol -- it relies on other protocols, such as the Session
      Initiation Protocol (SIP), to coordinate MRCPv2 clients and servers and
      manage sessions between them, and the Session Description Protocol (SDP)
      to describe, discover, and exchange capabilities. It also depends on SIP
      and SDP to establish the media sessions and associated parameters
      between the media source or sink and the media server. Once this is
      done, the MRCPv2 exchange operates over the control session
      established above, allowing the client to control the media processing
      resources on the speech resource server.</p></section><section id="section-boilerplate.1"><div id="status-of-memo">
<h2 id="name-status-of-this-memo"><a href="#name-status-of-this-memo" class="section-name selfRef">Status of This Memo</a></h2>
<p id="section-boilerplate.1-1">This is an Internet Standards Track document.</p>
<p id="section-boilerplate.1-2">This document is a product of the Internet Engineering Task Force
            (IETF).  It represents the consensus of the IETF community.  It has
            received public review and has been approved for publication by
            the Internet Engineering Steering Group (IESG).  Further
            information on Internet Standards is available in Section 2 of 
            RFC 7841.</p>
<p id="section-boilerplate.1-3">Information about the current status of this document, any
            errata, and how to provide feedback on it may be obtained at
            http://www.rfc-editor.org/info/rfc6787.</p>
</div></section><section id="section-boilerplate.2"><div id="copyright">
<h2 id="name-copyright-notice"><a href="#name-copyright-notice" class="section-name selfRef">Copyright Notice</a></h2>
<p id="section-boilerplate.2-1">Copyright (c) 2012 IETF Trust and the persons identified as the document
            authors. All rights reserved.</p>
<p id="section-boilerplate.2-2">This document is subject to BCP 78 and the IETF Trust's Legal
            Provisions Relating to IETF Documents
            (http://trustee.ietf.org/license-info) in effect on the date of
            publication of this document. Please review these documents carefully,
            as they describe your rights and restrictions with respect to this
            document. Code Components extracted from this document must include
            Simplified BSD License text as described in Section 4.e of the Trust
            Legal Provisions and are provided without warranty as described in the
            Simplified BSD License.</p>
<p id="section-boilerplate.2-3">This document may contain material from IETF Documents or IETF
            Contributions published or made publicly available before November
            10, 2008. The person(s) controlling the copyright in some of this
            material may not have granted the IETF Trust the right to allow
            modifications of such material outside the IETF Standards Process.
            Without obtaining an adequate license from the person(s)
            controlling the copyright in such materials, this document may not
            be modified outside the IETF Standards Process, and derivative
            works of it may not be created outside the IETF Standards Process,
            except to format it for publication as an RFC or to translate it
            into languages other than English.</p>
</div></section><section id="section-boilerplate.3"><div id="toc">
<a href="#" onclick="scroll(0,0)" class="toplink">â–²</a><h2 id="name-table-of-contents"><a href="#name-table-of-contents" class="section-name selfRef">Table of Contents</a></h2>
<nav class="toc"><ul class="toc">
<li id="section-boilerplate.3-2" class="toc"><p id="section-boilerplate.3-3"><a href="#section-1" class="xref">1</a>.  <a href="#name-introduction" class="xref">Introduction</a></p></li>
<li id="section-boilerplate.3-4" class="toc">
<p id="section-boilerplate.3-5"><a href="#section-2" class="xref">2</a>.  <a href="#name-document-conventions" class="xref">Document Conventions</a></p>
<ul class="toc">
<li id="section-boilerplate.3-7" class="toc"><p id="section-boilerplate.3-8"><a href="#section-2.1" class="xref">2.1</a>.  <a href="#name-definitions" class="xref">Definitions</a></p></li>
<li id="section-boilerplate.3-9" class="toc"><p id="section-boilerplate.3-10"><a href="#section-2.2" class="xref">2.2</a>.  <a href="#name-state-machine-diagrams" class="xref">State-Machine Diagrams</a></p></li>
<li id="section-boilerplate.3-11" class="toc"><p id="section-boilerplate.3-12"><a href="#section-2.3" class="xref">2.3</a>.  <a href="#name-uri-schemes" class="xref">URI Schemes</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-13" class="toc">
<p id="section-boilerplate.3-14"><a href="#section-3" class="xref">3</a>.  <a href="#name-architecture" class="xref">Architecture</a></p>
<ul class="toc">
<li id="section-boilerplate.3-16" class="toc"><p id="section-boilerplate.3-17"><a href="#section-3.1" class="xref">3.1</a>.  <a href="#name-mrcpv2-media-resource-types" class="xref">MRCPv2 Media Resource Types</a></p></li>
<li id="section-boilerplate.3-18" class="toc"><p id="section-boilerplate.3-19"><a href="#section-3.2" class="xref">3.2</a>.  <a href="#name-server-and-resource-address" class="xref">Server and Resource Addressing</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-20" class="toc">
<p id="section-boilerplate.3-21"><a href="#section-4" class="xref">4</a>.  <a href="#name-mrcpv2-basics" class="xref">MRCPv2 Basics</a></p>
<ul class="toc">
<li id="section-boilerplate.3-23" class="toc"><p id="section-boilerplate.3-24"><a href="#section-4.1" class="xref">4.1</a>.  <a href="#name-connecting-to-the-server" class="xref">Connecting to the Server</a></p></li>
<li id="section-boilerplate.3-25" class="toc"><p id="section-boilerplate.3-26"><a href="#section-4.2" class="xref">4.2</a>.  <a href="#name-managing-resource-control-c" class="xref">Managing Resource Control Channels</a></p></li>
<li id="section-boilerplate.3-27" class="toc"><p id="section-boilerplate.3-28"><a href="#section-4.3" class="xref">4.3</a>.  <a href="#name-sip-session-example" class="xref">SIP Session Example</a></p></li>
<li id="section-boilerplate.3-29" class="toc"><p id="section-boilerplate.3-30"><a href="#section-4.4" class="xref">4.4</a>.  <a href="#name-media-streams-and-rtp-ports" class="xref">Media Streams and RTP Ports</a></p></li>
<li id="section-boilerplate.3-31" class="toc"><p id="section-boilerplate.3-32"><a href="#section-4.5" class="xref">4.5</a>.  <a href="#name-mrcpv2-message-transport" class="xref">MRCPv2 Message Transport</a></p></li>
<li id="section-boilerplate.3-33" class="toc"><p id="section-boilerplate.3-34"><a href="#section-4.6" class="xref">4.6</a>.  <a href="#name-mrcpv2-session-termination" class="xref">MRCPv2 Session Termination</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-35" class="toc">
<p id="section-boilerplate.3-36"><a href="#section-5" class="xref">5</a>.  <a href="#name-mrcpv2-specification" class="xref">MRCPv2 Specification</a></p>
<ul class="toc">
<li id="section-boilerplate.3-38" class="toc"><p id="section-boilerplate.3-39"><a href="#section-5.1" class="xref">5.1</a>.  <a href="#name-common-protocol-elements" class="xref">Common Protocol Elements</a></p></li>
<li id="section-boilerplate.3-40" class="toc"><p id="section-boilerplate.3-41"><a href="#section-5.2" class="xref">5.2</a>.  <a href="#name-request" class="xref">Request</a></p></li>
<li id="section-boilerplate.3-42" class="toc"><p id="section-boilerplate.3-43"><a href="#section-5.3" class="xref">5.3</a>.  <a href="#name-response" class="xref">Response</a></p></li>
<li id="section-boilerplate.3-44" class="toc"><p id="section-boilerplate.3-45"><a href="#section-5.4" class="xref">5.4</a>.  <a href="#name-status-codes" class="xref">Status Codes</a></p></li>
<li id="section-boilerplate.3-46" class="toc"><p id="section-boilerplate.3-47"><a href="#section-5.5" class="xref">5.5</a>.  <a href="#name-events" class="xref">Events</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-48" class="toc">
<p id="section-boilerplate.3-49"><a href="#section-6" class="xref">6</a>.  <a href="#name-mrcpv2-generic-methods-head" class="xref">MRCPv2 Generic Methods, Headers, and Result Structure</a></p>
<ul class="toc">
<li id="section-boilerplate.3-51" class="toc">
<p id="section-boilerplate.3-52"><a href="#section-6.1" class="xref">6.1</a>.  <a href="#name-generic-methods" class="xref">Generic Methods</a></p>
<ul class="toc">
<li id="section-boilerplate.3-54" class="toc"><p id="section-boilerplate.3-55"><a href="#section-6.1.1" class="xref">6.1.1</a>.  <a href="#name-set-params" class="xref">SET-PARAMS</a></p></li>
<li id="section-boilerplate.3-56" class="toc"><p id="section-boilerplate.3-57"><a href="#section-6.1.2" class="xref">6.1.2</a>.  <a href="#name-get-params" class="xref">GET-PARAMS</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-58" class="toc">
<p id="section-boilerplate.3-59"><a href="#section-6.2" class="xref">6.2</a>.  <a href="#name-generic-message-headers" class="xref">Generic Message Headers</a></p>
<ul class="toc">
<li id="section-boilerplate.3-61" class="toc"><p id="section-boilerplate.3-62"><a href="#section-6.2.1" class="xref">6.2.1</a>.  <a href="#name-channel-identifier" class="xref">Channel-Identifier</a></p></li>
<li id="section-boilerplate.3-63" class="toc"><p id="section-boilerplate.3-64"><a href="#section-6.2.2" class="xref">6.2.2</a>.  <a href="#name-accept" class="xref">Accept</a></p></li>
<li id="section-boilerplate.3-65" class="toc"><p id="section-boilerplate.3-66"><a href="#section-6.2.3" class="xref">6.2.3</a>.  <a href="#name-active-request-id-list" class="xref">Active-Request-Id-List</a></p></li>
<li id="section-boilerplate.3-67" class="toc"><p id="section-boilerplate.3-68"><a href="#section-6.2.4" class="xref">6.2.4</a>.  <a href="#name-proxy-sync-id" class="xref">Proxy-Sync-Id</a></p></li>
<li id="section-boilerplate.3-69" class="toc"><p id="section-boilerplate.3-70"><a href="#section-6.2.5" class="xref">6.2.5</a>.  <a href="#name-accept-charset" class="xref">Accept-Charset</a></p></li>
<li id="section-boilerplate.3-71" class="toc"><p id="section-boilerplate.3-72"><a href="#section-6.2.6" class="xref">6.2.6</a>.  <a href="#name-content-type" class="xref">Content-Type</a></p></li>
<li id="section-boilerplate.3-73" class="toc"><p id="section-boilerplate.3-74"><a href="#section-6.2.7" class="xref">6.2.7</a>.  <a href="#name-content-id" class="xref">Content-ID</a></p></li>
<li id="section-boilerplate.3-75" class="toc"><p id="section-boilerplate.3-76"><a href="#section-6.2.8" class="xref">6.2.8</a>.  <a href="#name-content-base" class="xref">Content-Base</a></p></li>
<li id="section-boilerplate.3-77" class="toc"><p id="section-boilerplate.3-78"><a href="#section-6.2.9" class="xref">6.2.9</a>.  <a href="#name-content-encoding" class="xref">Content-Encoding</a></p></li>
<li id="section-boilerplate.3-79" class="toc"><p id="section-boilerplate.3-80"><a href="#section-6.2.10" class="xref">6.2.10</a>.  <a href="#name-content-location" class="xref">Content-Location</a></p></li>
<li id="section-boilerplate.3-81" class="toc"><p id="section-boilerplate.3-82"><a href="#section-6.2.11" class="xref">6.2.11</a>.  <a href="#name-content-length" class="xref">Content-Length</a></p></li>
<li id="section-boilerplate.3-83" class="toc"><p id="section-boilerplate.3-84"><a href="#section-6.2.12" class="xref">6.2.12</a>.  <a href="#name-fetch-timeout" class="xref">Fetch Timeout</a></p></li>
<li id="section-boilerplate.3-85" class="toc"><p id="section-boilerplate.3-86"><a href="#section-6.2.13" class="xref">6.2.13</a>.  <a href="#name-cache-control" class="xref">Cache-Control</a></p></li>
<li id="section-boilerplate.3-87" class="toc"><p id="section-boilerplate.3-88"><a href="#section-6.2.14" class="xref">6.2.14</a>.  <a href="#name-logging-tag" class="xref">Logging-Tag</a></p></li>
<li id="section-boilerplate.3-89" class="toc"><p id="section-boilerplate.3-90"><a href="#section-6.2.15" class="xref">6.2.15</a>.  <a href="#name-set-cookie" class="xref">Set-Cookie</a></p></li>
<li id="section-boilerplate.3-91" class="toc"><p id="section-boilerplate.3-92"><a href="#section-6.2.16" class="xref">6.2.16</a>.  <a href="#name-vendor-specific-parameters" class="xref">Vendor-Specific Parameters</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-93" class="toc">
<p id="section-boilerplate.3-94"><a href="#section-6.3" class="xref">6.3</a>.  <a href="#name-generic-result-structure" class="xref">Generic Result Structure</a></p>
<ul class="toc"><li id="section-boilerplate.3-96" class="toc"><p id="section-boilerplate.3-97"><a href="#section-6.3.1" class="xref">6.3.1</a>.  <a href="#name-natural-language-semantics-" class="xref">Natural Language Semantics Markup Language</a></p></li></ul>
</li>
</ul>
</li>
<li id="section-boilerplate.3-98" class="toc"><p id="section-boilerplate.3-99"><a href="#section-7" class="xref">7</a>.  <a href="#name-resource-discovery" class="xref">Resource Discovery</a></p></li>
<li id="section-boilerplate.3-100" class="toc">
<p id="section-boilerplate.3-101"><a href="#section-8" class="xref">8</a>.  <a href="#name-speech-synthesizer-resource" class="xref">Speech Synthesizer Resource</a></p>
<ul class="toc">
<li id="section-boilerplate.3-103" class="toc"><p id="section-boilerplate.3-104"><a href="#section-8.1" class="xref">8.1</a>.  <a href="#name-synthesizer-state-machine" class="xref">Synthesizer State Machine</a></p></li>
<li id="section-boilerplate.3-105" class="toc"><p id="section-boilerplate.3-106"><a href="#section-8.2" class="xref">8.2</a>.  <a href="#name-synthesizer-methods" class="xref">Synthesizer Methods</a></p></li>
<li id="section-boilerplate.3-107" class="toc"><p id="section-boilerplate.3-108"><a href="#section-8.3" class="xref">8.3</a>.  <a href="#name-synthesizer-events" class="xref">Synthesizer Events</a></p></li>
<li id="section-boilerplate.3-109" class="toc">
<p id="section-boilerplate.3-110"><a href="#section-8.4" class="xref">8.4</a>.  <a href="#name-synthesizer-header-fields" class="xref">Synthesizer Header Fields</a></p>
<ul class="toc">
<li id="section-boilerplate.3-112" class="toc"><p id="section-boilerplate.3-113"><a href="#section-8.4.1" class="xref">8.4.1</a>.  <a href="#name-jump-size" class="xref">Jump-Size</a></p></li>
<li id="section-boilerplate.3-114" class="toc"><p id="section-boilerplate.3-115"><a href="#section-8.4.2" class="xref">8.4.2</a>.  <a href="#name-kill-on-barge-in" class="xref">Kill-On-Barge-In</a></p></li>
<li id="section-boilerplate.3-116" class="toc"><p id="section-boilerplate.3-117"><a href="#section-8.4.3" class="xref">8.4.3</a>.  <a href="#name-speaker-profile" class="xref">Speaker-Profile</a></p></li>
<li id="section-boilerplate.3-118" class="toc"><p id="section-boilerplate.3-119"><a href="#section-8.4.4" class="xref">8.4.4</a>.  <a href="#name-completion-cause" class="xref">Completion-Cause</a></p></li>
<li id="section-boilerplate.3-120" class="toc"><p id="section-boilerplate.3-121"><a href="#section-8.4.5" class="xref">8.4.5</a>.  <a href="#name-completion-reason" class="xref">Completion-Reason</a></p></li>
<li id="section-boilerplate.3-122" class="toc"><p id="section-boilerplate.3-123"><a href="#section-8.4.6" class="xref">8.4.6</a>.  <a href="#name-voice-parameter" class="xref">Voice-Parameter</a></p></li>
<li id="section-boilerplate.3-124" class="toc"><p id="section-boilerplate.3-125"><a href="#section-8.4.7" class="xref">8.4.7</a>.  <a href="#name-prosody-parameters" class="xref">Prosody-Parameters</a></p></li>
<li id="section-boilerplate.3-126" class="toc"><p id="section-boilerplate.3-127"><a href="#section-8.4.8" class="xref">8.4.8</a>.  <a href="#name-speech-marker" class="xref">Speech-Marker</a></p></li>
<li id="section-boilerplate.3-128" class="toc"><p id="section-boilerplate.3-129"><a href="#section-8.4.9" class="xref">8.4.9</a>.  <a href="#name-speech-language" class="xref">Speech-Language</a></p></li>
<li id="section-boilerplate.3-130" class="toc"><p id="section-boilerplate.3-131"><a href="#section-8.4.10" class="xref">8.4.10</a>.  <a href="#name-fetch-hint" class="xref">Fetch-Hint</a></p></li>
<li id="section-boilerplate.3-132" class="toc"><p id="section-boilerplate.3-133"><a href="#section-8.4.11" class="xref">8.4.11</a>.  <a href="#name-audio-fetch-hint" class="xref">Audio-Fetch-Hint</a></p></li>
<li id="section-boilerplate.3-134" class="toc"><p id="section-boilerplate.3-135"><a href="#section-8.4.12" class="xref">8.4.12</a>.  <a href="#name-failed-uri" class="xref">Failed-URI</a></p></li>
<li id="section-boilerplate.3-136" class="toc"><p id="section-boilerplate.3-137"><a href="#section-8.4.13" class="xref">8.4.13</a>.  <a href="#name-failed-uri-cause" class="xref">Failed-URI-Cause</a></p></li>
<li id="section-boilerplate.3-138" class="toc"><p id="section-boilerplate.3-139"><a href="#section-8.4.14" class="xref">8.4.14</a>.  <a href="#name-speak-restart" class="xref">Speak-Restart</a></p></li>
<li id="section-boilerplate.3-140" class="toc"><p id="section-boilerplate.3-141"><a href="#section-8.4.15" class="xref">8.4.15</a>.  <a href="#name-speak-length" class="xref">Speak-Length</a></p></li>
<li id="section-boilerplate.3-142" class="toc"><p id="section-boilerplate.3-143"><a href="#section-8.4.16" class="xref">8.4.16</a>.  <a href="#name-load-lexicon" class="xref">Load-Lexicon</a></p></li>
<li id="section-boilerplate.3-144" class="toc"><p id="section-boilerplate.3-145"><a href="#section-8.4.17" class="xref">8.4.17</a>.  <a href="#name-lexicon-search-order" class="xref">Lexicon-Search-Order</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-146" class="toc">
<p id="section-boilerplate.3-147"><a href="#section-8.5" class="xref">8.5</a>.  <a href="#name-synthesizer-message-body" class="xref">Synthesizer Message Body</a></p>
<ul class="toc">
<li id="section-boilerplate.3-149" class="toc"><p id="section-boilerplate.3-150"><a href="#section-8.5.1" class="xref">8.5.1</a>.  <a href="#name-synthesizer-speech-data" class="xref">Synthesizer Speech Data</a></p></li>
<li id="section-boilerplate.3-151" class="toc"><p id="section-boilerplate.3-152"><a href="#section-8.5.2" class="xref">8.5.2</a>.  <a href="#name-lexicon-data" class="xref">Lexicon Data</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-153" class="toc"><p id="section-boilerplate.3-154"><a href="#section-8.6" class="xref">8.6</a>.  <a href="#name-speak-method" class="xref">SPEAK Method</a></p></li>
<li id="section-boilerplate.3-155" class="toc"><p id="section-boilerplate.3-156"><a href="#section-8.7" class="xref">8.7</a>.  <a href="#name-stop" class="xref">STOP</a></p></li>
<li id="section-boilerplate.3-157" class="toc"><p id="section-boilerplate.3-158"><a href="#section-8.8" class="xref">8.8</a>.  <a href="#name-barge-in-occurred" class="xref">BARGE-IN-OCCURRED</a></p></li>
<li id="section-boilerplate.3-159" class="toc"><p id="section-boilerplate.3-160"><a href="#section-8.9" class="xref">8.9</a>.  <a href="#name-pause" class="xref">PAUSE</a></p></li>
<li id="section-boilerplate.3-161" class="toc"><p id="section-boilerplate.3-162"><a href="#section-8.10" class="xref">8.10</a>.  <a href="#name-resume" class="xref">RESUME</a></p></li>
<li id="section-boilerplate.3-163" class="toc"><p id="section-boilerplate.3-164"><a href="#section-8.11" class="xref">8.11</a>.  <a href="#name-control" class="xref">CONTROL</a></p></li>
<li id="section-boilerplate.3-165" class="toc"><p id="section-boilerplate.3-166"><a href="#section-8.12" class="xref">8.12</a>.  <a href="#name-speak-complete" class="xref">SPEAK-COMPLETE</a></p></li>
<li id="section-boilerplate.3-167" class="toc"><p id="section-boilerplate.3-168"><a href="#section-8.13" class="xref">8.13</a>.  <a href="#name-speech-marker-2" class="xref">SPEECH-MARKER</a></p></li>
<li id="section-boilerplate.3-169" class="toc"><p id="section-boilerplate.3-170"><a href="#section-8.14" class="xref">8.14</a>.  <a href="#name-define-lexicon" class="xref">DEFINE-LEXICON</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-171" class="toc">
<p id="section-boilerplate.3-172"><a href="#section-9" class="xref">9</a>.  <a href="#name-speech-recognizer-resource" class="xref">Speech Recognizer Resource</a></p>
<ul class="toc">
<li id="section-boilerplate.3-174" class="toc"><p id="section-boilerplate.3-175"><a href="#section-9.1" class="xref">9.1</a>.  <a href="#name-recognizer-state-machine" class="xref">Recognizer State Machine</a></p></li>
<li id="section-boilerplate.3-176" class="toc"><p id="section-boilerplate.3-177"><a href="#section-9.2" class="xref">9.2</a>.  <a href="#name-recognizer-methods" class="xref">Recognizer Methods</a></p></li>
<li id="section-boilerplate.3-178" class="toc"><p id="section-boilerplate.3-179"><a href="#section-9.3" class="xref">9.3</a>.  <a href="#name-recognizer-events" class="xref">Recognizer Events</a></p></li>
<li id="section-boilerplate.3-180" class="toc">
<p id="section-boilerplate.3-181"><a href="#section-9.4" class="xref">9.4</a>.  <a href="#name-recognizer-header-fields" class="xref">Recognizer Header Fields</a></p>
<ul class="toc">
<li id="section-boilerplate.3-183" class="toc"><p id="section-boilerplate.3-184"><a href="#section-9.4.1" class="xref">9.4.1</a>.  <a href="#name-confidence-threshold" class="xref">Confidence-Threshold</a></p></li>
<li id="section-boilerplate.3-185" class="toc"><p id="section-boilerplate.3-186"><a href="#section-9.4.2" class="xref">9.4.2</a>.  <a href="#name-sensitivity-level" class="xref">Sensitivity-Level</a></p></li>
<li id="section-boilerplate.3-187" class="toc"><p id="section-boilerplate.3-188"><a href="#section-9.4.3" class="xref">9.4.3</a>.  <a href="#name-speed-vs-accuracy" class="xref">Speed-Vs-Accuracy</a></p></li>
<li id="section-boilerplate.3-189" class="toc"><p id="section-boilerplate.3-190"><a href="#section-9.4.4" class="xref">9.4.4</a>.  <a href="#name-n-best-list-length" class="xref">N-Best-List-Length</a></p></li>
<li id="section-boilerplate.3-191" class="toc"><p id="section-boilerplate.3-192"><a href="#section-9.4.5" class="xref">9.4.5</a>.  <a href="#name-input-type" class="xref">Input-Type</a></p></li>
<li id="section-boilerplate.3-193" class="toc"><p id="section-boilerplate.3-194"><a href="#section-9.4.6" class="xref">9.4.6</a>.  <a href="#name-no-input-timeout" class="xref">No-Input-Timeout</a></p></li>
<li id="section-boilerplate.3-195" class="toc"><p id="section-boilerplate.3-196"><a href="#section-9.4.7" class="xref">9.4.7</a>.  <a href="#name-recognition-timeout" class="xref">Recognition-Timeout</a></p></li>
<li id="section-boilerplate.3-197" class="toc"><p id="section-boilerplate.3-198"><a href="#section-9.4.8" class="xref">9.4.8</a>.  <a href="#name-waveform-uri" class="xref">Waveform-URI</a></p></li>
<li id="section-boilerplate.3-199" class="toc"><p id="section-boilerplate.3-200"><a href="#section-9.4.9" class="xref">9.4.9</a>.  <a href="#name-media-type" class="xref">Media-Type</a></p></li>
<li id="section-boilerplate.3-201" class="toc"><p id="section-boilerplate.3-202"><a href="#section-9.4.10" class="xref">9.4.10</a>.  <a href="#name-input-waveform-uri" class="xref">Input-Waveform-URI</a></p></li>
<li id="section-boilerplate.3-203" class="toc"><p id="section-boilerplate.3-204"><a href="#section-9.4.11" class="xref">9.4.11</a>.  <a href="#name-completion-cause-2" class="xref">Completion-Cause</a></p></li>
<li id="section-boilerplate.3-205" class="toc"><p id="section-boilerplate.3-206"><a href="#section-9.4.12" class="xref">9.4.12</a>.  <a href="#name-completion-reason-2" class="xref">Completion-Reason</a></p></li>
<li id="section-boilerplate.3-207" class="toc"><p id="section-boilerplate.3-208"><a href="#section-9.4.13" class="xref">9.4.13</a>.  <a href="#name-recognizer-context-block" class="xref">Recognizer-Context-Block</a></p></li>
<li id="section-boilerplate.3-209" class="toc"><p id="section-boilerplate.3-210"><a href="#section-9.4.14" class="xref">9.4.14</a>.  <a href="#name-start-input-timers" class="xref">Start-Input-Timers</a></p></li>
<li id="section-boilerplate.3-211" class="toc"><p id="section-boilerplate.3-212"><a href="#section-9.4.15" class="xref">9.4.15</a>.  <a href="#name-speech-complete-timeout" class="xref">Speech-Complete-Timeout</a></p></li>
<li id="section-boilerplate.3-213" class="toc"><p id="section-boilerplate.3-214"><a href="#section-9.4.16" class="xref">9.4.16</a>.  <a href="#name-speech-incomplete-timeout" class="xref">Speech-Incomplete-Timeout</a></p></li>
<li id="section-boilerplate.3-215" class="toc"><p id="section-boilerplate.3-216"><a href="#section-9.4.17" class="xref">9.4.17</a>.  <a href="#name-dtmf-interdigit-timeout" class="xref">DTMF-Interdigit-Timeout</a></p></li>
<li id="section-boilerplate.3-217" class="toc"><p id="section-boilerplate.3-218"><a href="#section-9.4.18" class="xref">9.4.18</a>.  <a href="#name-dtmf-term-timeout" class="xref">DTMF-Term-Timeout</a></p></li>
<li id="section-boilerplate.3-219" class="toc"><p id="section-boilerplate.3-220"><a href="#section-9.4.19" class="xref">9.4.19</a>.  <a href="#name-dtmf-term-char" class="xref">DTMF-Term-Char</a></p></li>
<li id="section-boilerplate.3-221" class="toc"><p id="section-boilerplate.3-222"><a href="#section-9.4.20" class="xref">9.4.20</a>.  <a href="#name-failed-uri-2" class="xref">Failed-URI</a></p></li>
<li id="section-boilerplate.3-223" class="toc"><p id="section-boilerplate.3-224"><a href="#section-9.4.21" class="xref">9.4.21</a>.  <a href="#name-failed-uri-cause-2" class="xref">Failed-URI-Cause</a></p></li>
<li id="section-boilerplate.3-225" class="toc"><p id="section-boilerplate.3-226"><a href="#section-9.4.22" class="xref">9.4.22</a>.  <a href="#name-save-waveform" class="xref">Save-Waveform</a></p></li>
<li id="section-boilerplate.3-227" class="toc"><p id="section-boilerplate.3-228"><a href="#section-9.4.23" class="xref">9.4.23</a>.  <a href="#name-new-audio-channel" class="xref">New-Audio-Channel</a></p></li>
<li id="section-boilerplate.3-229" class="toc"><p id="section-boilerplate.3-230"><a href="#section-9.4.24" class="xref">9.4.24</a>.  <a href="#name-speech-language-2" class="xref">Speech-Language</a></p></li>
<li id="section-boilerplate.3-231" class="toc"><p id="section-boilerplate.3-232"><a href="#section-9.4.25" class="xref">9.4.25</a>.  <a href="#name-ver-buffer-utterance" class="xref">Ver-Buffer-Utterance</a></p></li>
<li id="section-boilerplate.3-233" class="toc"><p id="section-boilerplate.3-234"><a href="#section-9.4.26" class="xref">9.4.26</a>.  <a href="#name-recognition-mode" class="xref">Recognition-Mode</a></p></li>
<li id="section-boilerplate.3-235" class="toc"><p id="section-boilerplate.3-236"><a href="#section-9.4.27" class="xref">9.4.27</a>.  <a href="#name-cancel-if-queue" class="xref">Cancel-If-Queue</a></p></li>
<li id="section-boilerplate.3-237" class="toc"><p id="section-boilerplate.3-238"><a href="#section-9.4.28" class="xref">9.4.28</a>.  <a href="#name-hotword-max-duration" class="xref">Hotword-Max-Duration</a></p></li>
<li id="section-boilerplate.3-239" class="toc"><p id="section-boilerplate.3-240"><a href="#section-9.4.29" class="xref">9.4.29</a>.  <a href="#name-hotword-min-duration" class="xref">Hotword-Min-Duration</a></p></li>
<li id="section-boilerplate.3-241" class="toc"><p id="section-boilerplate.3-242"><a href="#section-9.4.30" class="xref">9.4.30</a>.  <a href="#name-interpret-text" class="xref">Interpret-Text</a></p></li>
<li id="section-boilerplate.3-243" class="toc"><p id="section-boilerplate.3-244"><a href="#section-9.4.31" class="xref">9.4.31</a>.  <a href="#name-dtmf-buffer-time" class="xref">DTMF-Buffer-Time</a></p></li>
<li id="section-boilerplate.3-245" class="toc"><p id="section-boilerplate.3-246"><a href="#section-9.4.32" class="xref">9.4.32</a>.  <a href="#name-clear-dtmf-buffer" class="xref">Clear-DTMF-Buffer</a></p></li>
<li id="section-boilerplate.3-247" class="toc"><p id="section-boilerplate.3-248"><a href="#section-9.4.33" class="xref">9.4.33</a>.  <a href="#name-early-no-match" class="xref">Early-No-Match</a></p></li>
<li id="section-boilerplate.3-249" class="toc"><p id="section-boilerplate.3-250"><a href="#section-9.4.34" class="xref">9.4.34</a>.  <a href="#name-num-min-consistent-pronunci" class="xref">Num-Min-Consistent-Pronunciations</a></p></li>
<li id="section-boilerplate.3-251" class="toc"><p id="section-boilerplate.3-252"><a href="#section-9.4.35" class="xref">9.4.35</a>.  <a href="#name-consistency-threshold" class="xref">Consistency-Threshold</a></p></li>
<li id="section-boilerplate.3-253" class="toc"><p id="section-boilerplate.3-254"><a href="#section-9.4.36" class="xref">9.4.36</a>.  <a href="#name-clash-threshold" class="xref">Clash-Threshold</a></p></li>
<li id="section-boilerplate.3-255" class="toc"><p id="section-boilerplate.3-256"><a href="#section-9.4.37" class="xref">9.4.37</a>.  <a href="#name-personal-grammar-uri" class="xref">Personal-Grammar-URI</a></p></li>
<li id="section-boilerplate.3-257" class="toc"><p id="section-boilerplate.3-258"><a href="#section-9.4.38" class="xref">9.4.38</a>.  <a href="#name-enroll-utterance" class="xref">Enroll-Utterance</a></p></li>
<li id="section-boilerplate.3-259" class="toc"><p id="section-boilerplate.3-260"><a href="#section-9.4.39" class="xref">9.4.39</a>.  <a href="#name-phrase-id" class="xref">Phrase-Id</a></p></li>
<li id="section-boilerplate.3-261" class="toc"><p id="section-boilerplate.3-262"><a href="#section-9.4.40" class="xref">9.4.40</a>.  <a href="#name-phrase-nl" class="xref">Phrase-NL</a></p></li>
<li id="section-boilerplate.3-263" class="toc"><p id="section-boilerplate.3-264"><a href="#section-9.4.41" class="xref">9.4.41</a>.  <a href="#name-weight" class="xref">Weight</a></p></li>
<li id="section-boilerplate.3-265" class="toc"><p id="section-boilerplate.3-266"><a href="#section-9.4.42" class="xref">9.4.42</a>.  <a href="#name-save-best-waveform" class="xref">Save-Best-Waveform</a></p></li>
<li id="section-boilerplate.3-267" class="toc"><p id="section-boilerplate.3-268"><a href="#section-9.4.43" class="xref">9.4.43</a>.  <a href="#name-new-phrase-id" class="xref">New-Phrase-Id</a></p></li>
<li id="section-boilerplate.3-269" class="toc"><p id="section-boilerplate.3-270"><a href="#section-9.4.44" class="xref">9.4.44</a>.  <a href="#name-confusable-phrases-uri" class="xref">Confusable-Phrases-URI</a></p></li>
<li id="section-boilerplate.3-271" class="toc"><p id="section-boilerplate.3-272"><a href="#section-9.4.45" class="xref">9.4.45</a>.  <a href="#name-abort-phrase-enrollment" class="xref">Abort-Phrase-Enrollment</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-273" class="toc">
<p id="section-boilerplate.3-274"><a href="#section-9.5" class="xref">9.5</a>.  <a href="#name-recognizer-message-body" class="xref">Recognizer Message Body</a></p>
<ul class="toc">
<li id="section-boilerplate.3-276" class="toc"><p id="section-boilerplate.3-277"><a href="#section-9.5.1" class="xref">9.5.1</a>.  <a href="#name-recognizer-grammar-data" class="xref">Recognizer Grammar Data</a></p></li>
<li id="section-boilerplate.3-278" class="toc"><p id="section-boilerplate.3-279"><a href="#section-9.5.2" class="xref">9.5.2</a>.  <a href="#name-recognizer-result-data" class="xref">Recognizer Result Data</a></p></li>
<li id="section-boilerplate.3-280" class="toc"><p id="section-boilerplate.3-281"><a href="#section-9.5.3" class="xref">9.5.3</a>.  <a href="#name-enrollment-result-data" class="xref">Enrollment Result Data</a></p></li>
<li id="section-boilerplate.3-282" class="toc"><p id="section-boilerplate.3-283"><a href="#section-9.5.4" class="xref">9.5.4</a>.  <a href="#name-recognizer-context-block-2" class="xref">Recognizer Context Block</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-284" class="toc">
<p id="section-boilerplate.3-285"><a href="#section-9.6" class="xref">9.6</a>.  <a href="#name-recognizer-results" class="xref">Recognizer Results</a></p>
<ul class="toc">
<li id="section-boilerplate.3-287" class="toc"><p id="section-boilerplate.3-288"><a href="#section-9.6.1" class="xref">9.6.1</a>.  <a href="#name-markup-functions" class="xref">Markup Functions</a></p></li>
<li id="section-boilerplate.3-289" class="toc"><p id="section-boilerplate.3-290"><a href="#section-9.6.2" class="xref">9.6.2</a>.  <a href="#name-overview-of-recognizer-resu" class="xref">Overview of Recognizer Result Elements and Their Relationships</a></p></li>
<li id="section-boilerplate.3-291" class="toc"><p id="section-boilerplate.3-292"><a href="#section-9.6.3" class="xref">9.6.3</a>.  <a href="#name-elements-and-attributes" class="xref">Elements and Attributes</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-293" class="toc">
<p id="section-boilerplate.3-294"><a href="#section-9.7" class="xref">9.7</a>.  <a href="#name-enrollment-results" class="xref">Enrollment Results</a></p>
<ul class="toc">
<li id="section-boilerplate.3-296" class="toc"><p id="section-boilerplate.3-297"><a href="#section-9.7.1" class="xref">9.7.1</a>.  <a href="#name-num-clashes-element" class="xref">&lt;num-clashes&gt; Element</a></p></li>
<li id="section-boilerplate.3-298" class="toc"><p id="section-boilerplate.3-299"><a href="#section-9.7.2" class="xref">9.7.2</a>.  <a href="#name-num-good-repetitions-elemen" class="xref">&lt;num-good-repetitions&gt; Element</a></p></li>
<li id="section-boilerplate.3-300" class="toc"><p id="section-boilerplate.3-301"><a href="#section-9.7.3" class="xref">9.7.3</a>.  <a href="#name-num-repetitions-still-neede" class="xref">&lt;num-repetitions-still-needed&gt; Element</a></p></li>
<li id="section-boilerplate.3-302" class="toc"><p id="section-boilerplate.3-303"><a href="#section-9.7.4" class="xref">9.7.4</a>.  <a href="#name-consistency-status-element" class="xref">&lt;consistency-status&gt; Element</a></p></li>
<li id="section-boilerplate.3-304" class="toc"><p id="section-boilerplate.3-305"><a href="#section-9.7.5" class="xref">9.7.5</a>.  <a href="#name-clash-phrase-ids-element" class="xref">&lt;clash-phrase-ids&gt; Element</a></p></li>
<li id="section-boilerplate.3-306" class="toc"><p id="section-boilerplate.3-307"><a href="#section-9.7.6" class="xref">9.7.6</a>.  <a href="#name-transcriptions-element" class="xref">&lt;transcriptions&gt; Element</a></p></li>
<li id="section-boilerplate.3-308" class="toc"><p id="section-boilerplate.3-309"><a href="#section-9.7.7" class="xref">9.7.7</a>.  <a href="#name-confusable-phrases-element" class="xref">&lt;confusable-phrases&gt; Element</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-310" class="toc"><p id="section-boilerplate.3-311"><a href="#section-9.8" class="xref">9.8</a>.  <a href="#name-define-grammar" class="xref">DEFINE-GRAMMAR</a></p></li>
<li id="section-boilerplate.3-312" class="toc"><p id="section-boilerplate.3-313"><a href="#section-9.9" class="xref">9.9</a>.  <a href="#name-recognize" class="xref">RECOGNIZE</a></p></li>
<li id="section-boilerplate.3-314" class="toc"><p id="section-boilerplate.3-315"><a href="#section-9.10" class="xref">9.10</a>.  <a href="#name-stop-2" class="xref">STOP</a></p></li>
<li id="section-boilerplate.3-316" class="toc"><p id="section-boilerplate.3-317"><a href="#section-9.11" class="xref">9.11</a>.  <a href="#name-get-result" class="xref">GET-RESULT</a></p></li>
<li id="section-boilerplate.3-318" class="toc"><p id="section-boilerplate.3-319"><a href="#section-9.12" class="xref">9.12</a>.  <a href="#name-start-of-input" class="xref">START-OF-INPUT</a></p></li>
<li id="section-boilerplate.3-320" class="toc"><p id="section-boilerplate.3-321"><a href="#section-9.13" class="xref">9.13</a>.  <a href="#name-start-input-timers-2" class="xref">START-INPUT-TIMERS</a></p></li>
<li id="section-boilerplate.3-322" class="toc"><p id="section-boilerplate.3-323"><a href="#section-9.14" class="xref">9.14</a>.  <a href="#name-recognition-complete" class="xref">RECOGNITION-COMPLETE</a></p></li>
<li id="section-boilerplate.3-324" class="toc"><p id="section-boilerplate.3-325"><a href="#section-9.15" class="xref">9.15</a>.  <a href="#name-start-phrase-enrollment" class="xref">START-PHRASE-ENROLLMENT</a></p></li>
<li id="section-boilerplate.3-326" class="toc"><p id="section-boilerplate.3-327"><a href="#section-9.16" class="xref">9.16</a>.  <a href="#name-enrollment-rollback" class="xref">ENROLLMENT-ROLLBACK</a></p></li>
<li id="section-boilerplate.3-328" class="toc"><p id="section-boilerplate.3-329"><a href="#section-9.17" class="xref">9.17</a>.  <a href="#name-end-phrase-enrollment" class="xref">END-PHRASE-ENROLLMENT</a></p></li>
<li id="section-boilerplate.3-330" class="toc"><p id="section-boilerplate.3-331"><a href="#section-9.18" class="xref">9.18</a>.  <a href="#name-modify-phrase" class="xref">MODIFY-PHRASE</a></p></li>
<li id="section-boilerplate.3-332" class="toc"><p id="section-boilerplate.3-333"><a href="#section-9.19" class="xref">9.19</a>.  <a href="#name-delete-phrase" class="xref">DELETE-PHRASE</a></p></li>
<li id="section-boilerplate.3-334" class="toc"><p id="section-boilerplate.3-335"><a href="#section-9.20" class="xref">9.20</a>.  <a href="#name-interpret" class="xref">INTERPRET</a></p></li>
<li id="section-boilerplate.3-336" class="toc"><p id="section-boilerplate.3-337"><a href="#section-9.21" class="xref">9.21</a>.  <a href="#name-interpretation-complete" class="xref">INTERPRETATION-COMPLETE</a></p></li>
<li id="section-boilerplate.3-338" class="toc"><p id="section-boilerplate.3-339"><a href="#section-9.22" class="xref">9.22</a>.  <a href="#name-dtmf-detection" class="xref">DTMF Detection</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-340" class="toc">
<p id="section-boilerplate.3-341"><a href="#section-10" class="xref">10</a>.  <a href="#name-recorder-resource" class="xref">Recorder Resource</a></p>
<ul class="toc">
<li id="section-boilerplate.3-343" class="toc"><p id="section-boilerplate.3-344"><a href="#section-10.1" class="xref">10.1</a>.  <a href="#name-recorder-state-machine" class="xref">Recorder State Machine</a></p></li>
<li id="section-boilerplate.3-345" class="toc"><p id="section-boilerplate.3-346"><a href="#section-10.2" class="xref">10.2</a>.  <a href="#name-recorder-methods" class="xref">Recorder Methods</a></p></li>
<li id="section-boilerplate.3-347" class="toc"><p id="section-boilerplate.3-348"><a href="#section-10.3" class="xref">10.3</a>.  <a href="#name-recorder-events" class="xref">Recorder Events</a></p></li>
<li id="section-boilerplate.3-349" class="toc">
<p id="section-boilerplate.3-350"><a href="#section-10.4" class="xref">10.4</a>.  <a href="#name-recorder-header-fields" class="xref">Recorder Header Fields</a></p>
<ul class="toc">
<li id="section-boilerplate.3-352" class="toc"><p id="section-boilerplate.3-353"><a href="#section-10.4.1" class="xref">10.4.1</a>.  <a href="#name-sensitivity-level-2" class="xref">Sensitivity-Level</a></p></li>
<li id="section-boilerplate.3-354" class="toc"><p id="section-boilerplate.3-355"><a href="#section-10.4.2" class="xref">10.4.2</a>.  <a href="#name-no-input-timeout-2" class="xref">No-Input-Timeout</a></p></li>
<li id="section-boilerplate.3-356" class="toc"><p id="section-boilerplate.3-357"><a href="#section-10.4.3" class="xref">10.4.3</a>.  <a href="#name-completion-cause-3" class="xref">Completion-Cause</a></p></li>
<li id="section-boilerplate.3-358" class="toc"><p id="section-boilerplate.3-359"><a href="#section-10.4.4" class="xref">10.4.4</a>.  <a href="#name-completion-reason-3" class="xref">Completion-Reason</a></p></li>
<li id="section-boilerplate.3-360" class="toc"><p id="section-boilerplate.3-361"><a href="#section-10.4.5" class="xref">10.4.5</a>.  <a href="#name-failed-uri-3" class="xref">Failed-URI</a></p></li>
<li id="section-boilerplate.3-362" class="toc"><p id="section-boilerplate.3-363"><a href="#section-10.4.6" class="xref">10.4.6</a>.  <a href="#name-failed-uri-cause-3" class="xref">Failed-URI-Cause</a></p></li>
<li id="section-boilerplate.3-364" class="toc"><p id="section-boilerplate.3-365"><a href="#section-10.4.7" class="xref">10.4.7</a>.  <a href="#name-record-uri" class="xref">Record-URI</a></p></li>
<li id="section-boilerplate.3-366" class="toc"><p id="section-boilerplate.3-367"><a href="#section-10.4.8" class="xref">10.4.8</a>.  <a href="#name-media-type-2" class="xref">Media-Type</a></p></li>
<li id="section-boilerplate.3-368" class="toc"><p id="section-boilerplate.3-369"><a href="#section-10.4.9" class="xref">10.4.9</a>.  <a href="#name-max-time" class="xref">Max-Time</a></p></li>
<li id="section-boilerplate.3-370" class="toc"><p id="section-boilerplate.3-371"><a href="#section-10.4.10" class="xref">10.4.10</a>.  <a href="#name-trim-length" class="xref">Trim-Length</a></p></li>
<li id="section-boilerplate.3-372" class="toc"><p id="section-boilerplate.3-373"><a href="#section-10.4.11" class="xref">10.4.11</a>.  <a href="#name-final-silence" class="xref">Final-Silence</a></p></li>
<li id="section-boilerplate.3-374" class="toc"><p id="section-boilerplate.3-375"><a href="#section-10.4.12" class="xref">10.4.12</a>.  <a href="#name-capture-on-speech" class="xref">Capture-On-Speech</a></p></li>
<li id="section-boilerplate.3-376" class="toc"><p id="section-boilerplate.3-377"><a href="#section-10.4.13" class="xref">10.4.13</a>.  <a href="#name-ver-buffer-utterance-2" class="xref">Ver-Buffer-Utterance</a></p></li>
<li id="section-boilerplate.3-378" class="toc"><p id="section-boilerplate.3-379"><a href="#section-10.4.14" class="xref">10.4.14</a>.  <a href="#name-start-input-timers-3" class="xref">Start-Input-Timers</a></p></li>
<li id="section-boilerplate.3-380" class="toc"><p id="section-boilerplate.3-381"><a href="#section-10.4.15" class="xref">10.4.15</a>.  <a href="#name-new-audio-channel-2" class="xref">New-Audio-Channel</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-382" class="toc"><p id="section-boilerplate.3-383"><a href="#section-10.5" class="xref">10.5</a>.  <a href="#name-recorder-message-body" class="xref">Recorder Message Body</a></p></li>
<li id="section-boilerplate.3-384" class="toc"><p id="section-boilerplate.3-385"><a href="#section-10.6" class="xref">10.6</a>.  <a href="#name-record" class="xref">RECORD</a></p></li>
<li id="section-boilerplate.3-386" class="toc"><p id="section-boilerplate.3-387"><a href="#section-10.7" class="xref">10.7</a>.  <a href="#name-stop-3" class="xref">STOP</a></p></li>
<li id="section-boilerplate.3-388" class="toc"><p id="section-boilerplate.3-389"><a href="#section-10.8" class="xref">10.8</a>.  <a href="#name-record-complete" class="xref">RECORD-COMPLETE</a></p></li>
<li id="section-boilerplate.3-390" class="toc"><p id="section-boilerplate.3-391"><a href="#section-10.9" class="xref">10.9</a>.  <a href="#name-start-input-timers-4" class="xref">START-INPUT-TIMERS</a></p></li>
<li id="section-boilerplate.3-392" class="toc"><p id="section-boilerplate.3-393"><a href="#section-10.10" class="xref">10.10</a>.  <a href="#name-start-of-input-2" class="xref">START-OF-INPUT</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-394" class="toc">
<p id="section-boilerplate.3-395"><a href="#section-11" class="xref">11</a>.  <a href="#name-speaker-verification-and-id" class="xref">Speaker Verification and Identification</a></p>
<ul class="toc">
<li id="section-boilerplate.3-397" class="toc"><p id="section-boilerplate.3-398"><a href="#section-11.1" class="xref">11.1</a>.  <a href="#name-speaker-verification-state-" class="xref">Speaker Verification State Machine</a></p></li>
<li id="section-boilerplate.3-399" class="toc"><p id="section-boilerplate.3-400"><a href="#section-11.2" class="xref">11.2</a>.  <a href="#name-speaker-verification-method" class="xref">Speaker Verification Methods</a></p></li>
<li id="section-boilerplate.3-401" class="toc"><p id="section-boilerplate.3-402"><a href="#section-11.3" class="xref">11.3</a>.  <a href="#name-verification-events" class="xref">Verification Events</a></p></li>
<li id="section-boilerplate.3-403" class="toc">
<p id="section-boilerplate.3-404"><a href="#section-11.4" class="xref">11.4</a>.  <a href="#name-verification-header-fields" class="xref">Verification Header Fields</a></p>
<ul class="toc">
<li id="section-boilerplate.3-406" class="toc"><p id="section-boilerplate.3-407"><a href="#section-11.4.1" class="xref">11.4.1</a>.  <a href="#name-repository-uri" class="xref">Repository-URI</a></p></li>
<li id="section-boilerplate.3-408" class="toc"><p id="section-boilerplate.3-409"><a href="#section-11.4.2" class="xref">11.4.2</a>.  <a href="#name-voiceprint-identifier" class="xref">Voiceprint-Identifier</a></p></li>
<li id="section-boilerplate.3-410" class="toc"><p id="section-boilerplate.3-411"><a href="#section-11.4.3" class="xref">11.4.3</a>.  <a href="#name-verification-mode" class="xref">Verification-Mode</a></p></li>
<li id="section-boilerplate.3-412" class="toc"><p id="section-boilerplate.3-413"><a href="#section-11.4.4" class="xref">11.4.4</a>.  <a href="#name-adapt-model" class="xref">Adapt-Model</a></p></li>
<li id="section-boilerplate.3-414" class="toc"><p id="section-boilerplate.3-415"><a href="#section-11.4.5" class="xref">11.4.5</a>.  <a href="#name-abort-model" class="xref">Abort-Model</a></p></li>
<li id="section-boilerplate.3-416" class="toc"><p id="section-boilerplate.3-417"><a href="#section-11.4.6" class="xref">11.4.6</a>.  <a href="#name-min-verification-score" class="xref">Min-Verification-Score</a></p></li>
<li id="section-boilerplate.3-418" class="toc"><p id="section-boilerplate.3-419"><a href="#section-11.4.7" class="xref">11.4.7</a>.  <a href="#name-num-min-verification-phrase" class="xref">Num-Min-Verification-Phrases</a></p></li>
<li id="section-boilerplate.3-420" class="toc"><p id="section-boilerplate.3-421"><a href="#section-11.4.8" class="xref">11.4.8</a>.  <a href="#name-num-max-verification-phrase" class="xref">Num-Max-Verification-Phrases</a></p></li>
<li id="section-boilerplate.3-422" class="toc"><p id="section-boilerplate.3-423"><a href="#section-11.4.9" class="xref">11.4.9</a>.  <a href="#name-no-input-timeout-3" class="xref">No-Input-Timeout</a></p></li>
<li id="section-boilerplate.3-424" class="toc"><p id="section-boilerplate.3-425"><a href="#section-11.4.10" class="xref">11.4.10</a>.  <a href="#name-save-waveform-2" class="xref">Save-Waveform</a></p></li>
<li id="section-boilerplate.3-426" class="toc"><p id="section-boilerplate.3-427"><a href="#section-11.4.11" class="xref">11.4.11</a>.  <a href="#name-media-type-3" class="xref">Media-Type</a></p></li>
<li id="section-boilerplate.3-428" class="toc"><p id="section-boilerplate.3-429"><a href="#section-11.4.12" class="xref">11.4.12</a>.  <a href="#name-waveform-uri-2" class="xref">Waveform-URI</a></p></li>
<li id="section-boilerplate.3-430" class="toc"><p id="section-boilerplate.3-431"><a href="#section-11.4.13" class="xref">11.4.13</a>.  <a href="#name-voiceprint-exists" class="xref">Voiceprint-Exists</a></p></li>
<li id="section-boilerplate.3-432" class="toc"><p id="section-boilerplate.3-433"><a href="#section-11.4.14" class="xref">11.4.14</a>.  <a href="#name-ver-buffer-utterance-3" class="xref">Ver-Buffer-Utterance</a></p></li>
<li id="section-boilerplate.3-434" class="toc"><p id="section-boilerplate.3-435"><a href="#section-11.4.15" class="xref">11.4.15</a>.  <a href="#name-input-waveform-uri-2" class="xref">Input-Waveform-URI</a></p></li>
<li id="section-boilerplate.3-436" class="toc"><p id="section-boilerplate.3-437"><a href="#section-11.4.16" class="xref">11.4.16</a>.  <a href="#name-completion-cause-4" class="xref">Completion-Cause</a></p></li>
<li id="section-boilerplate.3-438" class="toc"><p id="section-boilerplate.3-439"><a href="#section-11.4.17" class="xref">11.4.17</a>.  <a href="#name-completion-reason-4" class="xref">Completion-Reason</a></p></li>
<li id="section-boilerplate.3-440" class="toc"><p id="section-boilerplate.3-441"><a href="#section-11.4.18" class="xref">11.4.18</a>.  <a href="#name-speech-complete-timeout-2" class="xref">Speech-Complete-Timeout</a></p></li>
<li id="section-boilerplate.3-442" class="toc"><p id="section-boilerplate.3-443"><a href="#section-11.4.19" class="xref">11.4.19</a>.  <a href="#name-new-audio-channel-3" class="xref">New-Audio-Channel</a></p></li>
<li id="section-boilerplate.3-444" class="toc"><p id="section-boilerplate.3-445"><a href="#section-11.4.20" class="xref">11.4.20</a>.  <a href="#name-abort-verification" class="xref">Abort-Verification</a></p></li>
<li id="section-boilerplate.3-446" class="toc"><p id="section-boilerplate.3-447"><a href="#section-11.4.21" class="xref">11.4.21</a>.  <a href="#name-start-input-timers-5" class="xref">Start-Input-Timers</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-448" class="toc">
<p id="section-boilerplate.3-449"><a href="#section-11.5" class="xref">11.5</a>.  <a href="#name-verification-message-body" class="xref">Verification Message Body</a></p>
<ul class="toc">
<li id="section-boilerplate.3-451" class="toc"><p id="section-boilerplate.3-452"><a href="#section-11.5.1" class="xref">11.5.1</a>.  <a href="#name-verification-result-data" class="xref">Verification Result Data</a></p></li>
<li id="section-boilerplate.3-453" class="toc"><p id="section-boilerplate.3-454"><a href="#section-11.5.2" class="xref">11.5.2</a>.  <a href="#name-verification-result-element" class="xref">Verification Result Elements</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-455" class="toc"><p id="section-boilerplate.3-456"><a href="#section-11.6" class="xref">11.6</a>.  <a href="#name-start-session" class="xref">START-SESSION</a></p></li>
<li id="section-boilerplate.3-457" class="toc"><p id="section-boilerplate.3-458"><a href="#section-11.7" class="xref">11.7</a>.  <a href="#name-end-session" class="xref">END-SESSION</a></p></li>
<li id="section-boilerplate.3-459" class="toc"><p id="section-boilerplate.3-460"><a href="#section-11.8" class="xref">11.8</a>.  <a href="#name-query-voiceprint" class="xref">QUERY-VOICEPRINT</a></p></li>
<li id="section-boilerplate.3-461" class="toc"><p id="section-boilerplate.3-462"><a href="#section-11.9" class="xref">11.9</a>.  <a href="#name-delete-voiceprint" class="xref">DELETE-VOICEPRINT</a></p></li>
<li id="section-boilerplate.3-463" class="toc"><p id="section-boilerplate.3-464"><a href="#section-11.10" class="xref">11.10</a>.  <a href="#name-verify" class="xref">VERIFY</a></p></li>
<li id="section-boilerplate.3-465" class="toc"><p id="section-boilerplate.3-466"><a href="#section-11.11" class="xref">11.11</a>.  <a href="#name-verify-from-buffer" class="xref">VERIFY-FROM-BUFFER</a></p></li>
<li id="section-boilerplate.3-467" class="toc"><p id="section-boilerplate.3-468"><a href="#section-11.12" class="xref">11.12</a>.  <a href="#name-verify-rollback" class="xref">VERIFY-ROLLBACK</a></p></li>
<li id="section-boilerplate.3-469" class="toc"><p id="section-boilerplate.3-470"><a href="#section-11.13" class="xref">11.13</a>.  <a href="#name-stop-4" class="xref">STOP</a></p></li>
<li id="section-boilerplate.3-471" class="toc"><p id="section-boilerplate.3-472"><a href="#section-11.14" class="xref">11.14</a>.  <a href="#name-start-input-timers-6" class="xref">START-INPUT-TIMERS</a></p></li>
<li id="section-boilerplate.3-473" class="toc"><p id="section-boilerplate.3-474"><a href="#section-11.15" class="xref">11.15</a>.  <a href="#name-verification-complete" class="xref">VERIFICATION-COMPLETE</a></p></li>
<li id="section-boilerplate.3-475" class="toc"><p id="section-boilerplate.3-476"><a href="#section-11.16" class="xref">11.16</a>.  <a href="#name-start-of-input-3" class="xref">START-OF-INPUT</a></p></li>
<li id="section-boilerplate.3-477" class="toc"><p id="section-boilerplate.3-478"><a href="#section-11.17" class="xref">11.17</a>.  <a href="#name-clear-buffer" class="xref">CLEAR-BUFFER</a></p></li>
<li id="section-boilerplate.3-479" class="toc"><p id="section-boilerplate.3-480"><a href="#section-11.18" class="xref">11.18</a>.  <a href="#name-get-intermediate-result" class="xref">GET-INTERMEDIATE-RESULT</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-481" class="toc">
<p id="section-boilerplate.3-482"><a href="#section-12" class="xref">12</a>.  <a href="#name-security-considerations" class="xref">Security Considerations</a></p>
<ul class="toc">
<li id="section-boilerplate.3-484" class="toc"><p id="section-boilerplate.3-485"><a href="#section-12.1" class="xref">12.1</a>.  <a href="#name-rendezvous-and-session-esta" class="xref">Rendezvous and Session Establishment</a></p></li>
<li id="section-boilerplate.3-486" class="toc"><p id="section-boilerplate.3-487"><a href="#section-12.2" class="xref">12.2</a>.  <a href="#name-control-channel-protection" class="xref">Control Channel Protection</a></p></li>
<li id="section-boilerplate.3-488" class="toc"><p id="section-boilerplate.3-489"><a href="#section-12.3" class="xref">12.3</a>.  <a href="#name-media-session-protection" class="xref">Media Session Protection</a></p></li>
<li id="section-boilerplate.3-490" class="toc"><p id="section-boilerplate.3-491"><a href="#section-12.4" class="xref">12.4</a>.  <a href="#name-indirect-content-access" class="xref">Indirect Content Access</a></p></li>
<li id="section-boilerplate.3-492" class="toc"><p id="section-boilerplate.3-493"><a href="#section-12.5" class="xref">12.5</a>.  <a href="#name-protection-of-stored-media" class="xref">Protection of Stored Media</a></p></li>
<li id="section-boilerplate.3-494" class="toc"><p id="section-boilerplate.3-495"><a href="#section-12.6" class="xref">12.6</a>.  <a href="#name-dtmf-and-recognition-buffer" class="xref">DTMF and Recognition Buffers</a></p></li>
<li id="section-boilerplate.3-496" class="toc"><p id="section-boilerplate.3-497"><a href="#section-12.7" class="xref">12.7</a>.  <a href="#name-client-set-server-parameter" class="xref">Client-Set Server Parameters</a></p></li>
<li id="section-boilerplate.3-498" class="toc"><p id="section-boilerplate.3-499"><a href="#section-12.8" class="xref">12.8</a>.  <a href="#name-delete-voiceprint-and-autho" class="xref">DELETE-VOICEPRINT and Authorization</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-500" class="toc">
<p id="section-boilerplate.3-501"><a href="#section-13" class="xref">13</a>.  <a href="#name-iana-considerations" class="xref">IANA Considerations</a></p>
<ul class="toc">
<li id="section-boilerplate.3-503" class="toc">
<p id="section-boilerplate.3-504"><a href="#section-13.1" class="xref">13.1</a>.  <a href="#name-new-registries" class="xref">New Registries</a></p>
<ul class="toc">
<li id="section-boilerplate.3-506" class="toc"><p id="section-boilerplate.3-507"><a href="#section-13.1.1" class="xref">13.1.1</a>.  <a href="#name-mrcpv2-resource-types" class="xref">MRCPv2 Resource Types</a></p></li>
<li id="section-boilerplate.3-508" class="toc"><p id="section-boilerplate.3-509"><a href="#section-13.1.2" class="xref">13.1.2</a>.  <a href="#name-mrcpv2-methods-and-events" class="xref">MRCPv2 Methods and Events</a></p></li>
<li id="section-boilerplate.3-510" class="toc"><p id="section-boilerplate.3-511"><a href="#section-13.1.3" class="xref">13.1.3</a>.  <a href="#name-mrcpv2-header-fields" class="xref">MRCPv2 Header Fields</a></p></li>
<li id="section-boilerplate.3-512" class="toc"><p id="section-boilerplate.3-513"><a href="#section-13.1.4" class="xref">13.1.4</a>.  <a href="#name-mrcpv2-status-codes" class="xref">MRCPv2 Status Codes</a></p></li>
<li id="section-boilerplate.3-514" class="toc"><p id="section-boilerplate.3-515"><a href="#section-13.1.5" class="xref">13.1.5</a>.  <a href="#name-grammar-reference-list-para" class="xref">Grammar Reference List Parameters</a></p></li>
<li id="section-boilerplate.3-516" class="toc"><p id="section-boilerplate.3-517"><a href="#section-13.1.6" class="xref">13.1.6</a>.  <a href="#name-mrcpv2-vendor-specific-para" class="xref">MRCPv2 Vendor-Specific Parameters</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-518" class="toc">
<p id="section-boilerplate.3-519"><a href="#section-13.2" class="xref">13.2</a>.  <a href="#name-nlsml-related-registrations" class="xref">NLSML-Related Registrations</a></p>
<ul class="toc"><li id="section-boilerplate.3-521" class="toc"><p id="section-boilerplate.3-522"><a href="#section-13.2.1" class="xref">13.2.1</a>.  <a href="#name-application-nlsmlxml-media-" class="xref">'application/nlsml+xml' Media Type Registration</a></p></li></ul>
</li>
<li id="section-boilerplate.3-523" class="toc"><p id="section-boilerplate.3-524"><a href="#section-13.3" class="xref">13.3</a>.  <a href="#name-nlsml-xml-schema-registrati" class="xref">NLSML XML Schema Registration</a></p></li>
<li id="section-boilerplate.3-525" class="toc"><p id="section-boilerplate.3-526"><a href="#section-13.4" class="xref">13.4</a>.  <a href="#name-mrcpv2-xml-namespace-regist" class="xref">MRCPv2 XML Namespace Registration</a></p></li>
<li id="section-boilerplate.3-527" class="toc">
<p id="section-boilerplate.3-528"><a href="#section-13.5" class="xref">13.5</a>.  <a href="#name-text-media-type-registratio" class="xref">Text Media Type Registrations</a></p>
<ul class="toc"><li id="section-boilerplate.3-530" class="toc"><p id="section-boilerplate.3-531"><a href="#section-13.5.1" class="xref">13.5.1</a>.  <a href="#name-text-grammar-ref-list" class="xref">text/grammar-ref-list</a></p></li></ul>
</li>
<li id="section-boilerplate.3-532" class="toc"><p id="section-boilerplate.3-533"><a href="#section-13.6" class="xref">13.6</a>.  <a href="#name-session-uri-scheme-registra" class="xref">'session' URI Scheme Registration</a></p></li>
<li id="section-boilerplate.3-534" class="toc">
<p id="section-boilerplate.3-535"><a href="#section-13.7" class="xref">13.7</a>.  <a href="#name-sdp-parameter-registrations" class="xref">SDP Parameter Registrations</a></p>
<ul class="toc">
<li id="section-boilerplate.3-537" class="toc"><p id="section-boilerplate.3-538"><a href="#section-13.7.1" class="xref">13.7.1</a>.  <a href="#name-sub-registry-proto" class="xref">Sub-Registry "proto"</a></p></li>
<li id="section-boilerplate.3-539" class="toc"><p id="section-boilerplate.3-540"><a href="#section-13.7.2" class="xref">13.7.2</a>.  <a href="#name-sub-registry-att-field-medi" class="xref">Sub-Registry "att-field (media-level)"</a></p></li>
</ul>
</li>
</ul>
</li>
<li id="section-boilerplate.3-541" class="toc">
<p id="section-boilerplate.3-542"><a href="#section-14" class="xref">14</a>.  <a href="#name-examples" class="xref">Examples</a></p>
<ul class="toc">
<li id="section-boilerplate.3-544" class="toc"><p id="section-boilerplate.3-545"><a href="#section-14.1" class="xref">14.1</a>.  <a href="#name-message-flow" class="xref">Message Flow</a></p></li>
<li id="section-boilerplate.3-546" class="toc">
<p id="section-boilerplate.3-547"><a href="#section-14.2" class="xref">14.2</a>.  <a href="#name-recognition-result-examples" class="xref">Recognition Result Examples</a></p>
<ul class="toc">
<li id="section-boilerplate.3-549" class="toc"><p id="section-boilerplate.3-550"><a href="#section-14.2.1" class="xref">14.2.1</a>.  <a href="#name-simple-asr-ambiguity" class="xref">Simple ASR Ambiguity</a></p></li>
<li id="section-boilerplate.3-551" class="toc"><p id="section-boilerplate.3-552"><a href="#section-14.2.2" class="xref">14.2.2</a>.  <a href="#name-mixed-initiative" class="xref">Mixed Initiative</a></p></li>
<li id="section-boilerplate.3-553" class="toc"><p id="section-boilerplate.3-554"><a href="#section-14.2.3" class="xref">14.2.3</a>.  <a href="#name-dtmf-input" class="xref">DTMF Input</a></p></li>
<li id="section-boilerplate.3-555" class="toc"><p id="section-boilerplate.3-556"><a href="#section-14.2.4" class="xref">14.2.4</a>.  <a href="#name-interpreting-meta-dialog-an" class="xref">Interpreting Meta-Dialog and Meta-Task Utterances</a></p></li>
<li id="section-boilerplate.3-557" class="toc"><p id="section-boilerplate.3-558"><a href="#section-14.2.5" class="xref">14.2.5</a>.  <a href="#name-anaphora-and-deixis" class="xref">Anaphora and Deixis</a></p></li>
<li id="section-boilerplate.3-559" class="toc"><p id="section-boilerplate.3-560"><a href="#section-14.2.6" class="xref">14.2.6</a>.  <a href="#name-distinguishing-individual-i" class="xref">Distinguishing Individual Items from Sets with One Member</a></p></li>
<li id="section-boilerplate.3-561" class="toc"><p id="section-boilerplate.3-562"><a href="#section-14.2.7" class="xref">14.2.7</a>.  <a href="#name-extensibility" class="xref">Extensibility</a></p></li>
</ul>
</li>
</ul>
</li>
<li id="section-boilerplate.3-563" class="toc"><p id="section-boilerplate.3-564"><a href="#section-15" class="xref">15</a>.  <a href="#name-abnf-normative-definition" class="xref">ABNF Normative Definition</a></p></li>
<li id="section-boilerplate.3-565" class="toc">
<p id="section-boilerplate.3-566"><a href="#section-16" class="xref">16</a>.  <a href="#name-xml-schemas" class="xref">XML Schemas</a></p>
<ul class="toc">
<li id="section-boilerplate.3-568" class="toc"><p id="section-boilerplate.3-569"><a href="#section-16.1" class="xref">16.1</a>.  <a href="#name-nlsml-schema-definition" class="xref">NLSML Schema Definition</a></p></li>
<li id="section-boilerplate.3-570" class="toc"><p id="section-boilerplate.3-571"><a href="#section-16.2" class="xref">16.2</a>.  <a href="#name-enrollment-results-schema-d" class="xref">Enrollment Results Schema Definition</a></p></li>
<li id="section-boilerplate.3-572" class="toc"><p id="section-boilerplate.3-573"><a href="#section-16.3" class="xref">16.3</a>.  <a href="#name-verification-results-schema" class="xref">Verification Results Schema Definition</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-574" class="toc">
<p id="section-boilerplate.3-575"><a href="#section-17" class="xref">17</a>.  <a href="#name-references" class="xref">References</a></p>
<ul class="toc">
<li id="section-boilerplate.3-577" class="toc"><p id="section-boilerplate.3-578"><a href="#section-17.1" class="xref">17.1</a>.  <a href="#name-normative-references" class="xref">Normative References</a></p></li>
<li id="section-boilerplate.3-579" class="toc"><p id="section-boilerplate.3-580"><a href="#section-17.2" class="xref">17.2</a>.  <a href="#name-informative-references" class="xref">Informative References</a></p></li>
</ul>
</li>
<li id="section-boilerplate.3-581" class="toc"><p id="section-boilerplate.3-582"><a href="#section-appendix.a" class="xref">Appendix A</a>.  <a href="#name-contributors" class="xref">Contributors</a></p></li>
<li id="section-boilerplate.3-583" class="toc"><p id="section-boilerplate.3-584"><a href="#section-appendix.b" class="xref">Appendix B</a>.  <a href="#name-acknowledgements" class="xref">Acknowledgements</a></p></li>
<li id="section-boilerplate.3-585" class="toc"><p id="section-boilerplate.3-586"><a href="#section-appendix.c" class="xref"></a>  <a href="#name-authors-addresses" class="xref">Authors' Addresses</a></p></li>
</ul></nav>
</div></section><section id="section-1"><h2 id="name-introduction">
<a href="#section-1" class="section-number selfRef">1.Â </a><a href="#name-introduction" class="section-name selfRef">Introduction</a>
</h2>
<p id="section-1-1">MRCPv2 is designed to allow a client device to
      control media processing resources on the network. Some of these
      media processing resources include speech recognition engines,
      speech synthesis engines, speaker verification, and speaker
      identification engines. MRCPv2 enables the implementation of
      distributed Interactive Voice Response platforms
      using <span>[<a href="#W3C.REC-voicexml20-20040316" class="xref">VoiceXML</a>]
      browsers or other client applications while maintaining separate
      back-end speech processing capabilities on specialized speech
      processing servers. MRCPv2 is based on the
      earlier </span><span>[<a href="#RFC4463" class="xref">Media Resource Control Protocol
      (MRCP)</a>] developed jointly by Cisco Systems, Inc., Nuance
      Communications, and Speechworks, Inc.  Although some of the
      method names are similar, the way in which these methods are
      communicated is different.  There are also more resources and
      more methods for each resource.  The first version of MRCP was
      essentially taken only as input to the development of this
      protocol.  There is no expectation that an MRCPv2 client will
      work with an MRCPv1 server or vice versa.  There is no migration
      plan or gateway definition between the two protocols.</span></p>
<p id="section-1-2">The protocol requirements of Speech Services Control (SPEECHSC) <span>[<a href="#RFC4313" class="xref">RFC4313</a>]
      include that the solution be capable of reaching a media processing
      server, setting up communication channels to the media resources, and
      sending and receiving control messages and media streams to/from the
      server. The </span><span>[<a href="#RFC3261" class="xref">Session Initiation Protocol
      (SIP)</a>] meets these requirements.</span></p>
<p id="section-1-3">The proprietary version of MRCP ran over the <span>[<a href="#RFC2326" class="xref">Real Time Streaming Protocol (RTSP)</a>]. At the time
      work on MRCPv2 was begun, the consensus was that this use of RTSP would
      break the RTSP protocol or cause backward-compatibility problems,
      something forbidden by Section 3.2 of </span><span>[<a href="#RFC4313" class="xref">RFC4313</a>]. 
      This is the reason why MRCPv2 does not run over RTSP.</span></p>
<p id="section-1-4">MRCPv2 leverages these capabilities by building upon SIP and the
      <span>[<a href="#RFC4566" class="xref">Session Description Protocol (SDP)</a>]. MRCPv2
      uses SIP to set up and tear down media and control sessions with the
      server. In addition, the client can use a SIP re-INVITE method (an
      INVITE dialog sent within an existing SIP session) to change the
      characteristics of these media and control session while maintaining the
      SIP dialog between the client and server. SDP is used to describe the
      parameters of the media sessions associated with that dialog. It is
      mandatory to support SIP as the session establishment protocol to ensure
      interoperability. Other protocols can be used for session establishment
      by prior agreement. This document only describes the use of SIP and
      SDP.</span></p>
<p id="section-1-5">MRCPv2 uses SIP and SDP to create the speech client/server dialog and
      set up the media channels to the server. It also uses SIP and SDP to
      establish MRCPv2 control sessions between the client and the server for
      each media processing resource required for that dialog. The MRCPv2
      protocol exchange between the client and the media resource is carried
      on that control session. MRCPv2 exchanges do not change the
      state of the SIP dialog, the media sessions, or other parameters of the
      dialog initiated via SIP. It controls and affects the state of the media
      processing resource associated with the MRCPv2 session(s).</p>
<p id="section-1-6">MRCPv2 defines the messages to control the different media processing
      resources and the state machines required to guide their operation. It
      also describes how these messages are carried over a transport-layer
      protocol such as the <span>[<a href="#RFC0793" class="xref">Transmission Control
      Protocol (TCP)</a>] or the </span><span>[<a href="#RFC5246" class="xref">Transport Layer
      Security (TLS) Protocol</a>]. (Note: the </span><span>[<a href="#RFC4960" class="xref">Stream
      Control Transmission Protocol (SCTP)</a>] is a viable transport for
      MRCPv2 as well, but the mapping onto SCTP is not described in this
      specification.)</span></p></section><section id="section-2"><h2 id="name-document-conventions">
<a href="#section-2" class="section-number selfRef">2.Â </a><a href="#name-document-conventions" class="section-name selfRef">Document Conventions</a>
</h2>
<p id="section-2-1">The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
      "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
      document are to be interpreted as described in <span>[<a href="#RFC2119" class="xref">RFC 2119</a>].</span></p>
<p id="section-2-2">Since many of the definitions and syntax are identical to those for
      the <span>[<a href="#RFC2616" class="xref">Hypertext Transfer Protocol -- HTTP/1.1</a>], this specification refers to the section where they
      are defined rather than copying it. For brevity, [HX.Y] is to be taken
      to refer to Section X.Y of RFC 2616.</span></p>
<p id="section-2-3">All the mechanisms specified in this document are described in both
      prose and an augmented Backus-Naur form (<span>[<a href="#RFC5234" class="xref">ABNF</a>]).</span></p>
<p id="section-2-4">The complete message format in ABNF form is provided in <a href="#S.abnf" class="xref">Section 15</a> and is the normative format definition. Note
      that productions may be duplicated within the main body of the document
      for reading convenience. If a production in the body of the text
      conflicts with one in the normative definition, the latter rules.</p>
<section id="section-2.1"><h3 id="name-definitions">
<a href="#section-2.1" class="section-number selfRef">2.1.Â </a><a href="#name-definitions" class="section-name selfRef">Definitions</a>
</h3>
<dl id="section-2.1-1" class="dlNewline">
<dt id="section-2.1-2">Media Resource</dt>
<dd id="section-2.1-3">An entity on
            the speech processing server that can be controlled through 
            MRCPv2.</dd>
<dt id="section-2.1-4">MRCP Server</dt>
<dd id="section-2.1-5">
Aggregate of one or more "Media Resource" entities on
                a server, exposed through MRCPv2.  Often, 'server' in 
                this document refers to an MRCP server.</dd>
<dt id="section-2.1-6">MRCP Client</dt>
<dd id="section-2.1-7">An entity
            controlling one or more Media Resources through MRCPv2
            ("Client" for short).</dd>
<dt id="section-2.1-8">DTMF</dt>
<dd id="section-2.1-9">Dual-Tone
            Multi-Frequency; a method of transmitting key presses in-band,
            either as actual tones (<span>[<a href="#Q.23" class="xref">Q.23</a>]) or as
            named tone events (</span><span>[<a href="#RFC4733" class="xref">RFC 4733</a>]).</span>
</dd>
<dt id="section-2.1-10">Endpointing</dt>
<dd id="section-2.1-11">The process of
            automatically detecting the beginning and end of speech in an
            audio stream. This is critical both for speech recognition and for
            automated recording as one would find in voice mail systems.</dd>
<dt id="section-2.1-12">Hotword Mode</dt>
<dd id="section-2.1-13">A mode of
            speech recognition where a stream of utterances is evaluated for
            match against a small set of command words. This is generally
            employed either to trigger some action or to control the
            subsequent grammar to be used for further recognition.</dd>
</dl></section><section id="section-2.2"><h3 id="name-state-machine-diagrams">
<a href="#section-2.2" class="section-number selfRef">2.2.Â </a><a href="#name-state-machine-diagrams" class="section-name selfRef">State-Machine Diagrams</a>
</h3>
<p id="section-2.2-1">The state-machine diagrams in this document do not show every
        possible method call. Rather, they reflect the state of the resource
        based on the methods that have moved to IN-PROGRESS or COMPLETE states
        (see <a href="#sec.response" class="xref">Section 5.3</a>). Note that since PENDING
        requests essentially have not affected the resource yet and are in the
        queue to be processed, they are not reflected in the state-machine
        diagrams.</p></section><section id="section-2.3"><h3 id="name-uri-schemes">
<a href="#section-2.3" class="section-number selfRef">2.3.Â </a><a href="#name-uri-schemes" class="section-name selfRef">URI Schemes</a>
</h3>
<p id="section-2.3-1">This document defines many protocol headers that contain URIs
        (<span>[<a href="#RFC3986" class="xref">Uniform Resource Identifiers</a>]) or
        lists of URIs for referencing media. The entire document, including
        the Security Considerations section (</span><a href="#sec.securityConsiderations" class="xref">Section 12</a>), assumes that HTTP or
        <span>[<a href="#RFC2818" class="xref">HTTP over TLS (HTTPS)</a>] will be used as
        the URI addressing scheme unless otherwise stated. However,
        implementations MAY support other schemes (such as 'file'), provided
        they have addressed any security considerations described in this
        document and any others particular to the specific scheme. For
        example, implementations where the client and server both reside on
        the same physical hardware and the file system is secured by
        traditional user-level file access controls could be reasonable
        candidates for supporting the 'file' scheme.</span></p></section></section><section id="section-3"><h2 id="name-architecture">
<a href="#section-3" class="section-number selfRef">3.Â </a><a href="#name-architecture" class="section-name selfRef">Architecture</a>
</h2>
<p id="section-3-1">A system using MRCPv2 consists of a client that requires the
      generation and/or consumption of media streams and a media resource
      server that has the resources or "engines" to process these streams as
      input or generate these streams as output. The client uses SIP and SDP
      to establish an MRCPv2 control channel with the server to use its media
      processing resources. MRCPv2 servers are addressed using SIP URIs.</p>
<p id="section-3-2">SIP uses SDP with the offer/answer
      model described in <span>[<a href="#RFC3264" class="xref">RFC 3264</a>] to set up the
      MRCPv2 control channels and describe their characteristics. A separate
      MRCPv2 session is needed to control each of the media processing
      resources associated with the SIP dialog between the client and server.
      Within a SIP dialog, the individual resource control channels for the
      different resources are added or removed through SDP offer/answer
      carried in a SIP re-INVITE transaction.</span></p>
<p id="section-3-3">The server, through the SDP exchange, provides the client with a
      difficult-to-guess, unambiguous channel identifier and a TCP port number (see <a href="#sec.resourceControl" class="xref">Section 4.2</a>). The client MAY
      then open a new TCP connection with the server on this port number.
      Multiple MRCPv2 channels can share a TCP connection between the client
      and the server. All MRCPv2 messages exchanged between the client and the
      server carry the specified channel identifier that the server MUST
      ensure is unambiguous among all MRCPv2 control channels that are active
      on that server. The client uses this channel identifier to indicate the
      media processing resource associated with that channel. For information
      on message framing, see <a href="#sec.messages" class="xref">Section 5</a>.</p>
<p id="section-3-4">SIP also establishes the media
      sessions between the client (or other source/sink of media) and the
      MRCPv2 server using SDP "m=" lines. One or more media processing resources
      may share a media session under a SIP session, or each media processing
      resource may have its own media session.</p>
<p id="section-3-5">The following diagram shows the general architecture of a system that
      uses MRCPv2. To simplify the diagram, only a few resources are shown.</p>
<figure id="figure-1"><div id="F.arch"><div id="section-3-6" class="artwork art-text" text-align="left"><pre>
     MRCPv2 client                   MRCPv2 Media Resource Server
|--------------------|         |------------------------------------|
||------------------||         ||----------------------------------||
|| Application Layer||         ||Synthesis|Recognition|Verification||
||------------------||         || Engine  |  Engine   |   Engine   ||
||Media Resource API||         ||    ||   |    ||     |    ||      ||
||------------------||         ||Synthesis|Recognizer |  Verifier  ||
|| SIP  |  MRCPv2   ||         ||Resource | Resource  |  Resource  ||
||Stack |           ||         ||     Media Resource Management    ||
||      |           ||         ||----------------------------------||
||------------------||         ||   SIP  |        MRCPv2           ||
||   TCP/IP Stack   ||--MRCPv2-||  Stack |                         ||
||                  ||         ||----------------------------------||
||------------------||---SIP---||           TCP/IP Stack           ||
|--------------------|         ||                                  ||
         |                     ||----------------------------------||
        SIP                    |------------------------------------|
         |                       /           
|-------------------|          RTP
|                   |          /
| Media Source/Sink |---------/
|                   |
|-------------------|
</pre></div></div>
<figcaption><a href="#figure-1">Figure 1</a><a href="#name-architectural-diagram" id="name-architectural-diagram" class="selfRef">Architectural Diagram</a></figcaption></figure><section id="section-3.1"><div id="sec.resourceTypes">
<h3 id="name-mrcpv2-media-resource-types">
<a href="#section-3.1" class="section-number selfRef">3.1.Â </a><a href="#name-mrcpv2-media-resource-types" class="section-name selfRef">MRCPv2 Media Resource Types</a>
</h3>
<p id="section-3.1-1">An MRCPv2 server may offer one or more of the following media
        processing resources to its clients. 

</p>
<dl id="section-3.1-2" class="dlNewline">
<dt id="section-3.1-3">Basic Synthesizer</dt>
<dd id="section-3.1-4">A speech
            synthesizer resource that has very limited capabilities and can
            generate its media stream exclusively from concatenated audio
            clips. The speech data is described using a limited subset of the
            <span>[<a href="#W3C.REC-speech-synthesis-20040907" class="xref">Speech Synthesis
            Markup Language (SSML)</a>] elements. A basic synthesizer MUST
            support the SSML tags &lt;speak&gt;, &lt;audio&gt;, &lt;say-as&gt;,
            and &lt;mark&gt;.</span>
</dd>
<dt id="section-3.1-5">Speech Synthesizer</dt>
<dd id="section-3.1-6">A
full-capability speech synthesis resource that can render speech
            from text. Such a synthesizer MUST have full <span>[<a href="#W3C.REC-speech-synthesis-20040907" class="xref">SSML</a>]
            support.</span>
</dd>
<dt id="section-3.1-7">Recorder</dt>
<dd id="section-3.1-8">A resource capable
            of recording audio and providing a URI pointer to the recording. A
            recorder MUST provide endpointing capabilities for suppressing
            silence at the beginning and end of a recording, and MAY also
            suppress silence in the middle of a recording. If such suppression
            is done, the recorder MUST maintain timing metadata to indicate
            the actual timestamps of the recorded media.</dd>
<dt id="section-3.1-9">DTMF Recognizer</dt>
<dd id="section-3.1-10">A
            recognizer resource capable of extracting and interpreting <span>[<a href="#Q.23" class="xref">Dual-Tone Multi-Frequency (DTMF)</a>] digits in a
            media stream and matching them against a supplied digit grammar. It
            could also do a semantic interpretation based on semantic tags in
            the grammar.</span>
</dd>
<dt id="section-3.1-11">Speech Recognizer</dt>
<dd id="section-3.1-12">A full
            speech recognition resource that is capable of receiving a media
            stream containing audio and interpreting it to recognition
            results. It also has a natural language semantic interpreter to
            post-process the recognized data according to the semantic data in
            the grammar and provide semantic results along with the recognized
            input. The recognizer MAY also support enrolled grammars, where
            the client can enroll and create new personal grammars for use in
            future recognition operations.</dd>
<dt id="section-3.1-13">Speaker Verifier</dt>
<dd id="section-3.1-14">A resource
            capable of verifying the authenticity of a claimed identity by
            matching a media stream containing spoken input to a pre-existing
            voiceprint. This may also involve matching the caller's voice
            against more than one voiceprint, also called multi-verification
            or speaker identification.</dd>
</dl>
</div></section><section id="section-3.2"><h3 id="name-server-and-resource-address">
<a href="#section-3.2" class="section-number selfRef">3.2.Â </a><a href="#name-server-and-resource-address" class="section-name selfRef">Server and Resource Addressing</a>
</h3>
<p id="section-3.2-1">The MRCPv2 server is a generic SIP server, and is thus addressed by
        a SIP URI (<span>[<a href="#RFC3261" class="xref">RFC 3261</a>]).</span></p>
<p id="section-3.2-2">For example:</p>
<div id="section-3.2-3" class="artwork art-text" text-align="left"><pre>
     sip:mrcpv2@example.net   or
     sips:mrcpv2@example.net
          </pre></div></section></section><section id="section-4"><h2 id="name-mrcpv2-basics">
<a href="#section-4" class="section-number selfRef">4.Â </a><a href="#name-mrcpv2-basics" class="section-name selfRef">MRCPv2 Basics</a>
</h2>
<p id="section-4-1">MRCPv2 requires a connection-oriented transport-layer protocol such
      as TCP to guarantee reliable sequencing and delivery of MRCPv2
      control messages between the client and the server. In order to meet the
      requirements for security enumerated in <span>[<a href="#RFC4313" class="xref">SPEECHSC
      requirements</a>], clients and servers MUST implement TLS as well. One
      or more connections between the client and the server can be shared
      among different MRCPv2 channels to the server. The individual messages
      carry the channel identifier to differentiate messages on different
      channels. MRCPv2 encoding is text based with mechanisms to
      carry embedded binary data. This allows arbitrary data like recognition
      grammars, recognition results, synthesizer speech markup, etc., to be
      carried in MRCPv2 messages. For information on message framing, see
      </span><a href="#sec.messages" class="xref">Section 5</a>.</p>
<section id="section-4.1"><div id="sec.connectToServer">
<h3 id="name-connecting-to-the-server">
<a href="#section-4.1" class="section-number selfRef">4.1.Â </a><a href="#name-connecting-to-the-server" class="section-name selfRef">Connecting to the Server</a>
</h3>
<p id="section-4.1-1">MRCPv2 employs SIP, in conjunction with SDP, as the session
        establishment and management protocol. The client reaches an MRCPv2 server
        using conventional INVITE and other SIP requests for establishing,
        maintaining, and terminating SIP dialogs. The SDP offer/answer
        exchange model over SIP is used to establish a resource control
        channel for each resource. The SDP offer/answer exchange is also used
        to establish media sessions between the server and the source or sink
        of audio.</p>
</div></section><section id="section-4.2"><div id="sec.resourceControl">
<h3 id="name-managing-resource-control-c">
<a href="#section-4.2" class="section-number selfRef">4.2.Â </a><a href="#name-managing-resource-control-c" class="section-name selfRef">Managing Resource Control Channels</a>
</h3>
<p id="section-4.2-1">The client needs a separate MRCPv2 resource control channel to
        control each media processing resource under the SIP dialog. A unique
        channel identifier string identifies these resource control channels.
        The channel identifier is a difficult-to-guess, unambiguous string followed by an
        "@", then by a string token specifying the type of resource. The
        server generates the channel identifier and MUST make sure it does not
        clash with the identifier of any other MRCP channel currently
        allocated by that server. MRCPv2 defines the following IANA-registered
        types of media processing resources. Additional resource types and their
        associated methods/events and state machines may be added as described
        below in <a href="#sec.iana" class="xref">Section 13</a>.</p>
<table id="table-1"></table>
<div id="table.resourceTypes">
<name id="name-resource-types">Resource Types</name><thead><tr>
<th>Resource Type</th>
<th>Resource Description</th>
<th>Described in</th>
</tr></thead>
<tbody>
<tr>
<td>speechrecog</td>
<td>Speech Recognizer</td>
<td><a href="#sec.recognizerResource" class="xref">Section 9</a></td>
</tr>
<tr>
<td>dtmfrecog</td>
<td>DTMF Recognizer</td>
<td><a href="#sec.recognizerResource" class="xref">Section 9</a></td>
</tr>
<tr>
<td>speechsynth</td>
<td>Speech Synthesizer</td>
<td><a href="#sec.synthesizerResource" class="xref">Section 8</a></td>
</tr>
<tr>
<td>basicsynth</td>
<td>Basic Synthesizer</td>
<td><a href="#sec.synthesizerResource" class="xref">Section 8</a></td>
</tr>
<tr>
<td>speakverify</td>
<td>Speaker Verification</td>
<td><a href="#sec.verifierResource" class="xref">Section 11</a></td>
</tr>
<tr>
<td>recorder</td>
<td>Speech Recorder</td>
<td><a href="#sec.recorderResource" class="xref">Section 10</a></td>
</tr>
</tbody>
</div>
<p id="section-4.2-2">The SIP INVITE or re-INVITE transaction and the SDP offer/answer
        exchange it carries contain "m=" lines describing the resource control
        channel to be allocated. There MUST be one SDP "m=" line for each MRCPv2
        resource to be used in the session. This "m=" line MUST have a media type
        field of "application" and a transport type field of either
        "TCP/MRCPv2" or "TCP/TLS/MRCPv2". The port number field of the
        "m=" line MUST contain the "discard" port of the transport protocol (port
        9 for TCP) in the SDP offer from the client and MUST contain the TCP
        listen port on the server in the SDP answer. The client may then
        either set up a TCP or TLS connection to that server port or share an
        already established connection to that port. Since MRCPv2 allows
        multiple sessions to share the same TCP connection, multiple "m=" lines
        in a single SDP document MAY share the same port field value; MRCPv2
        servers MUST NOT assume any relationship between resources using the
        same port other than the sharing of the communication channel.</p>
<p id="section-4.2-3">MRCPv2 resources do not use the port or format field of the "m=" line
        to distinguish themselves from other resources using the same channel.
        The client MUST specify the resource type identifier in the resource
        attribute associated with the control "m=" line of the SDP offer. The
        server MUST respond with the full Channel-Identifier (which includes
        the resource type identifier and a difficult-to-guess, unambiguous string) in the
        "channel" attribute associated with the control "m=" line of the SDP
        answer. To remain backwards compatible with conventional SDP usage,
        the format field of the "m=" line MUST have the arbitrarily selected
        value of "1".</p>
<p id="section-4.2-4">When the client wants to add a media processing resource to the
        session, it issues a new SDP offer, according to the procedures of
        <span>[<a href="#RFC3264" class="xref">RFC 3264</a>], in a SIP re-INVITE request.
        The SDP offer/answer exchange carried by this SIP transaction contains
        one or more additional control "m=" lines for the new resources to be
        allocated to the session. The server, on seeing the new "m=" line,
        allocates the resources (if they are available) and responds with a
        corresponding control "m=" line in the SDP answer carried in the SIP
        response. If the new resources are not available, the re-INVITE
        receives an error message, and existing media processing going on
        before the re-INVITE will continue as it was before. It is not
        possible to allocate more than one resource of each type. If a client
        requests more than one resource of any type, the server MUST behave as
        if the resources of that type (beyond the first one) are not available.</span></p>
<p id="section-4.2-5">MRCPv2 clients and servers using TCP as a transport
        protocol MUST use the procedures specified
        in <span>[<a href="#RFC4145" class="xref">RFC 4145</a>] for setting up the
        TCP connection, with the considerations described
        hereby. Similarly, MRCPv2 clients and servers using TCP/TLS as
        a transport protocol MUST use the procedures specified
        in </span><span>[<a href="#RFC4572" class="xref">RFC 4572</a>] for setting up the
        TLS connection, with the considerations described hereby. The
        a=setup attribute, as described in </span><span>[<a href="#RFC4145" class="xref">RFC
        4145</a>], MUST be "active" for the offer from the client
        and MUST be "passive" for the answer from the MRCPv2
        server. The a=connection attribute MUST have a value of "new"
        on the very first control "m=" line offer from the client to an
        MRCPv2 server. Subsequent control "m=" line offers from the
        client to the MRCP server MAY contain "new" or "existing",
        depending on whether the client wants to set up a new
        connection or share an existing connection, respectively. If
        the client specifies a value of "new", the server MUST respond
        with a value of "new". If the client specifies a value of
        "existing", the server MUST respond. The legal values in the
        response are "existing" if the server prefers to share an
        existing connection or "new" if not. In the latter case, the
        client MUST initiate a new transport connection.</span></p>
<p id="section-4.2-6">When the client wants to deallocate the resource from this
        session, it issues a new SDP offer, according to <span>[<a href="#RFC3264" class="xref">RFC 3264</a>], where the control "m=" line port MUST
        be set to 0. This SDP offer is sent in a SIP re-INVITE request. This
        deallocates the associated MRCPv2 identifier and resource. The server
        MUST NOT close the TCP or TLS connection if it is currently
        being shared among multiple MRCP channels. When all MRCP channels that
        may be sharing the connection are released and/or the associated SIP
        dialog is terminated, the client or server terminates the
        connection.</span></p>
<p id="section-4.2-7">When the client wants to tear down the whole session and all its
        resources, it MUST issue a SIP BYE request to close the SIP session.
        This will deallocate all the control channels and resources allocated
        under the session.</p>
<p id="section-4.2-8">All servers MUST support TLS. Servers MAY use TCP without TLS
        in controlled environments (e.g., not in the public Internet) where
        both nodes are inside a protected perimeter, for example, preventing
        access to the MRCP server from remote nodes outside the controlled
        perimeter. It is up to the client, through the SDP offer, to choose
        which transport it wants to use for an MRCPv2 session. Aside from the
        exceptions given above, when using TCP, the "m=" lines MUST conform to
        <span>[<a href="#RFC4145" class="xref">RFC4145</a>], which describes the usage of
        SDP for connection-oriented transport. When using TLS, the SDP "m=" line
        for the control stream MUST conform to </span><span>[<a href="#RFC4572" class="xref">Connection-Oriented Media (COMEDIA)
        over TLS</a>], which specifies the usage of SDP for establishing a
        secure connection-oriented transport over TLS.</span></p>
</div></section><section id="section-4.3"><div id="sec.SIPExample">
<h3 id="name-sip-session-example">
<a href="#section-4.3" class="section-number selfRef">4.3.Â </a><a href="#name-sip-session-example" class="section-name selfRef">SIP Session Example</a>
</h3>
<p id="section-4.3-1">This first example shows the power of using SIP to route to the
        appropriate resource. In the example, note the use of a request to a
        domain's speech server service in the INVITE to
        mresources@example.com. The SIP routing machinery in the domain
        locates the actual server, mresources@server.example.com, which gets
        returned in the 200 OK. Note that "cmid" is defined in <a href="#sec.mediaStreams" class="xref">Section 4.4</a>.</p>
<p id="section-4.3-2">This example exchange adds a resource control channel for
          a synthesizer. Since a synthesizer also generates an audio stream,
          this interaction also creates a receive-only <span>[<a href="#RFC3550" class="xref">Real-Time Protocol (RTP)</a>] media session for
          the server to send audio to. The SIP dialog with the media
          source/sink is independent of MRCP and is not shown.</span></p>
<figure id="figure-2"><div><div id="section-4.3-3" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  INVITE sip:mresources@example.com SIP/2.0 
       Via:SIP/2.0/TCP client.atlanta.example.com:5060; 
        branch=z9hG4bK74bf1 
       Max-Forwards:6 
       To:MediaServer &lt;sip:mresources@example.com&gt; 
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774 
       Call-ID:a84b4c76e66710 
       CSeq:314161 INVITE 
       Contact:&lt;sip:sarvi@client.example.com&gt; 
       Content-Type:application/sdp 
       Content-Length:...
       
       v=0 
       o=sarvi 2890844526 2890844526 IN IP4 192.0.2.12 
       s=- 
       c=IN IP4 192.0.2.12
       t=0 0
       m=application 9 TCP/MRCPv2 1 
       a=setup:active
       a=connection:new
       a=resource:speechsynth
       a=cmid:1
       m=audio 49170 RTP/AVP 0 
       a=rtpmap:0 pcmu/8000 
       a=recvonly 
       a=mid:1
     

S-&gt;C:  SIP/2.0 200 OK 
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bf1;received=192.0.32.10
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784 
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774 
       Call-ID:a84b4c76e66710 
       CSeq:314161 INVITE 
       Contact:&lt;sip:mresources@server.example.com&gt; 
       Content-Type:application/sdp 
       Content-Length:... 
       
       v=0 
       o=- 2890842808 2890842808 IN IP4 192.0.2.11 
       s=- 
       c=IN IP4 192.0.2.11
       t=0 0
       m=application 32416 TCP/MRCPv2 1 
       a=setup:passive
       a=connection:new
       a=channel:32AECB234338@speechsynth 
       a=cmid:1
       m=audio 48260 RTP/AVP 0 
       a=rtpmap:0 pcmu/8000 
       a=sendonly 
       a=mid:1 
     

C-&gt;S:  ACK sip:mresources@server.example.com SIP/2.0 
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bf2
       Max-Forwards:6 
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:Sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774 
       Call-ID:a84b4c76e66710 
       CSeq:314161 ACK 
       Content-Length:0
</pre></div></div>
<figcaption><a href="#figure-2">Figure 2</a><a href="#name-example-add-synthesizer-con" id="name-example-add-synthesizer-con" class="selfRef">Example: Add Synthesizer Control Channel</a></figcaption></figure><p id="section-4.3-4">This example exchange continues from the previous figure
          and allocates an additional resource control channel for a
          recognizer. Since a recognizer would need to receive an audio stream
          for recognition, this interaction also updates the audio stream to
          sendrecv, making it a two-way RTP media session.</p>
<figure id="figure-3"><div><div id="section-4.3-5" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  INVITE sip:mresources@server.example.com SIP/2.0 
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bf3
       Max-Forwards:6 
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774 
       Call-ID:a84b4c76e66710 
       CSeq:314162 INVITE 
       Contact:&lt;sip:sarvi@client.example.com&gt; 
       Content-Type:application/sdp 
       Content-Length:...
       
       v=0 
       o=sarvi 2890844526 2890844527 IN IP4 192.0.2.12 
       s=-
       c=IN IP4 192.0.2.12
       t=0 0
       m=application 9 TCP/MRCPv2 1 
       a=setup:active
       a=connection:existing
       a=resource:speechsynth
       a=cmid:1
       m=audio 49170 RTP/AVP 0 96 
       a=rtpmap:0 pcmu/8000 
       a=rtpmap:96 telephone-event/8000 
       a=fmtp:96 0-15 
       a=sendrecv 
       a=mid:1
       m=application 9 TCP/MRCPv2 1 
       a=setup:active
       a=connection:existing
       a=resource:speechrecog
       a=cmid:1
     

S-&gt;C:  SIP/2.0 200 OK 
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bf3;received=192.0.32.10
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774 
       Call-ID:a84b4c76e66710 
       CSeq:314162 INVITE 
       Contact:&lt;sip:mresources@server.example.com&gt; 
       Content-Type:application/sdp 
       Content-Length:...
            
       v=0 
       o=- 2890842808 2890842809 IN IP4 192.0.2.11 
       s=-
       c=IN IP4 192.0.2.11
       t=0 0
       m=application 32416 TCP/MRCPv2 1 
       a=setup:passive
       a=connection:existing
       a=channel:32AECB234338@speechsynth
       a=cmid:1
       m=audio 48260 RTP/AVP 0 96 
       a=rtpmap:0 pcmu/8000 
       a=rtpmap:96 telephone-event/8000 
       a=fmtp:96 0-15 
       a=sendrecv 
       a=mid:1
       m=application 32416 TCP/MRCPv2 1 
       a=setup:passive
       a=connection:existing
       a=channel:32AECB234338@speechrecog
       a=cmid:1
     

C-&gt;S:  ACK sip:mresources@server.example.com SIP/2.0 
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bf4
       Max-Forwards:6 
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:Sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774 
       Call-ID:a84b4c76e66710 
       CSeq:314162 ACK 
       Content-Length:0
</pre></div></div>
<figcaption><a href="#figure-3">Figure 3</a><a href="#name-example-add-recognizer" id="name-example-add-recognizer" class="selfRef">Example: Add Recognizer</a></figcaption></figure><p id="section-4.3-6">This example exchange continues from the previous figure
          and deallocates the recognizer channel. Since a recognizer no
          longer needs to receive an audio stream, this interaction also
          updates the RTP media session to recvonly.</p>
<figure id="figure-4"><div><div id="section-4.3-7" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  INVITE sip:mresources@server.example.com SIP/2.0 
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bf5
       Max-Forwards:6 
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774 
       Call-ID:a84b4c76e66710 
       CSeq:314163 INVITE 
       Contact:&lt;sip:sarvi@client.example.com&gt; 
       Content-Type:application/sdp 
       Content-Length:...
            
       v=0 
       o=sarvi 2890844526 2890844528 IN IP4 192.0.2.12 
       s=-
       c=IN IP4 192.0.2.12
       t=0 0
       m=application 9 TCP/MRCPv2 1 
       a=resource:speechsynth 
       a=cmid:1
       m=audio 49170 RTP/AVP 0 
       a=rtpmap:0 pcmu/8000 
       a=recvonly 
       a=mid:1
       m=application 0 TCP/MRCPv2 1 
       a=resource:speechrecog 
       a=cmid:1
     

S-&gt;C:  SIP/2.0 200 OK 
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bf5;received=192.0.32.10
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774 
       Call-ID:a84b4c76e66710 
       CSeq:314163 INVITE 
       Contact:&lt;sip:mresources@server.example.com&gt;
       Content-Type:application/sdp 
       Content-Length:...
     
       v=0 
       o=- 2890842808 2890842810 IN IP4 192.0.2.11 
       s=-
       c=IN IP4 192.0.2.11
       t=0 0
       m=application 32416 TCP/MRCPv2 1 
       a=channel:32AECB234338@speechsynth 
       a=cmid:1
       m=audio 48260 RTP/AVP 0 
       a=rtpmap:0 pcmu/8000 
       a=sendonly 
       a=mid:1
       m=application 0 TCP/MRCPv2 1 
       a=channel:32AECB234338@speechrecog 
       a=cmid:1
     

C-&gt;S:  ACK sip:mresources@server.example.com SIP/2.0 
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bf6
       Max-Forwards:6 
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:Sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774 
       Call-ID:a84b4c76e66710 
       CSeq:314163 ACK 
       Content-Length:0
</pre></div></div>
<figcaption><a href="#figure-4">Figure 4</a><a href="#name-example-deallocate-recogniz" id="name-example-deallocate-recogniz" class="selfRef">Example: Deallocate Recognizer</a></figcaption></figure>
</div></section><section id="section-4.4"><div id="sec.mediaStreams">
<h3 id="name-media-streams-and-rtp-ports">
<a href="#section-4.4" class="section-number selfRef">4.4.Â </a><a href="#name-media-streams-and-rtp-ports" class="section-name selfRef">Media Streams and RTP Ports</a>
</h3>
<p id="section-4.4-1">Since MRCPv2 resources either generate or consume media streams,
        the client or the server needs to associate media sessions with their
        corresponding resource or resources. More than one resource could be
        associated with a single media session or each resource could be
        assigned a separate media session. Also, note that more than one media
        session can be associated with a single resource if need be, but this
        scenario is not useful for the current set of resources. For example,
        a synthesizer and a recognizer could be associated to the same media
        session (m=audio line), if it is opened in "sendrecv" mode.
        Alternatively, the recognizer could have its own "sendonly" audio
        session, and the synthesizer could have its own "recvonly" audio
        session.</p>
<p id="section-4.4-2">The association between control channels and their corresponding
        media sessions is established using a new "resource channel media
        identifier" media-level attribute ("cmid"). Valid values of this
        attribute are the values of the "mid" attribute defined in <span>[<a href="#RFC5888" class="xref">RFC 5888</a>]. If there is more than one audio
        "m=" line, then each audio "m=" line MUST have a "mid" attribute. Each
        control "m=" line MAY have one or more "cmid" attributes that match the
        resource control channel to the "mid" attributes of the audio "m=" lines
        it is associated with. Note that if a control "m=" line does not have a
        "cmid" attribute it will not be associated with any media. The
        operations on such a resource will hence be limited. For example, if
        it was a recognizer resource, the RECOGNIZE method requires an
        associated media to process while the INTERPRET method does not. The
        formatting of the "cmid" attribute is described by the following
        ABNF:</span></p>
<div id="section-4.4-3" class="artwork art-text art-abnf" text-align="left"><pre>
cmid-attribute     = "a=cmid:" identification-tag
identification-tag = token</pre></div>
<p id="section-4.4-4"></p>
<p id="section-4.4-5">To allow this flexible mapping of media sessions to MRCPv2 control
        channels, a single audio "m=" line can be associated with multiple
        resources, or each resource can have its own audio "m=" line. For example,
        if the client wants to allocate a recognizer and a synthesizer and
        associate them with a single two-way audio stream, the SDP offer would
        contain two control "m=" lines and a single audio "m=" line with an
        attribute of "sendrecv". Each of the control "m=" lines would have a
        "cmid" attribute whose value matches the "mid" of the audio "m=" line.
        If, on the other hand, the client wants to allocate a recognizer and a
        synthesizer each with its own separate audio stream, the SDP offer
        would carry two control "m=" lines (one for the recognizer and another
        for the synthesizer) and two audio "m=" lines (one with the attribute
        "sendonly" and another with attribute "recvonly"). The "cmid"
        attribute of the recognizer control "m=" line would match the "mid" value
        of the "sendonly" audio "m=" line, and the "cmid" attribute of the
        synthesizer control "m=" line would match the "mid" attribute of the
        "recvonly" "m=" line.</p>
<p id="section-4.4-6">When a server receives media (e.g., audio) on a media
        session that is associated with more than one media processing
        resource, it is the responsibility of the server to receive
        and fork the media to the resources that need to consume
        it. If multiple resources in an MRCPv2 session are generating
        audio (or other media) to be sent on a single associated media
        session, it is the responsibility of the server either to
        multiplex the multiple streams onto the single RTP session or
        to contain an embedded RTP mixer (see <span>[<a href="#RFC3550" class="xref">RFC
        3550</a>]) to combine the multiple streams into one. In the
        former case, the media stream will contain RTP packets
        generated by different sources, and hence the packets will
        have different Synchronization Source Identifiers (SSRCs). In
        the latter case, the RTP packets will contain multiple
        Contributing Source Identifiers (CSRCs) corresponding to the
        original streams before being combined by the mixer. If an
        MRCPv2 server implementation neither multiplexes nor mixes, it
        MUST disallow the client from associating multiple such
        resources to a single audio stream by rejecting the SDP offer
        with a SIP 488 "Not Acceptable" error. Note that there is a
        large installed base that will return a SIP 501 "Not
        Implemented" error in this case. To facilitate
        interoperability with this installed base, new implementations
        SHOULD treat a 501 in this
        context as a 488 when it is received from an element known to
        be a legacy implementation.</span></p>
</div></section><section id="section-4.5"><h3 id="name-mrcpv2-message-transport">
<a href="#section-4.5" class="section-number selfRef">4.5.Â </a><a href="#name-mrcpv2-message-transport" class="section-name selfRef">MRCPv2 Message Transport</a>
</h3>
<p id="section-4.5-1">The MRCPv2 messages defined in this document are transported over a
        TCP or TLS connection between the client and the
        server. The method for setting up this transport connection and the
        resource control channel is discussed in Sections <a href="#sec.connectToServer" class="xref">4.1</a> and <a href="#sec.resourceControl" class="xref">4.2</a>. Multiple resource control
        channels between a client and a server that belong to different SIP
        dialogs can share one or more TLS or TCP connections between
        them; the server and client MUST support this mode of operation.
        Clients and servers MUST use the MRCPv2 channel identifier, carried in
        the Channel-Identifier header field in individual MRCPv2 messages, to
        differentiate MRCPv2 messages from different resource channels (see
        <a href="#sec.channelIdentifier" class="xref">Section 6.2.1</a> for details). All MRCPv2
        servers MUST support TLS. Servers MAY use TCP without TLS in
        controlled environments (e.g., not in the public Internet) where both
        nodes are inside a protected perimeter, for example, preventing access
        to the MRCP server from remote nodes outside the controlled perimeter.
        It is up to the client to choose which mode of transport it wants to
        use for an MRCPv2 session.</p>
<p id="section-4.5-2">Most examples from here on show only the MRCPv2 messages and do not
        show the SIP messages that may have been used to establish the MRCPv2
        control channel.</p></section><section id="section-4.6"><h3 id="name-mrcpv2-session-termination">
<a href="#section-4.6" class="section-number selfRef">4.6.Â </a><a href="#name-mrcpv2-session-termination" class="section-name selfRef">MRCPv2 Session Termination</a>
</h3>
<p id="section-4.6-1">If an MRCP client notices that the underlying connection has been
        closed for one of its MRCP channels, and it has not previously
        initiated a re-INVITE to close that channel, it MUST send a BYE to
        close down the SIP dialog and all other MRCP channels. If an MRCP
        server notices that the underlying connection has been closed for one
        of its MRCP channels, and it has not previously received and accepted
        a re-INVITE closing that channel, then it MUST send a BYE to close
        down the SIP dialog and all other MRCP channels.</p></section></section><section id="section-5"><div id="sec.messages">
<h2 id="name-mrcpv2-specification">
<a href="#section-5" class="section-number selfRef">5.Â </a><a href="#name-mrcpv2-specification" class="section-name selfRef">MRCPv2 Specification</a>
</h2>
<p id="section-5-1">Except as otherwise indicated, MRCPv2 messages are Unicode
      encoded in UTF-8 (<span>[<a href="#RFC3629" class="xref">RFC 3629</a>]) to
      allow many different languages to be
      represented.  </span><a href="#sec.defineGrammar" class="xref">DEFINE-GRAMMAR</a>,
      for example, is one such exception, since its body can contain
      arbitrary XML in arbitrary (but specified via XML) encodings.
      MRCPv2 also allows message bodies to be represented in other
      character sets (for example, <span>[<a href="#ISO.8859-1.1987" class="xref">ISO
      8859-1</a>]) because, in some locales, other character sets are
      already in widespread use. The MRCPv2 headers (the
      first line of an MRCP message) and header field names use only
      the US-ASCII subset of UTF-8.</span></p>
<p id="section-5-2">Lines are terminated by CRLF (carriage return, then line
      feed). Also, some parameters in the message may contain binary
      data or a record spanning multiple lines. Such fields have a
      length value associated with the parameter, which indicates the
      number of octets immediately following the parameter.</p>
<section id="section-5.1"><div id="sec.common">
<h3 id="name-common-protocol-elements">
<a href="#section-5.1" class="section-number selfRef">5.1.Â </a><a href="#name-common-protocol-elements" class="section-name selfRef">Common Protocol Elements</a>
</h3>
<p id="section-5.1-1">The MRCPv2 message set consists of requests from the client to the
        server, responses from the server to the client, and asynchronous
        events from the server to the client. All these messages consist of a
        start-line, one or more header fields, an empty line (i.e., a line with
        nothing preceding the CRLF) indicating the end of the header fields,
        and an optional message body.</p>
<div id="section-5.1-2" class="artwork art-text art-abnf" text-align="left"><pre>
generic-message =   start-line
                    message-header
                    CRLF
                    [ message-body ]

message-body    =   *OCTET

start-line      =   request-line / response-line / event-line

message-header  =   1*(generic-header / resource-header /
                       generic-field)

resource-header =   synthesizer-header
                /   recognizer-header
                /   recorder-header
                /   verifier-header
</pre></div>
<p id="section-5.1-3">The message-body contains resource-specific and message-specific
        data. The actual media types used to carry the data are specified
        in the sections defining the individual messages. Generic header
        fields are described in <a href="#sec.genericHeaders" class="xref">Section 6.2</a>.</p>
<p id="section-5.1-4">If a message contains a message body, the message MUST contain
        content-headers indicating the media type and encoding of the data in
        the message body.</p>
<p id="section-5.1-5">Request, response and event messages (described in following
        sections) include the version of MRCP that the message conforms to.
        Version compatibility rules follow [H3.1] regarding version ordering,
        compliance requirements, and upgrading of version numbers. The version
        information is indicated by "MRCP" (as opposed to "HTTP" in [H3.1]) or
        "MRCP/2.0" (as opposed to "HTTP/1.1" in [H3.1]). To be compliant with
        this specification, clients and servers sending MRCPv2 messages MUST
        indicate an mrcp-version of "MRCP/2.0". ABNF productions using
        mrcp-version can be found in Sections <a href="#sec.request" class="xref">5.2</a>, <a href="#sec.response" class="xref">5.3</a>, and <a href="#sec.events" class="xref">5.5</a>.</p>
<div id="section-5.1-6" class="artwork art-text art-abnf" text-align="left"><pre>
mrcp-version   =    "MRCP" "/" 1*2DIGIT "." 1*2DIGIT
          </pre></div>
<p id="section-5.1-7"></p>
<p id="section-5.1-8">The message-length field specifies the length of the message in
        octets, including the start-line, and MUST be the second token from the
        beginning of the message. This is to make the framing and parsing of
        the message simpler to do. This field specifies the length of the
        message including data that may be encoded into the body of the
        message. Note that this value MAY be given as a fixed-length integer
        that is zero-padded (with leading zeros) in order to eliminate or reduce
        inefficiency in cases where the message-length value would change as a
        result of the length of the message-length token itself. This value,
        as with all lengths in MRCP, is to be interpreted as a base-10 number.
        In particular, leading zeros do not indicate that the value is to be
        interpreted as a base-8 number.</p>
<div id="section-5.1-9" class="artwork art-text art-abnf" text-align="left"><pre>
message-length =    1*19DIGIT
          </pre></div>
<p id="section-5.1-10">The following sample MRCP exchange demonstrates proper
        message-length values. The values for message-length have been removed
        from all other examples in the specification and replaced by '...' to
        reduce confusion in the case of minor message-length computation
        errors in those examples.</p>
<div id="section-5.1-11" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 877 INTERPRET 543266
        Channel-Identifier:32AECB23433801@speechrecog 
        Interpret-Text:may I speak to Andre Roy 
        Content-Type:application/srgs+xml  
        Content-ID:&lt;request1@form-level.store&gt;  
        Content-Length:661
        
        &lt;?xml version="1.0"?&gt;
        &lt;!-- the default grammar language is US English --&gt;
        &lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
                 xml:lang="en-US" version="1.0" root="request"&gt;
        &lt;!-- single language attachment to tokens --&gt;
            &lt;rule id="yes"&gt;
                &lt;one-of&gt;
                    &lt;item xml:lang="fr-CA"&gt;oui&lt;/item&gt;
                    &lt;item xml:lang="en-US"&gt;yes&lt;/item&gt;
                &lt;/one-of&gt;
            &lt;/rule&gt;
        
        &lt;!-- single language attachment to a rule expansion --&gt;
            &lt;rule id="request"&gt;
                may I speak to
                &lt;one-of xml:lang="fr-CA"&gt;
                    &lt;item&gt;Michel Tremblay&lt;/item&gt;
                    &lt;item&gt;Andre Roy&lt;/item&gt;
                &lt;/one-of&gt;
            &lt;/rule&gt;
        &lt;/grammar&gt;
              
S-&gt;C:   MRCP/2.0 82 543266 200 IN-PROGRESS
        Channel-Identifier:32AECB23433801@speechrecog
                   
S-&gt;C:   MRCP/2.0 634 INTERPRETATION-COMPLETE 543266 200 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
        Completion-Cause:000 success
        Content-Type:application/nlsml+xml
        Content-Length:441
        
        &lt;?xml version="1.0"?&gt;
        &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                xmlns:ex="http://www.example.com/example"
                grammar="session:request1@form-level.store"&gt;
            &lt;interpretation&gt;
                &lt;instance name="Person"&gt;
                    &lt;ex:Person&gt;
                        &lt;ex:Name&gt; Andre Roy &lt;/ex:Name&gt;
                    &lt;/ex:Person&gt;
                &lt;/instance&gt;
                &lt;input&gt;   may I speak to Andre Roy &lt;/input&gt;
            &lt;/interpretation&gt;
        &lt;/result&gt;
</pre></div>
<p id="section-5.1-12">All MRCPv2 messages, responses and events MUST carry the
        Channel-Identifier header field so the server or client can
        differentiate messages from different control channels that may share
        the same transport connection.</p>
<p id="section-5.1-13">In the resource-specific header field descriptions in Sections
        <a href="#sec.synthesizerResource" class="xref">8</a>-<a href="#sec.verifierResource" class="xref">11</a>, a header field is disallowed on a method (request, response, or
        event) for that resource unless specifically listed as being allowed.
        Also, the phrasing "This header field MAY occur on method X" indicates
        that the header field is allowed on that method but is not required to
        be used in every instance of that method.</p>
</div></section><section id="section-5.2"><div id="sec.request">
<h3 id="name-request">
<a href="#section-5.2" class="section-number selfRef">5.2.Â </a><a href="#name-request" class="section-name selfRef">Request</a>
</h3>
<p id="section-5.2-1">An MRCPv2 request consists of a Request line followed by the
        message header section and an optional message body containing data
        specific to the request message.</p>
<p id="section-5.2-2">The Request message from a client to the server includes within the
        first line the method to be applied, a method tag for that request and
        the version of the protocol in use.</p>
<div id="section-5.2-3" class="artwork art-text art-abnf" text-align="left"><pre>
request-line   =    mrcp-version SP message-length SP method-name
                    SP request-id CRLF
          </pre></div>
<p id="section-5.2-4">The mrcp-version field is the MRCP protocol version that is being
        used by the client.</p>
<p id="section-5.2-5">The message-length field specifies the length of the message,
        including the start-line.</p>
<p id="section-5.2-6">Details about the mrcp-version and message-length fields are given
        in <a href="#sec.common" class="xref">Section 5.1</a>.</p>
<p id="section-5.2-7">The method-name field identifies the specific request that the
        client is making to the server. Each resource supports a subset of the
        MRCPv2 methods. The subset for each resource is defined in the section
        of the specification for the corresponding resource.</p>
<div id="section-5.2-8" class="artwork art-text art-abnf" text-align="left"><pre>
method-name    =    generic-method
               /    synthesizer-method
               /    recognizer-method
               /    recorder-method
               /    verifier-method
          </pre></div>
<p id="section-5.2-9">The request-id field is a unique identifier representable as an
        unsigned 32-bit integer created by the client and sent to the server.
        Clients MUST utilize monotonically increasing request-ids for
        consecutive requests within an MRCP session. The request-id space is
        linear (i.e., not mod(32)), so the space does not wrap, and validity can
        be checked with a simple unsigned comparison operation. The client may
        choose any initial value for its first request, but a small integer is
        RECOMMENDED to avoid exhausting the space in long sessions. If the
        server receives duplicate or out-of-order requests, the server MUST
        reject the request with a response code of 410. Since request-ids are
        scoped to the MRCP session, they are unique across all TCP connections
        and all resource channels in the session.</p>
<p id="section-5.2-10">The server resource MUST use the client-assigned identifier in its
        response to the request. If the request does not complete
        synchronously, future asynchronous events associated with this request
        MUST carry the client-assigned request-id.</p>
<div id="section-5.2-11" class="artwork art-text art-abnf" text-align="left"><pre>
request-id     =    1*10DIGIT
          </pre></div>
</div></section><section id="section-5.3"><div id="sec.response">
<h3 id="name-response">
<a href="#section-5.3" class="section-number selfRef">5.3.Â </a><a href="#name-response" class="section-name selfRef">Response</a>
</h3>
<p id="section-5.3-1">After receiving and interpreting the request message for a method,
        the server resource responds with an MRCPv2 response message. The
        response consists of a response line followed by the message header
        section and an optional message body containing data specific to the
        method.</p>
<div id="section-5.3-2" class="artwork art-text art-abnf" text-align="left"><pre>
response-line  =    mrcp-version SP message-length SP request-id
                    SP status-code SP request-state CRLF
          </pre></div>
<p id="section-5.3-3">The mrcp-version field MUST contain the version of the request if
        supported; otherwise, it MUST contain the highest version of
        MRCP supported by the server.</p>
<p id="section-5.3-4">The message-length field specifies the length of the message,
        including the start-line.</p>
<p id="section-5.3-5">Details about the mrcp-version and message-length fields are given
        in <a href="#sec.common" class="xref">Section 5.1</a>.</p>
<p id="section-5.3-6">The request-id used in the response MUST match the one sent in the
        corresponding request message.</p>
<p id="section-5.3-7">The status-code field is a 3-digit code representing the success or
        failure or other status of the request.</p>
<div id="section-5.3-8" class="artwork art-text art-abnf" text-align="left"><pre>
status-code     =    3DIGIT
          </pre></div>
<p id="section-5.3-9">The request-state field indicates if the action initiated by the
        Request is PENDING, IN-PROGRESS, or COMPLETE. The COMPLETE status means
        that the request was processed to completion and that there will be no
        more events or other messages from that resource to the client with
        that request-id. The PENDING status means that the request has been
        placed in a queue and will be processed in first-in-first-out order.
        The IN-PROGRESS status means that the request is being processed and
        is not yet complete. A PENDING or IN-PROGRESS status indicates that
        further Event messages may be delivered with that request-id.</p>
<div id="section-5.3-10" class="artwork art-text art-abnf" text-align="left"><pre>
request-state    =  "COMPLETE"
                 /  "IN-PROGRESS"
                 /  "PENDING"
          </pre></div>
</div></section><section id="section-5.4"><div id="sec.statusCodes">
<h3 id="name-status-codes">
<a href="#section-5.4" class="section-number selfRef">5.4.Â </a><a href="#name-status-codes" class="section-name selfRef">Status Codes</a>
</h3>
<p id="section-5.4-1">The status codes are classified under the Success (2xx),
        Client Failure (4xx), and Server Failure (5xx) codes.</p>
<table id="table-2">
<name id="name-success-2xx">Success (2xx)</name><thead><tr>
<th>Code</th>
<th>Meaning</th>
</tr></thead>
<tbody>
<tr>
<td>200</td>
<td>Success</td>
</tr>
<tr>
<td>201</td>
<td>Success with some optional header fields ignored</td>
</tr>
</tbody>
</table>
<table id="table-3">
<name id="name-client-failure-4xx">Client Failure (4xx)</name><thead><tr>
<th>Code</th>
<th>Meaning</th>
</tr></thead>
<tbody>
<tr>
<td>401</td>
<td>Method not allowed</td>
</tr>
<tr>
<td>402</td>
<td>Method not valid in this state</td>
</tr>
<tr>
<td>403</td>
<td>Unsupported header field</td>
</tr>
<tr>
<td>404</td>
<td>Illegal value for header field. This is the error for a syntax
          violation.</td>
</tr>
<tr>
<td>405</td>
<td>Resource not allocated for this session or does not exist</td>
</tr>
<tr>
<td>406</td>
<td>Mandatory Header Field Missing</td>
</tr>
<tr>
<td>407</td>
<td>Method or Operation Failed (e.g., Grammar compilation failed in
          the recognizer. Detailed cause codes might be available through a
          resource-specific header.)</td>
</tr>
<tr>
<td>408</td>
<td>Unrecognized or unsupported message entity</td>
</tr>
<tr>
<td>409</td>
<td>Unsupported Header Field Value. This is a value that is
          syntactically legal but exceeds the implementation's capabilities or
          expectations.</td>
</tr>
<tr>
<td>410</td>
<td>Non-Monotonic or Out-of-order sequence number in request.</td>
</tr>
<tr>
<td>411-420</td>
<td>Reserved for future assignment</td>
</tr>
</tbody>
</table>
<table id="table-4">
<name id="name-server-failure-5xx">Server Failure (5xx)</name><thead><tr>
<th>Code</th>
<th>Meaning</th>
</tr></thead>
<tbody>
<tr>
<td>501</td>
<td>Server Internal Error</td>
</tr>
<tr>
<td>502</td>
<td>Protocol Version not supported</td>
</tr>
<tr>
<td>503</td>
<td>Reserved for future assignment</td>
</tr>
<tr>
<td>504</td>
<td>Message too large</td>
</tr>
</tbody>
</table>
</div></section><section id="section-5.5"><div id="sec.events">
<h3 id="name-events">
<a href="#section-5.5" class="section-number selfRef">5.5.Â </a><a href="#name-events" class="section-name selfRef">Events</a>
</h3>
<p id="section-5.5-1">The server resource may need to communicate a change in state or
        the occurrence of a certain event to the client. These messages are
        used when a request does not complete immediately and the response
        returns a status of PENDING or IN-PROGRESS. The intermediate results
        and events of the request are indicated to the client through the
        event message from the server. The event message consists of an event
        header line followed by the message header section and an optional
        message body containing data specific to the event message. The header
        line has the request-id of the corresponding request and status value.
        The request-state value is COMPLETE if the request is done and this
        was the last event, else it is IN-PROGRESS.</p>
<div id="section-5.5-2" class="artwork art-text art-abnf" text-align="left"><pre>
event-line       =  mrcp-version SP message-length SP event-name
                    SP request-id SP request-state CRLF</pre></div>
<p id="section-5.5-3">The mrcp-version used here is identical to the one used in the
        Request/Response line and indicates the highest version of MRCP
        running on the server.</p>
<p id="section-5.5-4">The message-length field specifies the length of the message,
        including the start-line.</p>
<p id="section-5.5-5">Details about the mrcp-version and message-length fields are given
        in <a href="#sec.common" class="xref">Section 5.1</a>.</p>
<p id="section-5.5-6">The event-name identifies the nature of the event generated by the
        media resource. The set of valid event names depends on the resource
        generating it. See the corresponding resource-specific section of the
        document.</p>
<div id="section-5.5-7" class="artwork art-text art-abnf" text-align="left"><pre>
event-name       =  synthesizer-event
                 /  recognizer-event
                 /  recorder-event
                 /  verifier-event</pre></div>
<p id="section-5.5-8">The request-id used in the event MUST match the one sent in the
        request that caused this event.</p>
<p id="section-5.5-9">The request-state indicates whether the Request/Command causing
        this event is complete or still in progress and whether it is the same as the
        one mentioned in <a href="#sec.response" class="xref">Section 5.3</a>. The final event
        for a request has a COMPLETE status indicating the completion of the
        request.</p>
</div></section>
</div></section><section id="section-6"><h2 id="name-mrcpv2-generic-methods-head">
<a href="#section-6" class="section-number selfRef">6.Â </a><a href="#name-mrcpv2-generic-methods-head" class="section-name selfRef">MRCPv2 Generic Methods, Headers, and Result Structure</a>
</h2>
<p id="section-6-1">MRCPv2 supports a set of methods and header fields that are common to
      all resources. These are discussed here; resource-specific methods and
      header fields are discussed in the corresponding resource-specific
      section of the document.</p>
<section id="section-6.1"><div id="sec.genericMethods">
<h3 id="name-generic-methods">
<a href="#section-6.1" class="section-number selfRef">6.1.Â </a><a href="#name-generic-methods" class="section-name selfRef">Generic Methods</a>
</h3>
<p id="section-6.1-1">MRCPv2 supports two generic methods for reading and writing the
        state associated with a resource.</p>
<div id="section-6.1-2" class="artwork art-text art-abnf" text-align="left"><pre>
generic-method      =    "SET-PARAMS"
                    /    "GET-PARAMS"</pre></div>
<p id="section-6.1-3"></p>
<p id="section-6.1-4">These are described in the following subsections.</p>
<section id="section-6.1.1"><h4 id="name-set-params">
<a href="#section-6.1.1" class="section-number selfRef">6.1.1.Â </a><a href="#name-set-params" class="section-name selfRef">SET-PARAMS</a>
</h4>
<p id="section-6.1.1-1">The SET-PARAMS method, from the client to the server, tells the
          MRCPv2 resource to define parameters for the session, such as voice
          characteristics and prosody on synthesizers, recognition timers on
          recognizers, etc. If the server accepts and sets all parameters, it
          MUST return a response status-code of 200. If it chooses to ignore
          some optional header fields that can be safely ignored without
          affecting operation of the server, it MUST return 201.</p>
<p id="section-6.1.1-2">If one or more of the header fields being sent is incorrect,
          error 403, 404, or 409 MUST be returned as follows:

</p>
<ul>
<li id="section-6.1.1-4">If one or more of the header fields being set has an illegal
              value, the server MUST reject the request with a 404 Illegal
              Value for Header Field.</li>
<li id="section-6.1.1-5">If one or more of the header fields being set is unsupported
              for the resource, the server MUST reject the request with a 403
              Unsupported Header Field, except as described in the next
              paragraph.</li>
<li id="section-6.1.1-6">If one or more of the header fields being set has an
              unsupported value, the server MUST reject the request with a 409
              Unsupported Header Field Value, except as described in the next
              paragraph.</li>
</ul>
<p id="section-6.1.1-7">If both error 404 and another error have occurred, only error 404
          MUST be returned. If both errors 403 and 409 have occurred, but not
          error 404, only error 403 MUST be returned.</p>
<p id="section-6.1.1-8">If error 403, 404, or 409 is returned, the response MUST include
          the bad or unsupported header fields and their values exactly as
          they were sent from the client. Session parameters modified using
          SETâ€‘PARAMS do not override parameters explicitly specified on
          individual requests or requests that are IN-PROGRESS.</p>
<div id="section-6.1.1-9" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... SET-PARAMS 543256
       Channel-Identifier:32AECB23433802@speechsynth
       Voice-gender:female
       Voice-variant:3

S-&gt;C:  MRCP/2.0 ... 543256 200 COMPLETE
       Channel-Identifier:32AECB23433802@speechsynth
   </pre></div></section><section id="section-6.1.2"><h4 id="name-get-params">
<a href="#section-6.1.2" class="section-number selfRef">6.1.2.Â </a><a href="#name-get-params" class="section-name selfRef">GET-PARAMS</a>
</h4>
<p id="section-6.1.2-1">The GET-PARAMS method, from the client to the server, asks the
          MRCPv2 resource for its current session parameters, such as voice
          characteristics and prosody on synthesizers, recognition timers on
          recognizers, etc. For every header field the client sends in the
          request without a value, the server MUST include the header field
          and its corresponding value in the response. If no parameter header
          fields are specified by the client, then the server MUST return all
          the settable parameters and their values in the corresponding header
          section of the response, including vendor-specific parameters. Such
          wildcard parameter requests can be very processing-intensive, since
          the number of settable parameters can be large depending on the
          implementation. Hence, it is RECOMMENDED that the client not use the
          wildcard GET-PARAMS operation very often. Note that GET-PARAMS
          returns header field values that apply to the whole session and not
          values that have a request-level scope. For example,
          Input-Waveform-URI is a request-level header field and thus would
          not be returned by GET-PARAMS.</p>
<p id="section-6.1.2-2">If all of the header fields requested are supported, the server
          MUST return a response status-code of 200. If some of the header
          fields being retrieved are unsupported for the resource, the server
          MUST reject the request with a 403 Unsupported Header Field. Such a
          response MUST include the unsupported header fields exactly as they
          were sent from the client, without values.</p>
<div id="section-6.1.2-3" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... GET-PARAMS 543256
        Channel-Identifier:32AECB23433802@speechsynth
        Voice-gender:
        Voice-variant:
        Vendor-Specific-Parameters:com.example.param1;
                      com.example.param2

S-&gt;C:   MRCP/2.0 ... 543256 200 COMPLETE
        Channel-Identifier:32AECB23433802@speechsynth
        Voice-gender:female
        Voice-variant:3
        Vendor-Specific-Parameters:com.example.param1="Company Name";
                      com.example.param2="124324234@example.com"
</pre></div></section>
</div></section><section id="section-6.2"><div id="sec.genericHeaders">
<h3 id="name-generic-message-headers">
<a href="#section-6.2" class="section-number selfRef">6.2.Â </a><a href="#name-generic-message-headers" class="section-name selfRef">Generic Message Headers</a>
</h3>
<p id="section-6.2-1">All MRCPv2 header fields, which include both the generic-headers
        defined in the following subsections and the resource-specific header
        fields defined later, follow the same generic format as that given in
        Section 3.1 of <span>[<a href="#RFC5322" class="xref">RFC 5322</a>]. Each header
        field consists of a name followed by a colon (":") and the value.
        Header field names are case-insensitive. The value MAY be preceded by
        any amount of LWS (linear white space), though a single SP (space) is
        preferred. Header fields may extend over multiple lines by preceding
        each extra line with at least one SP or HT (horizontal tab).</span></p>
<div id="section-6.2-2" class="artwork art-text art-abnf" text-align="left"><pre>
generic-field  = field-name ":" [ field-value ]
field-name     = token
field-value    = *LWS field-content *( CRLF 1*LWS field-content)
field-content  = &lt;the OCTETs making up the field-value
                 and consisting of either *TEXT or combinations
                 of token, separators, and quoted-string&gt;
</pre></div>
<p id="section-6.2-3">The field-content does not include any leading or trailing LWS
        (i.e., linear white space occurring before the first non-whitespace
        character of the field-value or after the last non-whitespace
        character of the field-value). Such leading or trailing LWS MAY be
        removed without changing the semantics of the field value. Any LWS
        that occurs between field-content MAY be replaced with a single SP
        before interpreting the field value or forwarding the message
        downstream.</p>
<p id="section-6.2-4">MRCPv2 servers and clients MUST NOT depend on header field order.
        It is RECOMMENDED to send general-header fields first, followed by
        request-header or response-header fields, and ending with the
        entity-header fields. However, MRCPv2 servers and clients MUST be
        prepared to process the header fields in any order. The only exception
        to this rule is when there are multiple header fields with the same
        name in a message.</p>
<p id="section-6.2-5">Multiple header fields with the same name MAY be present in a
        message if and only if the entire value for that header field is
        defined as a comma-separated list [i.e., #(values)].</p>
<p id="section-6.2-6">Since vendor-specific parameters may be order-dependent, it MUST be
        possible to combine multiple header fields of the same name into one
        "name:value" pair without changing the semantics of the message, by
        appending each subsequent value to the first, each separated by a
        comma. The order in which header fields with the same name are
        received is therefore significant to the interpretation of the
        combined header field value, and thus an intermediary MUST NOT change
        the order of these values when a message is forwarded.</p>
<div id="section-6.2-7" class="artwork art-text art-abnf" text-align="left"><pre>
generic-header      =    channel-identifier
                    /    accept
                    /    active-request-id-list
                    /    proxy-sync-id
                    /    accept-charset
                    /    content-type
                    /    content-id
                    /    content-base
                    /    content-encoding
                    /    content-location
                    /    content-length
                    /    fetch-timeout
                    /    cache-control
                    /    logging-tag 
                    /    set-cookie
                    /    vendor-specific
</pre></div>
<section id="section-6.2.1"><div id="sec.channelIdentifier">
<h4 id="name-channel-identifier">
<a href="#section-6.2.1" class="section-number selfRef">6.2.1.Â </a><a href="#name-channel-identifier" class="section-name selfRef">Channel-Identifier</a>
</h4>
<p id="section-6.2.1-1">All MRCPv2 requests, responses, and events MUST contain the
          Channel-Identifier header field. The value is allocated by the
          server when a control channel is added to the session and
          communicated to the client by the "a=channel" attribute in the SDP
          answer from the server. The header field value consists of 2 parts
          separated by the '@' symbol. The first part is an unambiguous string
          identifying the MRCPv2 session. The second part is a string token
          that specifies one of the media processing resource types listed in
          <a href="#sec.resourceTypes" class="xref">Section 3.1</a>. The unambiguous string
          (first part) MUST be difficult to guess, unique among the resource instances managed by
          the server, and common to all resource channels with that server
          established through a single SIP dialog.</p>
<div id="section-6.2.1-2" class="artwork art-text art-abnf" text-align="left"><pre>
channel-identifier  = "Channel-Identifier" ":" channel-id CRLF
channel-id          = 1*alphanum "@" 1*alphanum
</pre></div>
</div></section><section id="section-6.2.2"><h4 id="name-accept">
<a href="#section-6.2.2" class="section-number selfRef">6.2.2.Â </a><a href="#name-accept" class="section-name selfRef">Accept</a>
</h4>
<p id="section-6.2.2-1">The Accept header field follows the syntax defined in [H14.1].
          The semantics are also identical, with the exception that if no
          Accept header field is present, the server MUST assume a default
          value that is specific to the resource type that is being
          controlled. This default value can be changed for a resource on a
          session by sending this header field in a SET-PARAMS method. The
          current default value of this header field for a resource in a
          session can be found through a GET-PARAMS method. This header field
          MAY occur on any request.</p></section><section id="section-6.2.3"><h4 id="name-active-request-id-list">
<a href="#section-6.2.3" class="section-number selfRef">6.2.3.Â </a><a href="#name-active-request-id-list" class="section-name selfRef">Active-Request-Id-List</a>
</h4>
<p id="section-6.2.3-1">In a request, this header field indicates the list of request-ids
          to which the request applies. This is useful when there are multiple
          requests that are PENDING or IN-PROGRESS and the client wants this
          request to apply to one or more of these specifically.</p>
<p id="section-6.2.3-2">In a response, this header field returns the list of request-ids
          that the method modified or affected. There could be one or more
          requests in a request-state of PENDING or IN-PROGRESS. When a method
          affecting one or more PENDING or IN-PROGRESS requests is sent from
          the client to the server, the response MUST contain the list of
          request-ids that were affected or modified by this command in its
          header section.</p>
<p id="section-6.2.3-3">The Active-Request-Id-List is only used in requests and
          responses, not in events.</p>
<p id="section-6.2.3-4">For example, if a STOP request with no Active-Request-Id-List is
          sent to a synthesizer resource that has one or more SPEAK requests
          in the PENDING or IN-PROGRESS state, all SPEAK requests MUST be
          cancelled, including the one IN-PROGRESS. The response to the STOP
          request contains in the Active-Request-Id-List value the request-ids
          of all the SPEAK requests that were terminated. After sending the
          STOP response, the server MUST NOT send any SPEAK-COMPLETE or
          RECOGNITION-COMPLETE events for the terminated requests.</p>
<div id="section-6.2.3-5" class="artwork art-text art-abnf" text-align="left"><pre>
active-request-id-list  =  "Active-Request-Id-List" ":" 
                           request-id *("," request-id) CRLF
</pre></div></section><section id="section-6.2.4"><h4 id="name-proxy-sync-id">
<a href="#section-6.2.4" class="section-number selfRef">6.2.4.Â </a><a href="#name-proxy-sync-id" class="section-name selfRef">Proxy-Sync-Id</a>
</h4>
<p id="section-6.2.4-1">When any server resource generates a "barge-in-able" event, it also
          generates a unique tag. The tag is sent as this header field's value
          in an event to the client. The client then acts as an intermediary
          among the server resources and sends a BARGE-IN-OCCURRED method to
          the synthesizer server resource with the Proxy-Sync-Id it received
          from the server resource. When the recognizer and synthesizer
          resources are part of the same session, they may choose to work
          together to achieve quicker interaction and response. Here, the
          Proxy-Sync-Id helps the resource receiving the event, intermediated
          by the client, to decide if this event has been processed through a
          direct interaction of the resources. This header field MAY occur
          only on events and the BARGE-IN-OCCURRED method. The name of this
          header field contains the word 'proxy' only for historical reasons
          and does not imply that a proxy server is involved.</p>
<div id="section-6.2.4-2" class="artwork art-text art-abnf" text-align="left"><pre>
proxy-sync-id    =  "Proxy-Sync-Id" ":" 1*VCHAR CRLF
            </pre></div></section><section id="section-6.2.5"><h4 id="name-accept-charset">
<a href="#section-6.2.5" class="section-number selfRef">6.2.5.Â </a><a href="#name-accept-charset" class="section-name selfRef">Accept-Charset</a>
</h4>
<p id="section-6.2.5-1">See [H14.2]. This specifies the acceptable character sets for
          entities returned in the response or events associated with this
          request. This is useful in specifying the character set to use in
          the Natural Language Semantic Markup Language (NLSML) results of a
          RECOGNITION-COMPLETE event. This header field is only used on
          requests.</p></section><section id="section-6.2.6"><h4 id="name-content-type">
<a href="#section-6.2.6" class="section-number selfRef">6.2.6.Â </a><a href="#name-content-type" class="section-name selfRef">Content-Type</a>
</h4>
<p id="section-6.2.6-1">See [H14.17]. MRCPv2 supports a restricted set of registered
          media types for content, including speech markup, grammar, and
          recognition results. The content types applicable to each MRCPv2
          resource-type are specified in the corresponding section of the
          document and are registered in the MIME Media Types registry
          maintained by IANA. The multipart content type "multipart/mixed"
          is supported to communicate multiple of the above mentioned
          contents, in which case the body parts MUST NOT contain any MRCPv2-specific header fields. This header field MAY occur on all
          messages.</p>
<div id="section-6.2.6-2" class="artwork art-text art-abnf" text-align="left"><pre>
content-type     =    "Content-Type" ":" media-type-value CRLF

media-type-value =    type "/" subtype *( ";" parameter )

type             =    token

subtype          =    token

parameter        =    attribute "=" value

attribute        =    token

value            =    token / quoted-string
            </pre></div></section><section id="section-6.2.7"><div id="sec.Content-ID">
<h4 id="name-content-id">
<a href="#section-6.2.7" class="section-number selfRef">6.2.7.Â </a><a href="#name-content-id" class="section-name selfRef">Content-ID</a>
</h4>
<p id="section-6.2.7-1">This header field contains an ID or name for the content by which
          it can be referenced. This header field operates according to the
          specification in <span>[<a href="#RFC2392" class="xref">RFC 2392</a>] and is
          required for content disambiguation in multipart messages. In
          MRCPv2, whenever the associated content is stored by either the
          client or the server, it MUST be retrievable using this ID. Such
          content can be referenced later in a session by addressing it with
          the 'session' URI scheme described in </span><a href="#sec.sessionURIScheme" class="xref">Section 13.6</a>. This header field MAY occur
          on all messages.</p>
</div></section><section id="section-6.2.8"><h4 id="name-content-base">
<a href="#section-6.2.8" class="section-number selfRef">6.2.8.Â </a><a href="#name-content-base" class="section-name selfRef">Content-Base</a>
</h4>
<p id="section-6.2.8-1">The Content-Base entity-header MAY be used to specify the base
          URI for resolving relative URIs within the entity.</p>
<div id="section-6.2.8-2" class="artwork art-text art-abnf" text-align="left"><pre>
content-base      = "Content-Base" ":" absoluteURI CRLF
            </pre></div>
<p id="section-6.2.8-3">Note, however, that the base URI of the contents within the
          entity-body may be redefined within that entity-body. An example of
          this would be multipart media, which in turn can have multiple
          entities within it. This header field MAY occur on all messages.</p></section><section id="section-6.2.9"><h4 id="name-content-encoding">
<a href="#section-6.2.9" class="section-number selfRef">6.2.9.Â </a><a href="#name-content-encoding" class="section-name selfRef">Content-Encoding</a>
</h4>
<p id="section-6.2.9-1">The Content-Encoding entity-header is used as a modifier to the
          Content-Type. When present, its value indicates what additional
          content encoding has been applied to the entity-body, and thus what
          decoding mechanisms must be applied in order to obtain the Media
          Type referenced by the Content-Type header field. Content-Encoding
          is primarily used to allow a document to be compressed without
          losing the identity of its underlying media type. Note that the SIP
          session can be used to determine accepted encodings (see <a href="#sec.resourceDiscovery" class="xref">Section 7</a>). This header field MAY occur
          on all messages.</p>
<div id="section-6.2.9-2" class="artwork art-text art-abnf" text-align="left"><pre>
content-encoding  = "Content-Encoding" ":" 
                    *WSP content-coding 
                    *(*WSP "," *WSP content-coding *WSP )
                    CRLF
</pre></div>
<p id="section-6.2.9-3">Content codings are defined in [H3.5]. An example of its use
          is</p>
<div id="section-6.2.9-4" class="artwork art-text" text-align="left"><pre>Content-Encoding:gzip</pre></div>
<p id="section-6.2.9-5">If multiple encodings have been applied to an entity, the content
          encodings MUST be listed in the order in which they were
          applied.</p></section><section id="section-6.2.10"><h4 id="name-content-location">
<a href="#section-6.2.10" class="section-number selfRef">6.2.10.Â </a><a href="#name-content-location" class="section-name selfRef">Content-Location</a>
</h4>
<p id="section-6.2.10-1">The Content-Location entity-header MAY be used to supply the
          resource location for the entity enclosed in the message when that
          entity is accessible from a location separate from the requested
          resource's URI. Refer to [H14.14].</p>
<div id="section-6.2.10-2" class="artwork art-text art-abnf" text-align="left"><pre>
content-location  =  "Content-Location" ":"
                     ( absoluteURI / relativeURI ) CRLF
</pre></div>
<p id="section-6.2.10-3">The Content-Location value is a statement of the location of the
          resource corresponding to this particular entity at the time of the
          request. This header field is provided for optimization purposes
          only. The receiver of this header field MAY assume that the entity
          being sent is identical to what would have been retrieved or might
          already have been retrieved from the Content-Location URI.</p>
<p id="section-6.2.10-4">For example, if the client provided a grammar markup inline, and
          it had previously retrieved it from a certain URI, that URI can be
          provided as part of the entity, using the Content-Location header
          field. This allows a resource like the recognizer to look into its
          cache to see if this grammar was previously retrieved, compiled, and
          cached. In this case, it might optimize by using the previously
          compiled grammar object.</p>
<p id="section-6.2.10-5">If the Content-Location is a relative URI, the relative URI is
          interpreted relative to the Content-Base URI. This header field MAY
          occur on all messages.</p></section><section id="section-6.2.11"><h4 id="name-content-length">
<a href="#section-6.2.11" class="section-number selfRef">6.2.11.Â </a><a href="#name-content-length" class="section-name selfRef">Content-Length</a>
</h4>
<p id="section-6.2.11-1">This header field contains the length of the content of
          the message body (i.e., after the double CRLF following the
          last header field). Unlike in HTTP, it MUST be included in
          all messages that carry content beyond the header
          section. If it is missing, a default value of zero is
          assumed.  Otherwise, it is interpreted according to
          [H14.13]. When a message having no use for a message body
          contains one, i.e., the Content-Length is non-zero, the
          receiver MUST ignore the content of the message body. This
          header field MAY occur on all messages.</p>
<div id="section-6.2.11-2" class="artwork art-text" text-align="left"><pre>
content-length  =  "Content-Length" ":" 1*19DIGIT CRLF
</pre></div></section><section id="section-6.2.12"><div id="sec.FetchTimeout">
<h4 id="name-fetch-timeout">
<a href="#section-6.2.12" class="section-number selfRef">6.2.12.Â </a><a href="#name-fetch-timeout" class="section-name selfRef">Fetch Timeout</a>
</h4>
<p id="section-6.2.12-1">When the recognizer or synthesizer needs to fetch documents or
          other resources, this header field controls the corresponding URI
          access properties. This defines the timeout for content that the
          server may need to fetch over the network. The value is interpreted
          to be in milliseconds and ranges from 0 to an
          implementation-specific maximum value. It is RECOMMENDED that servers be cautious about accepting long timeout values.  The default value for this
          header field is implementation specific. This header field MAY occur
          in DEFINE-GRAMMAR, RECOGNIZE, SPEAK, SET-PARAMS, or GET-PARAMS.</p>
<div id="section-6.2.12-2" class="artwork art-text" text-align="left"><pre>
fetch-timeout       =   "Fetch-Timeout" ":" 1*19DIGIT CRLF
            </pre></div>
</div></section><section id="section-6.2.13"><h4 id="name-cache-control">
<a href="#section-6.2.13" class="section-number selfRef">6.2.13.Â </a><a href="#name-cache-control" class="section-name selfRef">Cache-Control</a>
</h4>
<p id="section-6.2.13-1">If the server implements content caching, it MUST adhere to the
          cache correctness rules of <span>[<a href="#RFC2616" class="xref">HTTP 1.1</a>]
          when accessing and caching stored content. In particular, the
          "expires" and "cache-control" header fields of the cached URI or
          document MUST be honored and take precedence over the Cache-Control
          defaults set by this header field. The Cache-Control directives are
          used to define the default caching algorithms on the server for the
          session or request. The scope of the directive is based on the
          method it is sent on. If the directive is sent on a SET-PARAMS
          method, it applies for all requests for external documents the
          server makes during that session, unless it is overridden by a
          Cache-Control header field on an individual request. If the
          directives are sent on any other requests, they apply only to
          external document requests the server makes for that request. An
          empty Cache-Control header field on the GET-PARAMS method is a
          request for the server to return the current Cache-Control
          directives setting on the server. This header field MAY occur only
          on requests.</span></p>
<div id="section-6.2.13-2" class="artwork art-text" text-align="left"><pre>
cache-control    =    "Cache-Control" ":" 
                      [*WSP cache-directive
                      *( *WSP "," *WSP cache-directive *WSP )]
                      CRLF

cache-directive     = "max-age" "=" delta-seconds    
                    / "max-stale" [ "=" delta-seconds ]
                    / "min-fresh" "=" delta-seconds 

delta-seconds       = 1*19DIGIT    
</pre></div>
<p id="section-6.2.13-3">Here, delta-seconds is a decimal time value specifying the number
          of seconds since the instant the message response or data was
          received by the server.</p>
<p id="section-6.2.13-4">The different cache-directive options allow the client to ask the
          server to override the default cache expiration mechanisms:

</p>
<dl id="section-6.2.13-5" class="dlParallel">
<dt id="section-6.2.13-6">max-age</dt>
<dd id="section-6.2.13-7">Indicates that the client can tolerate the
              server using content whose age is no greater than the specified
              time in seconds. Unless a "max-stale" directive is also
              included, the client is not willing to accept a response based
              on stale data.</dd>
<dt id="section-6.2.13-8">min-fresh</dt>
<dd id="section-6.2.13-9">Indicates that the client is willing to
              accept a server response with cached data whose expiration is no
              less than its current age plus the specified time in seconds. If
              the server's cache time-to-live exceeds the client-supplied
              min-fresh value, the server MUST NOT utilize cached content.</dd>
<dt id="section-6.2.13-10">max-stale</dt>
<dd id="section-6.2.13-11">Indicates that the client is willing to
              allow a server to utilize cached data that has exceeded its
              expiration time. If "max-stale" is assigned a value, then the
              client is willing to allow the server to use cached data that
              has exceeded its expiration time by no more than the specified
              number of seconds. If no value is assigned to "max-stale", then
              the client is willing to allow the server to use stale data of
              any age.</dd>
</dl>
<p id="section-6.2.13-12">If the server cache is requested to use stale response/data
          without validation, it MAY do so only if this does not conflict with
          any "MUST"-level requirements concerning cache validation (e.g., a
          "must-revalidate" Cache-Control directive in the HTTP 1.1
          specification pertaining to the corresponding URI).</p>
<p id="section-6.2.13-13">If both the MRCPv2 Cache-Control directive and the cached entry
          on the server include "max-age" directives, then the lesser of the
          two values is used for determining the freshness of the cached entry
          for that request.</p></section><section id="section-6.2.14"><h4 id="name-logging-tag">
<a href="#section-6.2.14" class="section-number selfRef">6.2.14.Â </a><a href="#name-logging-tag" class="section-name selfRef">Logging-Tag</a>
</h4>
<p id="section-6.2.14-1">This header field MAY be sent as part of a SET-PARAMS/GET-PARAMS
          method to set or retrieve the logging tag for logs generated by the
          server. Once set, the value persists until a new value is set or the
          session ends. The MRCPv2 server MAY provide a mechanism to
          create subsets of
          its output logs so that system administrators can examine or extract
          only the log file portion during which the logging tag was set to a
          certain value.</p>
<p id="section-6.2.14-2">It is RECOMMENDED that clients include in the logging tag
          information to identify the MRCPv2 client User Agent, so
          that one can determine which MRCPv2 client request generated
          a given log message at the server.  It is also RECOMMENDED that
          MRCPv2 clients not log personally identifiable information
          such as credit card numbers and national identification
          numbers.</p>
<div id="section-6.2.14-3" class="artwork art-text" text-align="left"><pre>
logging-tag    = "Logging-Tag" ":" 1*UTFCHAR CRLF
            </pre></div></section><section id="section-6.2.15"><div id="sec.SetCookie">
<h4 id="name-set-cookie">
<a href="#section-6.2.15" class="section-number selfRef">6.2.15.Â </a><a href="#name-set-cookie" class="section-name selfRef">Set-Cookie</a>
</h4>
<p id="section-6.2.15-1">Since the associated HTTP client on an MRCPv2 server fetches
          documents for processing on behalf of the MRCPv2 client, the cookie
          store in the HTTP client of the MRCPv2 server is treated as an
          extension of the cookie store in the HTTP client of the MRCPv2
          client. This requires that the MRCPv2 client and server be able to
          synchronize their common cookie store as needed. To enable the
          MRCPv2 client to push its stored cookies to the MRCPv2 server and
          get new cookies from the MRCPv2 server stored back to the MRCPv2
          client, the Set-Cookie entity-header field MAY be included in MRCPv2
          requests to update the cookie store on a server and be returned in
          final MRCPv2 responses or events to subsequently update the client's
          own cookie store. The stored cookies on the server persist for the
          duration of the MRCPv2 session and MUST be destroyed at the end of
          the session. To ensure support for cookies, MRCPv2 clients and
          servers MUST support the Set-Cookie entity-header field.</p>
<p id="section-6.2.15-2">Note that it is the MRCPv2 client that determines which,
          if any, cookies are sent to the server.  There is no
          requirement that all cookies be shared.  Rather, it is
          RECOMMENDED that MRCPv2 clients communicate only cookies
          needed by the MRCPv2 server to process its requests.</p>
<div id="section-6.2.15-3" class="artwork art-text" text-align="left"><pre>
set-cookie      =       "Set-Cookie:" cookies CRLF
cookies         =       cookie *("," *LWS cookie)
cookie          =       attribute "=" value *(";" cookie-av)
cookie-av       =       "Comment" "=" value
                /       "Domain" "=" value
                /       "Max-Age" "=" value
                /       "Path" "=" value
                /       "Secure"
                /       "Version" "=" 1*19DIGIT
                /       "Age" "=" delta-seconds

set-cookie        = "Set-Cookie:" SP set-cookie-string
set-cookie-string = cookie-pair *( ";" SP cookie-av )
cookie-pair       = cookie-name "=" cookie-value
cookie-name       = token
cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )
cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E
token             = &lt;token, defined in [RFC2616], Section 2.2&gt;

cookie-av         = expires-av / max-age-av / domain-av /
                     path-av / secure-av / httponly-av /
                     extension-av / age-av
expires-av        = "Expires=" sane-cookie-date
sane-cookie-date  = &lt;rfc1123-date, from [RFC2616], Section 3.3.1&gt;
max-age-av        = "Max-Age=" non-zero-digit *DIGIT
non-zero-digit    = %x31-39
domain-av         = "Domain=" domain-value
domain-value      = &lt;subdomain&gt;
path-av           = "Path=" path-value
path-value        = &lt;any CHAR except CTLs or ";"&gt;
secure-av         = "Secure"
httponly-av       = "HttpOnly"
extension-av      = &lt;any CHAR except CTLs or ";"&gt;
age-av            = "Age=" delta-seconds
</pre></div>
<p id="section-6.2.15-4">The Set-Cookie header field is specified
          in <span>[<a href="#RFC6265" class="xref">RFC 6265</a>]. The "Age"
          attribute is introduced in this specification to indicate
          the age of the cookie and is OPTIONAL. An MRCPv2 client or
          server MUST calculate the age of the cookie according to the
          age calculation rules in the </span><span>[<a href="#RFC2616" class="xref">HTTP/1.1
          specification</a>] and append the "Age" attribute
          accordingly.  This attribute is provided because time may
          have passed since the client received the cookie from an
          HTTP server. Rather than having the client reduce Max-Age by
          the actual age, it passes Max-Age verbatim and appends the
          "Age" attribute, thus maintaining the cookie as received while
          still accounting for the fact that time has passed.</span></p>
<p id="section-6.2.15-5">The MRCPv2 client or server MUST supply defaults for the "Domain"
          and "Path" attributes, as
          specified in RFC 6265, if they are omitted by the HTTP origin server. Note that there is no leading dot present in
          the "Domain" attribute value in this case. Although an explicitly
          specified "Domain" value received via the HTTP protocol may be
          modified to include a leading dot, an MRCPv2 client or server MUST
          NOT modify the "Domain" value when received via the MRCPv2
          protocol.</p>
<p id="section-6.2.15-6">An MRCPv2 client or server MAY combine multiple cookie header
          fields of the same type into a single "field-name:field-value" pair
          as described in <a href="#sec.genericHeaders" class="xref">Section 6.2</a>.</p>
<p id="section-6.2.15-7">The Set-Cookie header field MAY be specified in any request that
          subsequently results in the server performing an HTTP access. When a
          server receives new cookie information from an HTTP origin server,
          and assuming the cookie store is modified according to RFC 6265, the
          server MUST return the new cookie information in the MRCPv2 COMPLETE
          response or event, as appropriate, to allow the client to update its
          own cookie store.</p>
<p id="section-6.2.15-8">The SET-PARAMS request MAY specify the Set-Cookie header field to
          update the cookie store on a server. The GET-PARAMS request MAY be
          used to return the entire cookie store of "Set-Cookie" type cookies
          to the client.</p>
</div></section><section id="section-6.2.16"><h4 id="name-vendor-specific-parameters">
<a href="#section-6.2.16" class="section-number selfRef">6.2.16.Â </a><a href="#name-vendor-specific-parameters" class="section-name selfRef">Vendor-Specific Parameters</a>
</h4>
<p id="section-6.2.16-1">This set of header fields allows for the client to set or
          retrieve vendor-specific parameters.</p>
<div id="section-6.2.16-2" class="artwork art-text" text-align="left"><pre>
vendor-specific          =    "Vendor-Specific-Parameters" ":"
                              [vendor-specific-av-pair 
                              *(";" vendor-specific-av-pair)] CRLF 

vendor-specific-av-pair  = vendor-av-pair-name "=" 
                           value

vendor-av-pair-name     = 1*UTFCHAR
</pre></div>
<p id="section-6.2.16-3">Header fields of this form MAY be sent in any method (request)
          and are used to manage implementation-specific parameters on the
          server side. The vendor-av-pair-name follows the reverse Internet
          Domain Name convention (see <a href="#sec.vendorSpecificRegistration" class="xref">Section 13.1.6</a> for syntax and
          registration information). The value of the vendor attribute is
          specified after the "=" symbol and MAY be quoted. For example:</p>
<div id="section-6.2.16-4" class="artwork art-text" text-align="left"><pre>
com.example.companyA.paramxyz=256
com.example.companyA.paramabc=High
com.example.companyB.paramxyz=Low
</pre></div>
<p id="section-6.2.16-5">When used in GET-PARAMS to get the current value of these
          parameters from the server, this header field value MAY contain a
          semicolon-separated list of implementation-specific attribute
          names.</p></section>
</div></section><section id="section-6.3"><div id="sec.result">
<h3 id="name-generic-result-structure">
<a href="#section-6.3" class="section-number selfRef">6.3.Â </a><a href="#name-generic-result-structure" class="section-name selfRef">Generic Result Structure</a>
</h3>
<p id="section-6.3-1">Result data from the server for the Recognizer and Verifier
        resources is carried as a typed media entity in the MRCPv2 message
        body of various events. The Natural Language Semantics Markup Language
        (NLSML), an XML markup based on an early draft from the W3C, is the
        default standard for returning results back to the client. Hence, all
        servers implementing these resource types MUST support the media type
        'application/nlsml+xml'. The <span>[<a href="#W3C.REC-emma-20090210" class="xref">Extensible MultiModal Annotation (EMMA)</a>] format can be used to return results as well. This can be done
        by negotiating the format at session establishment time with SDP
        (a=resultformat:application/emma+xml) or with SIP (Allow/Accept). With
        SIP, for example, if a client wants results in EMMA, an MRCPv2 server
        can route the request to another server that supports EMMA by
        inspecting the SIP header fields, rather than having to inspect
         the SDP.</span></p>
<p id="section-6.3-2">MRCPv2 uses this representation to convey content among the clients
        and servers that generate and make use of the markup. MRCPv2 uses
        NSLML specifically to convey recognition, enrollment, and verification
        results between the corresponding resource on the MRCPv2 server and
        the MRCPv2 client. Details of this result format are fully described
        in <a href="#sec.NLSML" class="xref">Section 6.3.1</a>.</p>
<figure id="figure-5"><div><div id="section-6.3-3" class="artwork art-text" text-align="left"><pre>
Content-Type:application/nlsml+xml
Content-Length:...

&lt;?xml version="1.0"?&gt;
&lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
        xmlns:ex="http://www.example.com/example"
        grammar="http://theYesNoGrammar"&gt;
    &lt;interpretation&gt;
        &lt;instance&gt;
                &lt;ex:response&gt;yes&lt;/ex:response&gt;
        &lt;/instance&gt;
        &lt;input&gt;OK&lt;/input&gt;
    &lt;/interpretation&gt;
&lt;/result&gt;
</pre></div></div>
<figcaption><a href="#figure-5">Figure 5</a><a href="#name-result-example" id="name-result-example" class="selfRef">Result Example</a></figcaption></figure><section id="section-6.3.1"><div id="sec.NLSML">
<h4 id="name-natural-language-semantics-">
<a href="#section-6.3.1" class="section-number selfRef">6.3.1.Â </a><a href="#name-natural-language-semantics-" class="section-name selfRef">Natural Language Semantics Markup Language</a>
</h4>
<p id="section-6.3.1-1">The Natural Language Semantics Markup Language (NLSML) is an XML
          data structure with elements and attributes designed to carry result
          information from recognizer (including enrollment) and verifier
          resources. The normative definition of NLSML is the RelaxNG schema
          in <a href="#sec.schema.NLSML" class="xref">Section 16.1</a>. Note that the elements
          and attributes of this format are defined in the MRCPv2 namespace.
          In the result structure, they must either be prefixed by a namespace
          prefix declared within the result or must be children of an element
          identified as belonging to the respective namespace. For details on
          how to use XML Namespaces, see <span>[<a href="#W3C.REC-xml-names11-20040204" class="xref">W3C.REC-xml-names11-20040204</a>]. Section 2 of </span><span>[<a href="#W3C.REC-xml-names11-20040204" class="xref">W3C.REC-xml-names11-20040204</a>] provides details on
          how to declare namespaces and namespace prefixes.</span></p>
<p id="section-6.3.1-2">The root element of NLSML is &lt;result&gt;. Optional child
          elements are &lt;interpretation&gt;, &lt;enrollment-result&gt;, and
          &lt;verification-result&gt;, at least one of which must be present.
          A single &lt;result&gt; MAY contain any or all of the optional child
          elements. Details of the &lt;result&gt; and &lt;interpretation&gt;
          elements and their subelements and attributes can be found in <a href="#sec.recognizerResults" class="xref">Section 9.6</a>. Details of the
          &lt;enrollment-result&gt; element and its subelements can be found
          in <a href="#sec.enrollmentResults" class="xref">Section 9.7</a>. Details of the
          &lt;verification-result&gt; element and its subelements can be found
          in <a href="#sec.verificationResults" class="xref">Section 11.5.2</a>.</p>
</div></section>
</div></section></section><section id="section-7"><div id="sec.resourceDiscovery">
<h2 id="name-resource-discovery">
<a href="#section-7" class="section-number selfRef">7.Â </a><a href="#name-resource-discovery" class="section-name selfRef">Resource Discovery</a>
</h2>
<p id="section-7-1">Server resources may be discovered and their capabilities learned by
      clients through standard SIP machinery. The client MAY issue a SIP
      OPTIONS transaction to a server, which has the effect of requesting the
      capabilities of the server. The server MUST respond to such a request
      with an SDP-encoded description of its capabilities according to <span>[<a href="#RFC3264" class="xref">RFC 3264</a>]. The MRCPv2 capabilities are described
      by a single "m=" line containing the media type "application" and transport
      type "TCP/TLS/MRCPv2" or "TCP/MRCPv2". There MUST be one "resource"
      attribute for each media resource that the server supports, and
      it has the
      resource type identifier as its value.</span></p>
<p id="section-7-2">The SDP description MUST also contain "m=" lines describing the audio
      capabilities and the coders the server supports.</p>
<p id="section-7-3">In this example, the client uses the SIP OPTIONS method to
        query the capabilities of the MRCPv2 server.</p>
<figure id="figure-6"><div><div id="section-7-4" class="artwork art-text" text-align="left"><pre>
C-&gt;S:
     OPTIONS sip:mrcp@server.example.com SIP/2.0
     Via:SIP/2.0/TCP client.atlanta.example.com:5060;
      branch=z9hG4bK74bf7
     Max-Forwards:6
     To:&lt;sip:mrcp@example.com&gt;
     From:Sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
     Call-ID:a84b4c76e66710
     CSeq:63104 OPTIONS
     Contact:&lt;sip:sarvi@client.example.com&gt;
     Accept:application/sdp
     Content-Length:0


S-&gt;C:
     SIP/2.0 200 OK
     Via:SIP/2.0/TCP client.atlanta.example.com:5060;
      branch=z9hG4bK74bf7;received=192.0.32.10
     To:&lt;sip:mrcp@example.com&gt;;tag=62784
     From:Sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
     Call-ID:a84b4c76e66710
     CSeq:63104 OPTIONS
     Contact:&lt;sip:mrcp@server.example.com&gt;
     Allow:INVITE, ACK, CANCEL, OPTIONS, BYE
     Accept:application/sdp
     Accept-Encoding:gzip
     Accept-Language:en
     Supported:foo
     Content-Type:application/sdp
     Content-Length:...
     
     v=0
     o=sarvi 2890844536 2890842811 IN IP4 192.0.2.12
     s=-
     i=MRCPv2 server capabilities
     c=IN IP4 192.0.2.12/127
     t=0 0
     m=application 0 TCP/TLS/MRCPv2 1 
     a=resource:speechsynth
     a=resource:speechrecog
     a=resource:speakverify
     m=audio 0 RTP/AVP 0 3
     a=rtpmap:0 PCMU/8000
     a=rtpmap:3 GSM/8000
</pre></div></div>
<figcaption><a href="#figure-6">Figure 6</a><a href="#name-using-sip-options-for-mrcpv" id="name-using-sip-options-for-mrcpv" class="selfRef">Using SIP OPTIONS for MRCPv2 Server Capability Discovery</a></figcaption></figure>
</div></section><section id="section-8"><div id="sec.synthesizerResource">
<h2 id="name-speech-synthesizer-resource">
<a href="#section-8" class="section-number selfRef">8.Â </a><a href="#name-speech-synthesizer-resource" class="section-name selfRef">Speech Synthesizer Resource</a>
</h2>
<p id="section-8-1">This resource processes text markup provided by the client and
      generates a stream of synthesized speech in real time. Depending upon
      the server implementation and capability of this resource, the client
      can also dictate parameters of the synthesized speech such as voice
      characteristics, speaker speed, etc.</p>
<p id="section-8-2">The synthesizer resource is controlled by MRCPv2 requests from the
      client. Similarly, the resource can respond to these requests or
      generate asynchronous events to the client to indicate conditions of
      interest to the client during the generation of the synthesized speech
      stream.</p>
<p id="section-8-3">This section applies for the following resource types:

</p>
<ul>
<li id="section-8-5">speechsynth</li>
<li id="section-8-6">basicsynth</li>
</ul>
<p id="section-8-7">The capabilities of these resources are defined in <a href="#sec.resourceTypes" class="xref">Section 3.1</a>.</p>
<section id="section-8.1"><h3 id="name-synthesizer-state-machine">
<a href="#section-8.1" class="section-number selfRef">8.1.Â </a><a href="#name-synthesizer-state-machine" class="section-name selfRef">Synthesizer State Machine</a>
</h3>
<p id="section-8.1-1">The synthesizer maintains a state machine to process MRCPv2
        requests from the client. The state transitions shown below describe
        the states of the synthesizer and reflect the state of the request at
        the head of the synthesizer resource queue. A SPEAK request in the
        PENDING state can be deleted or stopped by a STOP request without
        affecting the state of the resource.</p>
<figure id="figure-7"><div><div id="section-8.1-2" class="artwork art-text" text-align="left"><pre>
Idle                    Speaking                  Paused
State                   State                     State
  |                        |                          |
  |----------SPEAK--------&gt;|                 |--------|
  |&lt;------STOP-------------|             CONTROL      |
  |&lt;----SPEAK-COMPLETE-----|                 |-------&gt;|
  |&lt;----BARGE-IN-OCCURRED--|                          |
  |              |---------|                          |
  |          CONTROL       |-----------PAUSE---------&gt;|
  |              |--------&gt;|&lt;----------RESUME---------|
  |                        |               |----------|
  |----------|             |              PAUSE       |
  |    BARGE-IN-OCCURRED   |               |---------&gt;|
  |&lt;---------|             |----------|               |
  |                        |      SPEECH-MARKER       |
  |                        |&lt;---------|               |
  |----------|             |----------|               |
  |         STOP           |       RESUME             |
  |          |             |&lt;---------|               |
  |&lt;---------|             |                          |
  |&lt;---------------------STOP-------------------------|
  |----------|             |                          |
  |     DEFINE-LEXICON     |                          |
  |          |             |                          |
  |&lt;---------|             |                          |
  |&lt;---------------BARGE-IN-OCCURRED------------------|
</pre></div></div>
<figcaption><a href="#figure-7">Figure 7</a><a href="#name-synthesizer-state-machine-2" id="name-synthesizer-state-machine-2" class="selfRef">Synthesizer State Machine</a></figcaption></figure></section><section id="section-8.2"><h3 id="name-synthesizer-methods">
<a href="#section-8.2" class="section-number selfRef">8.2.Â </a><a href="#name-synthesizer-methods" class="section-name selfRef">Synthesizer Methods</a>
</h3>
<p id="section-8.2-1">The synthesizer supports the following methods.</p>
<div id="section-8.2-2" class="artwork art-text" text-align="left"><pre>
synthesizer-method   =  "SPEAK"
                     /  "STOP"
                     /  "PAUSE"
                     /  "RESUME"
                     /  "BARGE-IN-OCCURRED"
                     /  "CONTROL"
                     /  "DEFINE-LEXICON"
</pre></div></section><section id="section-8.3"><h3 id="name-synthesizer-events">
<a href="#section-8.3" class="section-number selfRef">8.3.Â </a><a href="#name-synthesizer-events" class="section-name selfRef">Synthesizer Events</a>
</h3>
<p id="section-8.3-1">The synthesizer can generate the following events.</p>
<div id="section-8.3-2" class="artwork art-text" text-align="left"><pre>
synthesizer-event    =  "SPEECH-MARKER"
                     /  "SPEAK-COMPLETE"
</pre></div></section><section id="section-8.4"><div id="sec.synthesizeHeaders">
<h3 id="name-synthesizer-header-fields">
<a href="#section-8.4" class="section-number selfRef">8.4.Â </a><a href="#name-synthesizer-header-fields" class="section-name selfRef">Synthesizer Header Fields</a>
</h3>
<p id="section-8.4-1">A synthesizer method can contain header fields containing request
        options and information to augment the Request, Response, or Event it
        is associated with.</p>
<div id="section-8.4-2" class="artwork art-text" text-align="left"><pre>
synthesizer-header  =  jump-size       
                    /  kill-on-barge-in  
                    /  speaker-profile   
                    /  completion-cause
                    /  completion-reason  
                    /  voice-parameter   
                    /  prosody-parameter
                    /  speech-marker     
                    /  speech-language 
                    /  fetch-hint        
                    /  audio-fetch-hint  
                    /  failed-uri        
                    /  failed-uri-cause  
                    /  speak-restart     
                    /  speak-length 
                    /  load-lexicon
                    /  lexicon-search-order
</pre></div>
<section id="section-8.4.1"><h4 id="name-jump-size">
<a href="#section-8.4.1" class="section-number selfRef">8.4.1.Â </a><a href="#name-jump-size" class="section-name selfRef">Jump-Size</a>
</h4>
<p id="section-8.4.1-1">This header field MAY be specified in a CONTROL method and
          controls the amount to jump forward or backward in an active SPEAK
          request. A '+' or '-' indicates a relative value to what is being
          currently played. This header field MAY also be specified in a SPEAK
          request as a desired offset into the synthesized speech. In this
          case, the synthesizer MUST begin speaking from this amount of time
          into the speech markup. Note that an offset that extends beyond the
          end of the produced speech will result in audio of length zero. The
          different speech length units supported are dependent on the
          synthesizer implementation. If the synthesizer resource does not
          support a unit for the operation, the resource MUST respond with a
          status-code of 409 "Unsupported Header Field Value".</p>
<div id="section-8.4.1-2" class="artwork art-text" text-align="left"><pre>
jump-size             =   "Jump-Size" ":" speech-length-value CRLF

speech-length-value   =   numeric-speech-length
                      /   text-speech-length

text-speech-length    =   1*UTFCHAR SP "Tag"

numeric-speech-length =    ("+" / "-") positive-speech-length

positive-speech-length =   1*19DIGIT SP numeric-speech-unit

numeric-speech-unit   =   "Second"
                      /   "Word"
                      /   "Sentence"
                      /   "Paragraph"
</pre></div></section><section id="section-8.4.2"><div id="sec.kill-on-barge-in">
<h4 id="name-kill-on-barge-in">
<a href="#section-8.4.2" class="section-number selfRef">8.4.2.Â </a><a href="#name-kill-on-barge-in" class="section-name selfRef">Kill-On-Barge-In</a>
</h4>
<p id="section-8.4.2-1">This header field MAY be sent as part of the SPEAK method to
          enable "kill-on-barge-in" support. If enabled, the SPEAK method is
          interrupted by DTMF input detected by a signal detector resource or
          by the start of speech sensed or recognized by the speech recognizer
          resource.</p>
<div id="section-8.4.2-2" class="artwork art-text" text-align="left"><pre>
kill-on-barge-in      =   "Kill-On-Barge-In" ":" BOOLEAN CRLF
</pre></div>
<p id="section-8.4.2-3">The client MUST send a BARGE-IN-OCCURRED method to the
          synthesizer resource when it receives a barge-in-able event from any
          source. This source could be a synthesizer resource or signal
          detector resource and MAY be either local or distributed. If this
          header field is not specified in a SPEAK request or explicitly set
          by a SETâ€‘PARAMS, the default value for this header field is
          "true".</p>
<p id="section-8.4.2-4">If the recognizer or signal detector resource is on the same
          server as the synthesizer and both are part of the same session, the
          server MAY work with both to provide internal notification to the
          synthesizer so that audio may be stopped without having to wait for
          the client's BARGE-IN-OCCURRED event.</p>
<p id="section-8.4.2-5">It is generally RECOMMENDED when playing a prompt to the user
          with Kill-On-Barge-In and asking for input, that the client issue
          the RECOGNIZE request ahead of the SPEAK request for optimum
          performance and user experience. This way, it is guaranteed that the
          recognizer is online before the prompt starts playing and the user's
          speech will not be truncated at the beginning (especially for power
          users).</p>
</div></section><section id="section-8.4.3"><h4 id="name-speaker-profile">
<a href="#section-8.4.3" class="section-number selfRef">8.4.3.Â </a><a href="#name-speaker-profile" class="section-name selfRef">Speaker-Profile</a>
</h4>
<p id="section-8.4.3-1">This header field MAY be part of the SET-PARAMS/GET-PARAMS or
          SPEAK request from the client to the server and specifies a URI
          that references the profile of the speaker. Speaker profiles are
          collections of voice parameters like gender, accent, etc.</p>
<div id="section-8.4.3-2" class="artwork art-text" text-align="left"><pre>
speaker-profile       =   "Speaker-Profile" ":" uri CRLF</pre></div></section><section id="section-8.4.4"><h4 id="name-completion-cause">
<a href="#section-8.4.4" class="section-number selfRef">8.4.4.Â </a><a href="#name-completion-cause" class="section-name selfRef">Completion-Cause</a>
</h4>
<p id="section-8.4.4-1">This header field MUST be specified in a SPEAK-COMPLETE event
          coming from the synthesizer resource to the client. This indicates
          the reason the SPEAK request completed.</p>
<div id="section-8.4.4-2" class="artwork art-text" text-align="left"><pre>
completion-cause      =   "Completion-Cause" ":" 3DIGIT SP
                          1*VCHAR CRLF

</pre></div>
<table id="table-5">
<name id="name-synthesizer-resource-comple">Synthesizer Resource Completion Cause Codes</name><thead><tr>
<th>Cause-Code</th>
<th>Cause-Name</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr>
<td>000</td>
<td>normal</td>
<td>SPEAK completed normally.</td>
</tr>
<tr>
<td>001</td>
<td>barge-in</td>
<td>SPEAK request was terminated because of barge-in.</td>
</tr>
<tr>
<td>002</td>
<td>parse-failure</td>
<td>SPEAK request terminated because of a failure to parse the
            speech markup text.</td>
</tr>
<tr>
<td>003</td>
<td>uri-failure</td>
<td>SPEAK request terminated because access to one of the URIs
            failed.</td>
</tr>
<tr>
<td>004</td>
<td>error</td>
<td>SPEAK request terminated prematurely due to synthesizer
            error.</td>
</tr>
<tr>
<td>005</td>
<td>language-unsupported</td>
<td>Language not supported.</td>
</tr>
<tr>
<td>006</td>
<td>lexicon-load-failure</td>
<td>Lexicon loading failed.</td>
</tr>
<tr>
<td>007</td>
<td>cancelled</td>
<td>A prior SPEAK request failed while this one was still in the
            queue.</td>
</tr>
</tbody>
</table></section><section id="section-8.4.5"><h4 id="name-completion-reason">
<a href="#section-8.4.5" class="section-number selfRef">8.4.5.Â </a><a href="#name-completion-reason" class="section-name selfRef">Completion-Reason</a>
</h4>
<p id="section-8.4.5-1">This header field MAY be specified in a SPEAK-COMPLETE event
          coming from the synthesizer resource to the client. This contains
          the reason text behind the SPEAK request completion. This header
          field communicates text describing the reason for the failure, such
          as an error in parsing the speech markup text.</p>
<div id="section-8.4.5-2" class="artwork art-text" text-align="left"><pre>
completion-reason   =   "Completion-Reason" ":" 
                        quoted-string CRLF

</pre></div>
<p id="section-8.4.5-3">The completion reason text is provided for client use in logs and
          for debugging and instrumentation purposes. Clients MUST NOT
          interpret the completion reason text.</p></section><section id="section-8.4.6"><h4 id="name-voice-parameter">
<a href="#section-8.4.6" class="section-number selfRef">8.4.6.Â </a><a href="#name-voice-parameter" class="section-name selfRef">Voice-Parameter</a>
</h4>
<p id="section-8.4.6-1">This set of header fields defines the voice of the speaker.</p>
<div id="section-8.4.6-2" class="artwork art-text" text-align="left"><pre>
voice-parameter    =   voice-gender
                    /   voice-age
                    /   voice-variant
                    /   voice-name

voice-gender        =   "Voice-Gender:" voice-gender-value CRLF
voice-gender-value  =   "male"
                    /   "female"
                    /   "neutral"
voice-age           =   "Voice-Age:" 1*3DIGIT CRLF
voice-variant       =   "Voice-Variant:" 1*19DIGIT CRLF
voice-name          =   "Voice-Name:"
                        1*UTFCHAR *(1*WSP 1*UTFCHAR) CRLF

</pre></div>
<p id="section-8.4.6-3">The "Voice-" parameters are derived from the similarly named
          attributes of the voice element specified in W3C's <span>[<a href="#W3C.REC-speech-synthesis-20040907" class="xref">Speech Synthesis Markup
          Language Specification (SSML)</a>]. Legal values for these
          parameters are as defined in that specification.</span></p>
<p id="section-8.4.6-4">These header fields MAY be sent in SET-PARAMS or GET-PARAMS requests
          to define or get default values for the entire session or MAY be sent
          in the SPEAK request to define default values for that SPEAK
          request. Note that SSML content can itself set these values internal
          to the SSML document, of course.</p>
<p id="section-8.4.6-5">Voice parameter header fields MAY also be sent in a CONTROL
          method to affect a SPEAK request in progress and change its behavior
          on the fly. If the synthesizer resource does not support this
          operation, it MUST reject the request with a status-code of 403
          "Unsupported Header Field".</p></section><section id="section-8.4.7"><h4 id="name-prosody-parameters">
<a href="#section-8.4.7" class="section-number selfRef">8.4.7.Â </a><a href="#name-prosody-parameters" class="section-name selfRef">Prosody-Parameters</a>
</h4>
<p id="section-8.4.7-1">This set of header fields defines the prosody of the speech.</p>
<div id="section-8.4.7-2" class="artwork art-text" text-align="left"><pre>
prosody-parameter   =   "Prosody-" prosody-param-name ":"
                        prosody-param-value CRLF

prosody-param-name    =    1*VCHAR

prosody-param-value   =    1*VCHAR

</pre></div>
<p id="section-8.4.7-3">prosody-param-name is any one of the attribute names under the
          prosody element specified in W3C's <span>[<a href="#W3C.REC-speech-synthesis-20040907" class="xref">Speech Synthesis Markup
          Language Specification</a>]. The prosody-param-value is any one of
          the value choices of the corresponding prosody element attribute
          from that specification.</span></p>
<p id="section-8.4.7-4">These header fields MAY be sent in SET-PARAMS or GET-PARAMS requests
          to define or get default values for the entire session or MAY be sent
          in the SPEAK request to define default values for that SPEAK
          request. Furthermore, these attributes can be part of the speech
          text marked up in SSML.</p>
<p id="section-8.4.7-5">The prosody parameter header fields in the SET-PARAMS or SPEAK
          request only apply if the speech data is of type 'text/plain' and does
          not use a speech markup format.</p>
<p id="section-8.4.7-6">These prosody parameter header fields MAY also be sent in a
          CONTROL method to affect a SPEAK request in progress and change its
          behavior on the fly. If the synthesizer resource does not support
          this operation, it MUST respond back to the client with a
          status-code of 403 "Unsupported Header Field".</p></section><section id="section-8.4.8"><h4 id="name-speech-marker">
<a href="#section-8.4.8" class="section-number selfRef">8.4.8.Â </a><a href="#name-speech-marker" class="section-name selfRef">Speech-Marker</a>
</h4>
<p id="section-8.4.8-1">This header field contains timestamp information in a "timestamp"
          field. This is a <span>[<a href="#RFC5905" class="xref">Network Time Protocol (NTP)</a>] timestamp, a 64-bit number in decimal form. It MUST be
          synced with the </span><span>[<a href="#RFC3550" class="xref">Real-Time Protocol (RTP)</a>] timestamp of the media stream through the </span><span>[<a href="#RFC3550" class="xref">Real-Time Control Protocol (RTCP)</a>].</span></p>
<p id="section-8.4.8-2">Markers are bookmarks that are defined within the markup. Most
          speech markup formats provide mechanisms to embed marker fields
          within speech texts. The synthesizer generates SPEECH-MARKER events
          when it reaches these marker fields. This header field MUST be part
          of the SPEECH-MARKER event and contain the marker tag value after
          the timestamp, separated by a semicolon. In these events, the
          timestamp marks the time the text corresponding to the marker was
          emitted as speech by the synthesizer.</p>
<p id="section-8.4.8-3">This header field MUST also be returned in responses to STOP,
          CONTROL, and BARGE-IN-OCCURRED methods, in the SPEAK-COMPLETE event,
          and in an IN-PROGRESS SPEAK response. In these messages, if any
          markers have been encountered for the current SPEAK, the marker tag
          value MUST be the last embedded marker encountered. If no markers
          have yet been encountered for the current SPEAK, only the timestamp
          is REQUIRED. Note that in these events, the purpose of this header
          field is to provide timestamp information associated with important
          events within the lifecycle of a request (start of SPEAK processing,
          end of SPEAK processing, receipt of
          CONTROL/STOP/BARGE-IN-OCCURRED).</p>
<div id="section-8.4.8-4" class="artwork art-text" text-align="left"><pre>
timestamp           =   "timestamp" "=" time-stamp-value

time-stamp-value    =   1*20DIGIT

speech-marker       =   "Speech-Marker" ":"
                        timestamp
                        [";" 1*(UTFCHAR / %x20)] CRLF
</pre></div></section><section id="section-8.4.9"><h4 id="name-speech-language">
<a href="#section-8.4.9" class="section-number selfRef">8.4.9.Â </a><a href="#name-speech-language" class="section-name selfRef">Speech-Language</a>
</h4>
<p id="section-8.4.9-1">This header field specifies the default language of the speech
          data if the language is not specified in the markup. The value of
          this header field MUST follow <span>[<a href="#RFC5646" class="xref">RFC 5646</a>]
          for its values. The header field MAY occur in SPEAK, SET-PARAMS, or
          GET-PARAMS requests.</span></p>
<div id="section-8.4.9-2" class="artwork art-text" text-align="left"><pre>
speech-language     =   "Speech-Language" ":" 1*VCHAR CRLF
            </pre></div></section><section id="section-8.4.10"><h4 id="name-fetch-hint">
<a href="#section-8.4.10" class="section-number selfRef">8.4.10.Â </a><a href="#name-fetch-hint" class="section-name selfRef">Fetch-Hint</a>
</h4>
<p id="section-8.4.10-1">When the synthesizer needs to fetch documents or other resources
          like speech markup or audio files, this header field controls the
          corresponding URI access properties. This provides client policy on
          when the synthesizer should retrieve content from the server. A
          value of "prefetch" indicates the content MAY be downloaded when the
          request is received, whereas "safe" indicates that content MUST NOT
          be downloaded until actually referenced. The default value is
          "prefetch". This header field MAY occur in SPEAK, SET-PARAMS, or
          GET-PARAMS requests.</p>
<div id="section-8.4.10-2" class="artwork art-text" text-align="left"><pre>
fetch-hint          =   "Fetch-Hint" ":"
                         ("prefetch" / "safe") CRLF
            </pre></div></section><section id="section-8.4.11"><h4 id="name-audio-fetch-hint">
<a href="#section-8.4.11" class="section-number selfRef">8.4.11.Â </a><a href="#name-audio-fetch-hint" class="section-name selfRef">Audio-Fetch-Hint</a>
</h4>
<p id="section-8.4.11-1">When the synthesizer needs to fetch documents or other resources
          like speech audio files, this header field controls the
          corresponding URI access properties. This provides client policy
          whether or not the synthesizer is permitted to attempt to optimize
          speech by pre-fetching audio. The value is either "safe" to say that
          audio is only fetched when it is referenced, never before;
          "prefetch" to permit, but not require the implementation to
          pre-fetch the audio; or "stream" to allow it to stream the audio
          fetches. The default value is "prefetch". This header field MAY
          occur in SPEAK, SET-PARAMS, or GET-PARAMS requests.</p>
<div id="section-8.4.11-2" class="artwork art-text" text-align="left"><pre>
audio-fetch-hint    =   "Audio-Fetch-Hint" ":"
                        ("prefetch" / "safe" / "stream") CRLF
            </pre></div></section><section id="section-8.4.12"><h4 id="name-failed-uri">
<a href="#section-8.4.12" class="section-number selfRef">8.4.12.Â </a><a href="#name-failed-uri" class="section-name selfRef">Failed-URI</a>
</h4>
<p id="section-8.4.12-1">When a synthesizer method needs a synthesizer to fetch or access
          a URI and the access fails, the server SHOULD provide the failed URI
          in this header field in the method response, unless there are
          multiple URI failures, in which case the server MUST provide one of
          the failed URIs in this header field in the method response.</p>
<div id="section-8.4.12-2" class="artwork art-text" text-align="left"><pre>
failed-uri          =   "Failed-URI" ":" absoluteURI CRLF
            </pre></div></section><section id="section-8.4.13"><h4 id="name-failed-uri-cause">
<a href="#section-8.4.13" class="section-number selfRef">8.4.13.Â </a><a href="#name-failed-uri-cause" class="section-name selfRef">Failed-URI-Cause</a>
</h4>
<p id="section-8.4.13-1">When a synthesizer method needs a synthesizer to fetch or access
          a URI and the access fails, the server MUST provide the URI-specific
          or protocol-specific response code for the URI in the Failed-URI
          header field in the method response through this header field. The
          value encoding is UTF-8 (<span>[<a href="#RFC3629" class="xref">RFC 3629</a>]) to
          accommodate any access protocol -- some access protocols might have a response
          string instead of a numeric response code.</span></p>
<div id="section-8.4.13-2" class="artwork art-text" text-align="left"><pre>failed-uri-cause    =   "Failed-URI-Cause" ":" 1*UTFCHAR CRLF</pre></div></section><section id="section-8.4.14"><h4 id="name-speak-restart">
<a href="#section-8.4.14" class="section-number selfRef">8.4.14.Â </a><a href="#name-speak-restart" class="section-name selfRef">Speak-Restart</a>
</h4>
<p id="section-8.4.14-1">When a client issues a CONTROL request to a currently speaking
          synthesizer resource to jump backward, and the target jump point is
          before the start of the current SPEAK request, the current SPEAK
          request MUST restart from the beginning of its speech data and the
          server's response to the CONTROL request MUST contain this header
          field with a value of "true" indicating a restart.</p>
<div id="section-8.4.14-2" class="artwork art-text" text-align="left"><pre>
speak-restart       =   "Speak-Restart" ":" BOOLEAN CRLF
            </pre></div></section><section id="section-8.4.15"><h4 id="name-speak-length">
<a href="#section-8.4.15" class="section-number selfRef">8.4.15.Â </a><a href="#name-speak-length" class="section-name selfRef">Speak-Length</a>
</h4>
<p id="section-8.4.15-1">This header field MAY be specified in a CONTROL method to control
          the maximum length of speech to speak, relative to the current speaking
          point in the currently active SPEAK request. If numeric, the value
          MUST be a positive integer. If a header field with a Tag unit is
          specified, then the speech output continues until the tag is reached
          or the SPEAK request is completed, whichever comes first. This header
          field MAY be specified in a SPEAK request to indicate the length to
          speak from the speech data and is relative to the point in speech
          that the SPEAK request starts. The different speech length units
          supported are synthesizer implementation dependent. If a server does
          not support the specified unit, the server MUST respond with a
          status-code of 409 "Unsupported Header Field Value".</p>
<div id="section-8.4.15-2" class="artwork art-text" text-align="left"><pre>
speak-length          =   "Speak-Length" ":" positive-length-value
                          CRLF

positive-length-value =   positive-speech-length
                      /   text-speech-length

text-speech-length    =   1*UTFCHAR SP "Tag"

positive-speech-length =  1*19DIGIT SP numeric-speech-unit

numeric-speech-unit   =   "Second"
                      /   "Word"
                      /   "Sentence"
                      /   "Paragraph"
</pre></div></section><section id="section-8.4.16"><div id="load-lexicon">
<h4 id="name-load-lexicon">
<a href="#section-8.4.16" class="section-number selfRef">8.4.16.Â </a><a href="#name-load-lexicon" class="section-name selfRef">Load-Lexicon</a>
</h4>
<p id="section-8.4.16-1">This header field is used to indicate whether a lexicon has to be
          loaded or unloaded. The value "true" means to load the lexicon if
          not already loaded, and the value "false" means to unload the
          lexicon if it is loaded. The default value for this header field is
          "true". This header field MAY be specified in a DEFINE-LEXICON
          method.</p>
<div id="section-8.4.16-2" class="artwork art-text" text-align="left"><pre>
load-lexicon       =   "Load-Lexicon" ":" BOOLEAN CRLF
            </pre></div>
</div></section><section id="section-8.4.17"><div id="lexicon-search-order">
<h4 id="name-lexicon-search-order">
<a href="#section-8.4.17" class="section-number selfRef">8.4.17.Â </a><a href="#name-lexicon-search-order" class="section-name selfRef">Lexicon-Search-Order</a>
</h4>
<p id="section-8.4.17-1">This header field is used to specify a list of active
          pronunciation lexicon URIs and the search order among the active
          lexicons. Lexicons specified within the SSML document take
          precedence over the lexicons specified in this header field. This
          header field MAY be specified in the SPEAK, SET-PARAMS, and
          GET-PARAMS methods.</p>
<div id="section-8.4.17-2" class="artwork art-text" text-align="left"><pre>
lexicon-search-order =   "Lexicon-Search-Order" ":"
          "&lt;" absoluteURI "&gt;" *(" " "&lt;" absoluteURI "&gt;") CRLF
            </pre></div>
</div></section>
</div></section><section id="section-8.5"><div id="sec.synthMessageBody">
<h3 id="name-synthesizer-message-body">
<a href="#section-8.5" class="section-number selfRef">8.5.Â </a><a href="#name-synthesizer-message-body" class="section-name selfRef">Synthesizer Message Body</a>
</h3>
<p id="section-8.5-1">A synthesizer message can contain additional information associated
        with the Request, Response, or Event in its message body.</p>
<section id="section-8.5.1"><h4 id="name-synthesizer-speech-data">
<a href="#section-8.5.1" class="section-number selfRef">8.5.1.Â </a><a href="#name-synthesizer-speech-data" class="section-name selfRef">Synthesizer Speech Data</a>
</h4>
<p id="section-8.5.1-1">Marked-up text for the synthesizer to speak is specified as a
          typed media entity in the message body. The speech data to be spoken
          by the synthesizer can be specified inline by embedding the data in
          the message body or by reference by providing a URI for accessing
          the data. In either case, the data and the format used to markup the
          speech needs to be of a content type supported by the server.</p>
<p id="section-8.5.1-2">All MRCPv2 servers containing synthesizer resources MUST support
          both plain text speech data and W3C's <span>[<a href="#W3C.REC-speech-synthesis-20040907" class="xref">Speech Synthesis Markup
          Language</a>] and hence MUST support the media types 'text/plain'
          and 'application/ssml+xml'. Other formats MAY be supported.</span></p>
<p id="section-8.5.1-3">If the speech data is to be fetched by URI reference, the media
          type 'text/uri-list' (see <span>[<a href="#RFC2483" class="xref">RFC 2483</a>]) is
          used to indicate one or more URIs that, when dereferenced, will
          contain the content to be spoken. If a list of speech URIs is
          specified, the resource MUST speak the speech data provided by each
          URI in the order in which the URIs are specified in the content.</span></p>
<p id="section-8.5.1-4">MRCPv2 clients and servers MUST support the 'multipart/mixed' media
          type. This is the appropriate media type to use when providing a mix
          of URI and inline speech data. Embedded within the multipart
          content block, there MAY be content for the 'text/uri-list',
          'application/ssml+xml', and/or 'text/plain' media types. The character
          set and encoding used in the speech data is specified according to
          standard media type definitions. The multipart content MAY also
          contain actual audio data. Clients may have recorded audio clips
          stored in memory or on a local device and wish to play it as part of
          the SPEAK request. The audio portions MAY be sent by the client as
          part of the multipart content block. This audio is referenced in
          the speech markup data that is another part in the multipart
          content block according to the 'multipart/mixed' media type
          specification.</p>
<figure id="figure-8"><div><div id="section-8.5.1-5" class="artwork art-text" text-align="left"><pre>
Content-Type:text/uri-list
Content-Length:...

http://www.example.com/ASR-Introduction.ssml
http://www.example.com/ASR-Document-Part1.ssml
http://www.example.com/ASR-Document-Part2.ssml
http://www.example.com/ASR-Conclusion.ssml

</pre></div></div>
<figcaption><a href="#figure-8">Figure 8</a><a href="#name-uri-list-example" id="name-uri-list-example" class="selfRef">URI List Example</a></figcaption></figure><figure id="figure-9"><div><div id="section-8.5.1-6" class="artwork art-text" text-align="left"><pre>
Content-Type:application/ssml+xml
Content-Length:...

&lt;?xml version="1.0"?&gt;
     &lt;speak version="1.0"                
            xmlns="http://www.w3.org/2001/10/synthesis"
            xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
            xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
            xml:lang="en-US"&gt;
       &lt;p&gt;
         &lt;s&gt;You have 4 new messages.&lt;/s&gt;
         &lt;s&gt;The first is from Aldine Turnbet
         and arrived at &lt;break/&gt;
         &lt;say-as interpret-as="vxml:time"&gt;0345p&lt;/say-as&gt;.&lt;/s&gt;

         &lt;s&gt;The subject is &lt;prosody
         rate="-20%"&gt;ski trip&lt;/prosody&gt;&lt;/s&gt;
      &lt;/p&gt;
     &lt;/speak&gt;
</pre></div></div>
<figcaption><a href="#figure-9">Figure 9</a><a href="#name-ssml-example" id="name-ssml-example" class="selfRef">SSML Example</a></figcaption></figure><figure id="figure-10"><div><div id="section-8.5.1-7" class="artwork art-text" text-align="left"><pre>
Content-Type:multipart/mixed; boundary="break"

--break
Content-Type:text/uri-list
Content-Length:...

http://www.example.com/ASR-Introduction.ssml
http://www.example.com/ASR-Document-Part1.ssml
http://www.example.com/ASR-Document-Part2.ssml
http://www.example.com/ASR-Conclusion.ssml
    
--break
Content-Type:application/ssml+xml
Content-Length:...

&lt;?xml version="1.0"?&gt;
    &lt;speak version="1.0"                
           xmlns="http://www.w3.org/2001/10/synthesis"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
           xml:lang="en-US"&gt;
       &lt;p&gt;
         &lt;s&gt;You have 4 new messages.&lt;/s&gt;
         &lt;s&gt;The first is from Stephanie Williams
         and arrived at &lt;break/&gt;
         &lt;say-as interpret-as="vxml:time"&gt;0342p&lt;/say-as&gt;.&lt;/s&gt;

         &lt;s&gt;The subject is &lt;prosody
         rate="-20%"&gt;ski trip&lt;/prosody&gt;&lt;/s&gt;
       &lt;/p&gt;
    &lt;/speak&gt;
--break--
</pre></div></div>
<figcaption><a href="#figure-10">Figure 10</a><a href="#name-multipart-example" id="name-multipart-example" class="selfRef">Multipart Example</a></figcaption></figure></section><section id="section-8.5.2"><div id="sec.lexiconData">
<h4 id="name-lexicon-data">
<a href="#section-8.5.2" class="section-number selfRef">8.5.2.Â </a><a href="#name-lexicon-data" class="section-name selfRef">Lexicon Data</a>
</h4>
<p id="section-8.5.2-1">Synthesizer lexicon data from the client to the server can be
          provided inline or by reference. Either way, they are carried as
          typed media in the message body of the MRCPv2 request message (see
          <a href="#sec.methodDefineLexicon" class="xref">Section 8.14</a>).</p>
<p id="section-8.5.2-2">When a lexicon is specified inline in the message, the client
          MUST provide a Content-ID for that lexicon as part of the content
          header fields. The server MUST store the lexicon associated with
          that Content-ID for the duration of the session. A stored lexicon
          can be overwritten by defining a new lexicon with the same
          Content-ID. Lexicons that have been associated with a Content-ID can
          be referenced through the 'session' URI scheme (see <a href="#sec.sessionURIScheme" class="xref">Section 13.6</a>).</p>
<p id="section-8.5.2-3">If lexicon data is specified by external URI reference, the media
          type 'text/uri-list' (see <span>[<a href="#RFC2483" class="xref">RFC 2483</a>] ) is
          used to list the one or more URIs that may be dereferenced to obtain
          the lexicon data. All MRCPv2 servers MUST support the "http" and
          "https" URI access mechanisms, and MAY support other mechanisms.</span></p>
<p id="section-8.5.2-4">If the data in the message body consists of a mix of URI and
          inline lexicon data, the 'multipart/mixed' media type is used. The
          character set and encoding used in the lexicon data may be specified
          according to standard media type definitions.</p>
</div></section>
</div></section><section id="section-8.6"><h3 id="name-speak-method">
<a href="#section-8.6" class="section-number selfRef">8.6.Â </a><a href="#name-speak-method" class="section-name selfRef">SPEAK Method</a>
</h3>
<p id="section-8.6-1">The SPEAK request provides the synthesizer resource with the speech
        text and initiates speech synthesis and streaming. The SPEAK method
        MAY carry voice and prosody header fields that alter the behavior of
        the voice being synthesized, as well as a typed media message body
        containing the actual marked-up text to be spoken.</p>
<p id="section-8.6-2">The SPEAK method implementation MUST do a fetch of all external
        URIs that are part of that operation. If caching is implemented, this
        URI fetching MUST conform to the cache-control hints and parameter
        header fields associated with the method in deciding whether it is to
        be fetched from cache or from the external server. If these
        hints/parameters are not specified in the method, the values set for
        the session using SET-PARAMS/GET-PARAMS apply. If it was not set for
        the session, their default values apply.</p>
<p id="section-8.6-3">When applying voice parameters, there are three levels of precedence.
        The highest precedence are those specified within the speech markup
        text, followed by those specified in the header fields of the SPEAK
        request and hence that apply for that SPEAK request only, followed by the
        session default values that can be set using the SET-PARAMS request
        and apply for subsequent methods invoked during the session.</p>
<p id="section-8.6-4">If the resource was idle at the time the SPEAK request arrived at
        the server and the SPEAK method is being actively processed, the
        resource responds immediately with a success status code and a
        request-state of IN-PROGRESS.</p>
<p id="section-8.6-5">If the resource is in the speaking or paused state when the SPEAK
        method arrives at the server, i.e., it is in the middle of processing a
        previous SPEAK request, the status returns success with a
        request-state of PENDING. The server places the SPEAK request in the
        synthesizer resource request queue. The request queue operates
        strictly FIFO: requests are processed serially in order of receipt. If
        the current SPEAK fails, all SPEAK methods in the pending queue are
        cancelled and each generates a SPEAK-COMPLETE event with a
        Completion-Cause of "cancelled".</p>
<p id="section-8.6-6">For the synthesizer resource, SPEAK is the only method that can
        return a request-state of IN-PROGRESS or PENDING. When the text has
        been synthesized and played into the media stream, the resource issues
        a SPEAK-COMPLETE event with the request-id of the SPEAK request and a
        request-state of COMPLETE.</p>
<figure id="figure-11"><div><div id="section-8.6-7" class="artwork art-text" text-align="left"><pre>
C-&gt;S: MRCP/2.0 ... SPEAK 543257 
      Channel-Identifier:32AECB23433802@speechsynth
      Voice-gender:neutral
      Voice-Age:25
      Prosody-volume:medium
      Content-Type:application/ssml+xml
      Content-Length:...
      
      &lt;?xml version="1.0"?&gt;
         &lt;speak version="1.0"                
             xmlns="http://www.w3.org/2001/10/synthesis"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
             xml:lang="en-US"&gt;
         &lt;p&gt;
          &lt;s&gt;You have 4 new messages.&lt;/s&gt;
          &lt;s&gt;The first is from Stephanie Williams and arrived at
             &lt;break/&gt;
             &lt;say-as interpret-as="vxml:time"&gt;0342p&lt;/say-as&gt;.
             &lt;/s&gt;
          &lt;s&gt;The subject is 
                 &lt;prosody rate="-20%"&gt;ski trip&lt;/prosody&gt;
          &lt;/s&gt;
         &lt;/p&gt;
        &lt;/speak&gt;

S-&gt;C: MRCP/2.0 ... 543257 200 IN-PROGRESS
      Channel-Identifier:32AECB23433802@speechsynth
      Speech-Marker:timestamp=857206027059


S-&gt;C: MRCP/2.0 ... SPEAK-COMPLETE 543257 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Completion-Cause:000 normal
      Speech-Marker:timestamp=857206027059
</pre></div></div>
<figcaption><a href="#figure-11">Figure 11</a><a href="#name-speak-example" id="name-speak-example" class="selfRef">SPEAK Example</a></figcaption></figure></section><section id="section-8.7"><h3 id="name-stop">
<a href="#section-8.7" class="section-number selfRef">8.7.Â </a><a href="#name-stop" class="section-name selfRef">STOP</a>
</h3>
<p id="section-8.7-1">The STOP method from the client to the server tells the synthesizer
        resource to stop speaking if it is speaking something.</p>
<p id="section-8.7-2">The STOP request can be sent with an Active-Request-Id-List header
        field to stop the zero or more specific SPEAK requests that may be in
        queue and return a response status-code of 200 "Success". If no
        Active-Request-Id-List header field is sent in the STOP request, the
        server terminates all outstanding SPEAK requests.</p>
<p id="section-8.7-3">If a STOP request successfully terminated one or more PENDING or
        INâ€‘PROGRESS SPEAK requests, then the response MUST contain an
        Active-Request-Id-List header field enumerating the SPEAK request-ids
        that were terminated. Otherwise, there is no Active-Request-Id-List
        header field in the response. No SPEAK-COMPLETE events are sent for
        such terminated requests.</p>
<p id="section-8.7-4">If a SPEAK request that was IN-PROGRESS and speaking was stopped,
        the next pending SPEAK request, if any, becomes IN-PROGRESS at the
        resource and enters the speaking state.</p>
<p id="section-8.7-5">If a SPEAK request that was IN-PROGRESS and paused was stopped, the
        next pending SPEAK request, if any, becomes IN-PROGRESS and enters the
        paused state.</p>
<figure id="figure-12"><div><div id="section-8.7-6" class="artwork art-text" text-align="left"><pre>
C-&gt;S: MRCP/2.0 ... SPEAK 543258
      Channel-Identifier:32AECB23433802@speechsynth
      Content-Type:application/ssml+xml
      Content-Length:...

      &lt;?xml version="1.0"?&gt;
        &lt;speak version="1.0"                
             xmlns="http://www.w3.org/2001/10/synthesis"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
             xml:lang="en-US"&gt;
         &lt;p&gt;
          &lt;s&gt;You have 4 new messages.&lt;/s&gt;
          &lt;s&gt;The first is from Stephanie Williams and arrived at 
             &lt;break/&gt;
             &lt;say-as interpret-as="vxml:time"&gt;0342p&lt;/say-as&gt;.&lt;/s&gt;
          &lt;s&gt;The subject is 
              &lt;prosody rate="-20%"&gt;ski trip&lt;/prosody&gt;&lt;/s&gt;
         &lt;/p&gt;
        &lt;/speak&gt;

S-&gt;C: MRCP/2.0 ... 543258 200 IN-PROGRESS
      Channel-Identifier:32AECB23433802@speechsynth
      Speech-Marker:timestamp=857206027059

C-&gt;S: MRCP/2.0 ... STOP 543259
      Channel-Identifier:32AECB23433802@speechsynth

S-&gt;C: MRCP/2.0 ... 543259 200 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Active-Request-Id-List:543258
      Speech-Marker:timestamp=857206039059
</pre></div></div>
<figcaption><a href="#figure-12">Figure 12</a><a href="#name-stop-example" id="name-stop-example" class="selfRef">STOP Example</a></figcaption></figure></section><section id="section-8.8"><h3 id="name-barge-in-occurred">
<a href="#section-8.8" class="section-number selfRef">8.8.Â </a><a href="#name-barge-in-occurred" class="section-name selfRef">BARGE-IN-OCCURRED</a>
</h3>
<p id="section-8.8-1">The BARGE-IN-OCCURRED method, when used with the synthesizer
        resource, provides a client that has detected a barge-in-able event a
        means to communicate the occurrence of the event to the synthesizer
        resource.</p>
<p id="section-8.8-2">This method is useful in two scenarios: 

</p>
<ol id="section-8.8-3">
<li id="section-8.8-4">The client has detected DTMF digits in the input media or some
            other barge-in-able event and wants to communicate that to the
            synthesizer resource.</li>
<li id="section-8.8-5">The recognizer resource and the synthesizer resource are in
            different servers. In this case, the client acts as an intermediary
            for the two servers. It receives an event from the recognition
            resource and sends a BARGE-IN-OCCURRED request to the synthesizer.
            In such cases, the BARGE-IN-OCCURRED method would also have a
            Proxy-Sync-Id header field received from the resource generating
            the original event.</li>
</ol>
<p id="section-8.8-6">If a SPEAK request is active with kill-on-barge-in enabled (see
        <a href="#sec.kill-on-barge-in" class="xref">Section 8.4.2</a>), and the
        BARGE-IN-OCCURRED event is received, the synthesizer MUST immediately
        stop streaming out audio. It MUST also terminate any speech requests
        queued behind the current active one, irrespective of whether
        or not they
        have barge-in enabled. If a barge-in-able SPEAK request was
        playing and it was terminated, the response MUST contain an
        Active-Request-Id-List header field listing the request-ids of all
        SPEAK requests that were terminated. The server generates no
        SPEAK-COMPLETE events for these requests.</p>
<p id="section-8.8-7">If there were no SPEAK requests terminated by the synthesizer
        resource as a result of the BARGE-IN-OCCURRED method, the server MUST
        respond to the BARGE-IN-OCCURRED with a status-code of 200 "Success",
        and the response MUST NOT contain an Active-Request-Id-List header
        field.</p>
<p id="section-8.8-8">If the synthesizer and recognizer resources are part of the same
        MRCPv2 session, they can be optimized for a quicker kill-on-barge-in
        response if the recognizer and synthesizer interact directly. In these
        cases, the client MUST still react to a START-OF-INPUT event from the
        recognizer by invoking the BARGE-IN-OCCURRED method to the
        synthesizer. The client MUST invoke the BARGE-IN-OCCURRED if it has
        any outstanding requests to the synthesizer resource in either the
        PENDING or IN-PROGRESS state.</p>
<figure id="figure-13"><div><div id="section-8.8-9" class="artwork art-text" text-align="left"><pre>
C-&gt;S: MRCP/2.0 ... SPEAK 543258
      Channel-Identifier:32AECB23433802@speechsynth
      Voice-gender:neutral
      Voice-Age:25
      Prosody-volume:medium
      Content-Type:application/ssml+xml
      Content-Length:...

      &lt;?xml version="1.0"?&gt;
        &lt;speak version="1.0"                
             xmlns="http://www.w3.org/2001/10/synthesis"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
             xml:lang="en-US"&gt;
         &lt;p&gt;
          &lt;s&gt;You have 4 new messages.&lt;/s&gt;
          &lt;s&gt;The first is from Stephanie Williams and arrived at 
             &lt;break/&gt;
             &lt;say-as interpret-as="vxml:time"&gt;0342p&lt;/say-as&gt;.&lt;/s&gt;
          &lt;s&gt;The subject is 
             &lt;prosody rate="-20%"&gt;ski trip&lt;/prosody&gt;&lt;/s&gt;
         &lt;/p&gt;
        &lt;/speak&gt;

S-&gt;C: MRCP/2.0 ... 543258 200 IN-PROGRESS
      Channel-Identifier:32AECB23433802@speechsynth
      Speech-Marker:timestamp=857206027059

C-&gt;S: MRCP/2.0 ... BARGE-IN-OCCURRED 543259
      Channel-Identifier:32AECB23433802@speechsynth
      Proxy-Sync-Id:987654321

S-&gt;C:MRCP/2.0 ... 543259 200 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Active-Request-Id-List:543258
      Speech-Marker:timestamp=857206039059
</pre></div></div>
<figcaption><a href="#figure-13">Figure 13</a><a href="#name-barge-in-occurred-example" id="name-barge-in-occurred-example" class="selfRef">BARGE-IN-OCCURRED Example</a></figcaption></figure></section><section id="section-8.9"><h3 id="name-pause">
<a href="#section-8.9" class="section-number selfRef">8.9.Â </a><a href="#name-pause" class="section-name selfRef">PAUSE</a>
</h3>
<p id="section-8.9-1">The PAUSE method from the client to the server tells the
        synthesizer resource to pause speech output if it is speaking
        something. If a PAUSE method is issued on a session when a SPEAK is
        not active, the server MUST respond with a status-code of 402 "Method
        not valid in this state". If a PAUSE method is issued on a session
        when a SPEAK is active and paused, the server MUST respond with a
        status-code of 200 "Success". If a SPEAK request was active, the server
        MUST return an Active-Request-Id-List header field whose value
        contains the request-id of the SPEAK request that was paused.</p>
<figure id="figure-14"><div><div id="section-8.9-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S: MRCP/2.0 ... SPEAK 543258
      Channel-Identifier:32AECB23433802@speechsynth
      Voice-gender:neutral
      Voice-Age:25
      Prosody-volume:medium
      Content-Type:application/ssml+xml
      Content-Length:...

      &lt;?xml version="1.0"?&gt;
        &lt;speak version="1.0"                
             xmlns="http://www.w3.org/2001/10/synthesis"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
             xml:lang="en-US"&gt;
         &lt;p&gt;
          &lt;s&gt;You have 4 new messages.&lt;/s&gt;
          &lt;s&gt;The first is from Stephanie Williams and arrived at 
             &lt;break/&gt;
             &lt;say-as interpret-as="vxml:time"&gt;0342p&lt;/say-as&gt;.&lt;/s&gt;

          &lt;s&gt;The subject is 
             &lt;prosody rate="-20%"&gt;ski trip&lt;/prosody&gt;&lt;/s&gt;
         &lt;/p&gt;
        &lt;/speak&gt;

S-&gt;C: MRCP/2.0 ... 543258 200 IN-PROGRESS
      Channel-Identifier:32AECB23433802@speechsynth
      Speech-Marker:timestamp=857206027059

C-&gt;S: MRCP/2.0 ... PAUSE 543259
      Channel-Identifier:32AECB23433802@speechsynth

S-&gt;C: MRCP/2.0 ... 543259 200 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Active-Request-Id-List:543258
</pre></div></div>
<figcaption><a href="#figure-14">Figure 14</a><a href="#name-pause-example" id="name-pause-example" class="selfRef">PAUSE Example</a></figcaption></figure></section><section id="section-8.10"><h3 id="name-resume">
<a href="#section-8.10" class="section-number selfRef">8.10.Â </a><a href="#name-resume" class="section-name selfRef">RESUME</a>
</h3>
<p id="section-8.10-1">The RESUME method from the client to the server tells a paused
        synthesizer resource to resume speaking. If a RESUME request is issued
        on a session with no active SPEAK request, the server MUST respond
        with a status-code of 402 "Method not valid in this state". If a
        RESUME request is issued on a session with an active SPEAK request
        that is speaking (i.e., not paused), the server MUST respond with a
        status-code of 200 "Success". If a SPEAK request was paused, the server
        MUST return an Active-Request-Id-List header field whose value
        contains the request-id of the SPEAK request that was resumed.</p>
<figure id="figure-15"><div><div id="section-8.10-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S: MRCP/2.0 ... SPEAK 543258
      Channel-Identifier:32AECB23433802@speechsynth
      Voice-gender:neutral
      Voice-age:25
      Prosody-volume:medium
      Content-Type:application/ssml+xml
      Content-Length:...
      
      &lt;?xml version="1.0"?&gt;
        &lt;speak version="1.0"                
             xmlns="http://www.w3.org/2001/10/synthesis"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
             xml:lang="en-US"&gt;
         &lt;p&gt;
          &lt;s&gt;You have 4 new messages.&lt;/s&gt;
          &lt;s&gt;The first is from Stephanie Williams and arrived at 
             &lt;break/&gt;
             &lt;say-as interpret-as="vxml:time"&gt;0342p&lt;/say-as&gt;.&lt;/s&gt;
          &lt;s&gt;The subject is 
             &lt;prosody rate="-20%"&gt;ski trip&lt;/prosody&gt;&lt;/s&gt;
         &lt;/p&gt;
        &lt;/speak&gt;

S-&gt;C: MRCP/2.0 ... 543258 200 IN-PROGRESS@speechsynth
      Channel-Identifier:32AECB23433802
      Speech-Marker:timestamp=857206027059

C-&gt;S: MRCP/2.0 ... PAUSE 543259
      Channel-Identifier:32AECB23433802@speechsynth

S-&gt;C: MRCP/2.0 ... 543259 200 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Active-Request-Id-List:543258

C-&gt;S: MRCP/2.0 ... RESUME 543260
      Channel-Identifier:32AECB23433802@speechsynth

S-&gt;C: MRCP/2.0 ... 543260 200 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Active-Request-Id-List:543258
</pre></div></div>
<figcaption><a href="#figure-15">Figure 15</a><a href="#name-resume-example" id="name-resume-example" class="selfRef">RESUME Example</a></figcaption></figure></section><section id="section-8.11"><h3 id="name-control">
<a href="#section-8.11" class="section-number selfRef">8.11.Â </a><a href="#name-control" class="section-name selfRef">CONTROL</a>
</h3>
<p id="section-8.11-1">The CONTROL method from the client to the server tells a
        synthesizer that is speaking to modify what it is speaking on the fly.
        This method is used to request the synthesizer to jump forward or
        backward in what it is speaking, change speaker rate, speaker
        parameters, etc. It affects only the currently IN-PROGRESS SPEAK
        request. Depending on the implementation and capability of the
        synthesizer resource, it may or may not support the various
        modifications indicated by header fields in the CONTROL request.</p>
<p id="section-8.11-2">When a client invokes a CONTROL method to jump forward and the
        operation goes beyond the end of the active SPEAK method's text, the
        CONTROL request still succeeds. The active SPEAK request completes and
        returns a SPEAK-COMPLETE event following the response to the CONTROL
        method. If there are more SPEAK requests in the queue, the synthesizer
        resource starts at the beginning of the next SPEAK request in the
        queue.</p>
<p id="section-8.11-3">When a client invokes a CONTROL method to jump backward and the
        operation jumps to the beginning or beyond the beginning of the speech
        data of the active SPEAK method, the CONTROL request still succeeds.
        The response to the CONTROL request contains the speak-restart header
        field, and the active SPEAK request restarts from the beginning of its
        speech data.</p>
<p id="section-8.11-4">These two behaviors can be used to rewind or fast-forward across
        multiple speech requests, if the client wants to break up a speech
        markup text into multiple SPEAK requests.</p>
<p id="section-8.11-5">If a SPEAK request was active when the CONTROL method was received,
        the server MUST return an Active-Request-Id-List header field
        containing the request-id of the SPEAK request that was active.</p>
<figure id="figure-16"><div><div id="section-8.11-6" class="artwork art-text" text-align="left"><pre>
C-&gt;S: MRCP/2.0 ... SPEAK 543258
      Channel-Identifier:32AECB23433802@speechsynth
      Voice-gender:neutral
      Voice-age:25
      Prosody-volume:medium
      Content-Type:application/ssml+xml
      Content-Length:...
      
      &lt;?xml version="1.0"?&gt;
        &lt;speak version="1.0"                
             xmlns="http://www.w3.org/2001/10/synthesis"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
             xml:lang="en-US"&gt;
         &lt;p&gt;
          &lt;s&gt;You have 4 new messages.&lt;/s&gt;
          &lt;s&gt;The first is from Stephanie Williams
             and arrived at &lt;break/&gt;
             &lt;say-as interpret-as="vxml:time"&gt;0342p&lt;/say-as&gt;.&lt;/s&gt;

          &lt;s&gt;The subject is &lt;prosody
             rate="-20%"&gt;ski trip&lt;/prosody&gt;&lt;/s&gt;
         &lt;/p&gt;
        &lt;/speak&gt;

S-&gt;C: MRCP/2.0 ... 543258 200 IN-PROGRESS
      Channel-Identifier:32AECB23433802@speechsynth
      Speech-Marker:timestamp=857205016059

C-&gt;S: MRCP/2.0 ... CONTROL 543259
      Channel-Identifier:32AECB23433802@speechsynth
      Prosody-rate:fast

S-&gt;C: MRCP/2.0 ... 543259 200 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Active-Request-Id-List:543258
      Speech-Marker:timestamp=857206027059

C-&gt;S: MRCP/2.0 ... CONTROL 543260
      Channel-Identifier:32AECB23433802@speechsynth
      Jump-Size:-15 Words

S-&gt;C: MRCP/2.0 ... 543260 200 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Active-Request-Id-List:543258
      Speech-Marker:timestamp=857206039059
</pre></div></div>
<figcaption><a href="#figure-16">Figure 16</a><a href="#name-control-example" id="name-control-example" class="selfRef">CONTROL Example</a></figcaption></figure></section><section id="section-8.12"><h3 id="name-speak-complete">
<a href="#section-8.12" class="section-number selfRef">8.12.Â </a><a href="#name-speak-complete" class="section-name selfRef">SPEAK-COMPLETE</a>
</h3>
<p id="section-8.12-1">This is an Event message from the synthesizer resource to the
        client that indicates the corresponding SPEAK request was completed.
        The request-id field matches the request-id of the SPEAK request that
        initiated the speech that just completed. The request-state field is
        set to COMPLETE by the server, indicating that this is the last event
        with the corresponding request-id. The Completion-Cause header field
        specifies the cause code pertaining to the status and reason of
        request completion, such as the SPEAK completed normally or because of
        an error, kill-on-barge-in, etc.</p>
<figure id="figure-17"><div><div id="section-8.12-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S: MRCP/2.0 ... SPEAK 543260
      Channel-Identifier:32AECB23433802@speechsynth
      Voice-gender:neutral
      Voice-age:25
      Prosody-volume:medium
      Content-Type:application/ssml+xml
      Content-Length:...

      &lt;?xml version="1.0"?&gt;
        &lt;speak version="1.0"                
             xmlns="http://www.w3.org/2001/10/synthesis"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
             xml:lang="en-US"&gt;
         &lt;p&gt;
          &lt;s&gt;You have 4 new messages.&lt;/s&gt;
          &lt;s&gt;The first is from Stephanie Williams
             and arrived at &lt;break/&gt;
             &lt;say-as interpret-as="vxml:time"&gt;0342p&lt;/say-as&gt;.&lt;/s&gt;
          &lt;s&gt;The subject is 
             &lt;prosody rate="-20%"&gt;ski trip&lt;/prosody&gt;&lt;/s&gt;
         &lt;/p&gt;
        &lt;/speak&gt;

S-&gt;C: MRCP/2.0 ... 543260 200 IN-PROGRESS
      Channel-Identifier:32AECB23433802@speechsynth
      Speech-Marker:timestamp=857206027059

S-&gt;C: MRCP/2.0 ... SPEAK-COMPLETE 543260 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Completion-Cause:000 normal
      Speech-Marker:timestamp=857206039059
</pre></div></div>
<figcaption><a href="#figure-17">Figure 17</a><a href="#name-speak-complete-example" id="name-speak-complete-example" class="selfRef">SPEAK-COMPLETE Example</a></figcaption></figure></section><section id="section-8.13"><h3 id="name-speech-marker-2">
<a href="#section-8.13" class="section-number selfRef">8.13.Â </a><a href="#name-speech-marker-2" class="section-name selfRef">SPEECH-MARKER</a>
</h3>
<p id="section-8.13-1">This is an event generated by the synthesizer resource to the
        client when the synthesizer encounters a marker tag in the speech
        markup it is currently processing. The value of the request-id field
        MUST match that of the corresponding SPEAK request. The request-state
        field MUST have the value "IN-PROGRESS" as the speech is still not
        complete. The value of the speech marker tag hit, describing where the
        synthesizer is in the speech markup, MUST be returned in the
        Speech-Marker header field, along with an NTP timestamp indicating the
        instant in the output speech stream that the marker was encountered.
        The SPEECH-MARKER event MUST also be generated with a null marker
        value and output NTP timestamp when a SPEAK request in Pending-State
        (i.e., in the queue) changes state to IN-PROGRESS and starts speaking.
        The NTP timestamp MUST be synchronized with the RTP timestamp used to
        generate the speech stream through standard RTCP machinery.</p>
<figure id="figure-18"><div><div id="section-8.13-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S: MRCP/2.0 ... SPEAK 543261
      Channel-Identifier:32AECB23433802@speechsynth
      Voice-gender:neutral
      Voice-age:25
      Prosody-volume:medium
      Content-Type:application/ssml+xml
      Content-Length:...
      
      &lt;?xml version="1.0"?&gt;
        &lt;speak version="1.0"                
             xmlns="http://www.w3.org/2001/10/synthesis"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
             xml:lang="en-US"&gt;
         &lt;p&gt;
          &lt;s&gt;You have 4 new messages.&lt;/s&gt;
          &lt;s&gt;The first is from Stephanie Williams
             and arrived at &lt;break/&gt;
             &lt;say-as interpret-as="vxml:time"&gt;0342p&lt;/say-as&gt;.&lt;/s&gt;
             &lt;mark name="here"/&gt;
          &lt;s&gt;The subject is 
             &lt;prosody rate="-20%"&gt;ski trip&lt;/prosody&gt;
          &lt;/s&gt;
          &lt;mark name="ANSWER"/&gt;
         &lt;/p&gt;
        &lt;/speak&gt;

S-&gt;C: MRCP/2.0 ... 543261 200 IN-PROGRESS
      Channel-Identifier:32AECB23433802@speechsynth
      Speech-Marker:timestamp=857205015059

S-&gt;C: MRCP/2.0 ... SPEECH-MARKER 543261 IN-PROGRESS
      Channel-Identifier:32AECB23433802@speechsynth
      Speech-Marker:timestamp=857206027059;here

S-&gt;C: MRCP/2.0 ... SPEECH-MARKER 543261 IN-PROGRESS
      Channel-Identifier:32AECB23433802@speechsynth
      Speech-Marker:timestamp=857206039059;ANSWER

S-&gt;C: MRCP/2.0 ... SPEAK-COMPLETE 543261 COMPLETE
      Channel-Identifier:32AECB23433802@speechsynth
      Completion-Cause:000 normal
      Speech-Marker:timestamp=857207689259;ANSWER
</pre></div></div>
<figcaption><a href="#figure-18">Figure 18</a><a href="#name-speech-marker-example" id="name-speech-marker-example" class="selfRef">SPEECH-MARKER Example</a></figcaption></figure></section><section id="section-8.14"><div id="sec.methodDefineLexicon">
<h3 id="name-define-lexicon">
<a href="#section-8.14" class="section-number selfRef">8.14.Â </a><a href="#name-define-lexicon" class="section-name selfRef">DEFINE-LEXICON</a>
</h3>
<p id="section-8.14-1">The DEFINE-LEXICON method, from the client to the server, provides
        a lexicon and tells the server to load or unload the lexicon (see
        <a href="#load-lexicon" class="xref">Section 8.4.16</a>). The media type of the lexicon is
        provided in the Content-Type header (see <a href="#sec.lexiconData" class="xref">Section 8.5.2</a>). 

 One such media type is "application/pls+xml" for the Pronunciation
 Lexicon Specification (PLS) 
<span>[<a href="#W3C.REC-pronunciation-lexicon-20081014" class="xref">W3C.REC-pronunciation-lexicon-20081014</a>] </span><span>[<a href="#RFC4267" class="xref">RFC4267</a>].</span></p>
<p id="section-8.14-2">If the server resource is in the speaking or paused state, the
        server MUST respond with a failure status-code of 402 "Method not
        valid in this state".</p>
<p id="section-8.14-3">If the resource is in the idle state and is able to successfully
        load/unload the lexicon, the status MUST return a 200 "Success"
        status-code and the request-state MUST be COMPLETE.</p>
<p id="section-8.14-4">If the synthesizer could not define the lexicon for some reason,
        for example, because the download failed or the lexicon was in an
        unsupported form, the server MUST respond with a failure status-code
        of 407 and a Completion-Cause header field describing the failure
        reason.</p>
</div></section>
</div></section><section id="section-9"><div id="sec.recognizerResource">
<h2 id="name-speech-recognizer-resource">
<a href="#section-9" class="section-number selfRef">9.Â </a><a href="#name-speech-recognizer-resource" class="section-name selfRef">Speech Recognizer Resource</a>
</h2>
<p id="section-9-1">The speech recognizer resource receives an incoming voice stream and
      provides the client with an interpretation of what was spoken in textual
      form.</p>
<p id="section-9-2">The recognizer resource is controlled by MRCPv2 requests from the
      client. The recognizer resource can both respond to these requests and
      generate asynchronous events to the client to indicate conditions of
      interest during the processing of the method.</p>
<p id="section-9-3">This section applies to the following resource types. 

</p>
<ol id="section-9-4">
<li id="section-9-5">speechrecog</li>
<li id="section-9-6">dtmfrecog</li>
</ol>
<p id="section-9-7">The difference between the above two resources is in their level of
      support for recognition grammars. The "dtmfrecog" resource type is
      capable of recognizing only DTMF digits and hence accepts only DTMF
      grammars. It only generates barge-in for DTMF inputs and ignores speech.
      The "speechrecog" resource type can recognize regular speech as well as
      DTMF digits and hence MUST support grammars describing either speech or
      DTMF. This resource generates barge-in events for speech and/or DTMF. By
      analyzing the grammars that are activated by the RECOGNIZE method, it
      determines if a barge-in should occur for speech and/or DTMF. When the
      recognizer decides it needs to generate a barge-in, it also generates a
      START-OF-INPUT event to the client. The recognizer resource MAY support
      recognition in the normal or hotword modes or both (although note that a
      single "speechrecog" resource does not perform normal and hotword mode
      recognition simultaneously). For implementations where a single
      recognizer resource does not support both modes, or simultaneous normal
      and hotword recognition is desired, the two modes can be invoked through
      separate resources allocated to the same SIP dialog (with different MRCP
      session identifiers) and share the RTP audio feed.</p>
<p id="section-9-8">The capabilities of the recognizer resource are enumerated
      below:</p>
<dl id="section-9-9" class="dlParallel">
<dt id="section-9-10">Normal Mode Recognition</dt>
<dd id="section-9-11">Normal mode recognition tries
          to match all of the speech or DTMF against the grammar and returns a
          no-match status if the input fails to match or the method times
          out.</dd>
<dt id="section-9-12">Hotword Mode Recognition</dt>
<dd id="section-9-13">Hotword mode is where the
          recognizer looks for a match against specific speech grammar or DTMF
          sequence and ignores speech or DTMF that does not match. The
          recognition completes only if there is a successful match of grammar, if
          the client cancels the request, or if there is a non-input or
          recognition timeout.</dd>
<dt id="section-9-14">Voice Enrolled Grammars</dt>
<dd id="section-9-15">A recognizer resource MAY
          optionally support Voice Enrolled Grammars. With this functionality,
          enrollment is performed using a person's voice. For example, a list
          of contacts can be created and maintained by recording the person's
          names using the caller's voice. This technique is sometimes also
          called speaker-dependent recognition.</dd>
<dt id="section-9-16">Interpretation</dt>
<dd id="section-9-17">A recognizer resource MAY be employed
          strictly for its natural language interpretation capabilities by
          supplying it with a text string as input instead of speech. In this
          mode, the resource takes text as input and produces an
          "interpretation" of the input according to the supplied grammar.</dd>
</dl>
<p id="section-9-18">Voice enrollment has the concept of an enrollment session. A session
      to add a new phrase to a personal grammar involves the initial
      enrollment followed by a repeat of enough utterances before committing
      the new phrase to the personal grammar. Each time an utterance is
      recorded, it is compared for similarity with the other samples and a
      clash test is performed against other entries in the personal grammar to
      ensure there are no similar and confusable entries.</p>
<p id="section-9-19">Enrollment is done using a recognizer resource. Controlling which
      utterances are to be considered for enrollment of a new phrase is done
      by setting a header field (see <a href="#sec.phraseID" class="xref">Section 9.4.39</a>) in
      the Recognize request.</p>
<p id="section-9-20">Interpretation is accomplished through the INTERPRET method (<a href="#sec.interpret" class="xref">Section 9.20</a>) and the Interpret-Text header field
      (<a href="#sec.interpretText" class="xref">Section 9.4.30</a>).</p>
<section id="section-9.1"><h3 id="name-recognizer-state-machine">
<a href="#section-9.1" class="section-number selfRef">9.1.Â </a><a href="#name-recognizer-state-machine" class="section-name selfRef">Recognizer State Machine</a>
</h3>
<p id="section-9.1-1">The recognizer resource maintains a state machine to process MRCPv2
        requests from the client.</p>
<figure id="figure-19"><div><div id="section-9.1-2" class="artwork art-text" text-align="left"><pre>
Idle                   Recognizing               Recognized
State                  State                     State
 |                       |                          |
 |---------RECOGNIZE----&gt;|---RECOGNITION-COMPLETE--&gt;|
 |&lt;------STOP------------|&lt;-----RECOGNIZE-----------|
 |                       |                          |
 |              |--------|              |-----------|
 |       START-OF-INPUT  |       GET-RESULT         |
 |              |-------&gt;|              |----------&gt;|
 |------------|          |                          |
 |      DEFINE-GRAMMAR   |----------|               |
 |&lt;-----------|          | START-INPUT-TIMERS       |
 |                       |&lt;---------|               |
 |------|                |                          |
 |  INTERPRET            |                          |
 |&lt;-----|                |------|                   |
 |                       |   RECOGNIZE              |
 |-------|               |&lt;-----|                   |
 |      STOP                                        |
 |&lt;------|                                          |
 |&lt;-------------------STOP--------------------------|
 |&lt;-------------------DEFINE-GRAMMAR----------------|      
</pre></div></div>
<figcaption><a href="#figure-19">Figure 19</a><a href="#name-recognizer-state-machine-2" id="name-recognizer-state-machine-2" class="selfRef">Recognizer State Machine</a></figcaption></figure><p id="section-9.1-3">If a recognizer resource supports voice enrolled grammars,
        starting an enrollment session does not change the state of the
        recognizer resource. Once an enrollment session is started, then
        utterances are enrolled by calling the RECOGNIZE method repeatedly.
        The state of the speech recognizer resource goes from IDLE to
        RECOGNIZING state each time RECOGNIZE is called.</p></section><section id="section-9.2"><h3 id="name-recognizer-methods">
<a href="#section-9.2" class="section-number selfRef">9.2.Â </a><a href="#name-recognizer-methods" class="section-name selfRef">Recognizer Methods</a>
</h3>
<p id="section-9.2-1">The recognizer supports the following methods.</p>
<div id="section-9.2-2" class="artwork art-text" text-align="left"><pre>
recognizer-method    =  recog-only-method
                     /  enrollment-method

recog-only-method    =  "DEFINE-GRAMMAR"
                     /  "RECOGNIZE"
                     /  "INTERPRET"
                     /  "GET-RESULT"
                     /  "START-INPUT-TIMERS"
                     /  "STOP"
</pre></div>
<p id="section-9.2-3">It is OPTIONAL for a recognizer resource to support voice enrolled
        grammars. If the recognizer resource does support voice enrolled
        grammars, it MUST support the following methods.</p>
<div id="section-9.2-4" class="artwork art-text" text-align="left"><pre>
enrollment-method    =  "START-PHRASE-ENROLLMENT"
                     /  "ENROLLMENT-ROLLBACK"
                     /  "END-PHRASE-ENROLLMENT"
                     /  "MODIFY-PHRASE"
                     /  "DELETE-PHRASE"
</pre></div></section><section id="section-9.3"><h3 id="name-recognizer-events">
<a href="#section-9.3" class="section-number selfRef">9.3.Â </a><a href="#name-recognizer-events" class="section-name selfRef">Recognizer Events</a>
</h3>
<p id="section-9.3-1">The recognizer can generate the following events.</p>
<div id="section-9.3-2" class="artwork art-text" text-align="left"><pre>
recognizer-event     =  "START-OF-INPUT"
                     /  "RECOGNITION-COMPLETE"
                     /  "INTERPRETATION-COMPLETE"
</pre></div></section><section id="section-9.4"><div id="sec.recognizerHeaders">
<h3 id="name-recognizer-header-fields">
<a href="#section-9.4" class="section-number selfRef">9.4.Â </a><a href="#name-recognizer-header-fields" class="section-name selfRef">Recognizer Header Fields</a>
</h3>
<p id="section-9.4-1">A recognizer message can contain header fields containing request
        options and information to augment the Method, Response, or Event
        message it is associated with.</p>
<div id="section-9.4-2" class="artwork art-text" text-align="left"><pre>
recognizer-header    =  recog-only-header
                     /  enrollment-header

recog-only-header    =  confidence-threshold
                     /  sensitivity-level
                     /  speed-vs-accuracy
                     /  n-best-list-length
                     /  no-input-timeout
                     /  input-type
                     /  recognition-timeout
                     /  waveform-uri
                     /  input-waveform-uri
                     /  completion-cause
                     /  completion-reason
                     /  recognizer-context-block
                     /  start-input-timers
                     /  speech-complete-timeout
                     /  speech-incomplete-timeout
                     /  dtmf-interdigit-timeout
                     /  dtmf-term-timeout
                     /  dtmf-term-char
                     /  failed-uri
                     /  failed-uri-cause
                     /  save-waveform
                     /  media-type
                     /  new-audio-channel
                     /  speech-language
                     /  ver-buffer-utterance
                     /  recognition-mode
                     /  cancel-if-queue
                     /  hotword-max-duration
                     /  hotword-min-duration
                     /  interpret-text
                     /  dtmf-buffer-time
                     /  clear-dtmf-buffer
                     /  early-no-match
</pre></div>
<p id="section-9.4-3">If a recognizer resource supports voice enrolled grammars, the
        following header fields are also used.</p>
<div id="section-9.4-4" class="artwork art-text" text-align="left"><pre>
enrollment-header    =  num-min-consistent-pronunciations
                     /  consistency-threshold
                     /  clash-threshold
                     /  personal-grammar-uri
                     /  enroll-utterance
                     /  phrase-id
                     /  phrase-nl
                     /  weight
                     /  save-best-waveform
                     /  new-phrase-id
                     /  confusable-phrases-uri
                     /  abort-phrase-enrollment
</pre></div>
<p id="section-9.4-5">For enrollment-specific header fields that can appear as part of
        SETâ€‘PARAMS or GET-PARAMS methods, the following general rule applies:
        the START-PHRASE-ENROLLMENT method MUST be invoked before these header
        fields may be set through the SET-PARAMS method or retrieved through
        the GET-PARAMS method.</p>
<p id="section-9.4-6">Note that the Waveform-URI header field of the Recognizer resource
        can also appear in the response to the END-PHRASE-ENROLLMENT
        method.</p>
<section id="section-9.4.1"><div id="sec.confidenceThreshold">
<h4 id="name-confidence-threshold">
<a href="#section-9.4.1" class="section-number selfRef">9.4.1.Â </a><a href="#name-confidence-threshold" class="section-name selfRef">Confidence-Threshold</a>
</h4>
<p id="section-9.4.1-1">When a recognizer resource recognizes or matches a spoken phrase
          with some portion of the grammar, it associates a confidence level
          with that match. The Confidence-Threshold header field tells the
          recognizer resource what confidence level the client considers a
          successful match. This is a float value between 0.0-1.0 indicating
          the recognizer's confidence in the recognition. If the recognizer
          determines that there is no candidate match with a confidence that
          is greater than the confidence threshold, then it MUST return
          no-match as the recognition result. This header field MAY occur in
          RECOGNIZE, SET-PARAMS, or GET-PARAMS. The default value for this
          header field is implementation specific, as is the interpretation of
          any specific value for this header field. Although values for
          servers from different vendors are not comparable, it is expected
          that clients will tune this value over time for a given server.</p>
<div id="section-9.4.1-2" class="artwork art-text" text-align="left"><pre>
confidence-threshold     =  "Confidence-Threshold" ":" FLOAT CRLF</pre></div>
</div></section><section id="section-9.4.2"><h4 id="name-sensitivity-level">
<a href="#section-9.4.2" class="section-number selfRef">9.4.2.Â </a><a href="#name-sensitivity-level" class="section-name selfRef">Sensitivity-Level</a>
</h4>
<p id="section-9.4.2-1">To filter out background noise and not mistake it for speech, the
          recognizer resource supports a variable level of sound sensitivity.
          The Sensitivity-Level header field is a float value between 0.0 and
          1.0 and allows the client to set the sensitivity level for the
          recognizer. This header field MAY occur in RECOGNIZE, SET-PARAMS, or
          GET-PARAMS. A higher value for this header field means higher
          sensitivity. The default value for this header field is
          implementation specific, as is the interpretation of any specific
          value for this header field. Although values for servers from
          different vendors are not comparable, it is expected that clients
          will tune this value over time for a given server.</p>
<div id="section-9.4.2-2" class="artwork art-text" text-align="left"><pre>
sensitivity-level        =  "Sensitivity-Level" ":" FLOAT CRLF
            </pre></div></section><section id="section-9.4.3"><h4 id="name-speed-vs-accuracy">
<a href="#section-9.4.3" class="section-number selfRef">9.4.3.Â </a><a href="#name-speed-vs-accuracy" class="section-name selfRef">Speed-Vs-Accuracy</a>
</h4>
<p id="section-9.4.3-1">Depending on the implementation and capability of the recognizer
          resource it may be tunable towards Performance or Accuracy. Higher
          accuracy may mean more processing and higher CPU utilization,
          meaning fewer active sessions per server and vice versa. The value
          is a float between 0.0 and 1.0. A value of 0.0 means fastest
          recognition. A value of 1.0 means best accuracy. This header field
          MAY occur in RECOGNIZE, SET-PARAMS, or GET-PARAMS. The default value
          for this header field is implementation specific. Although values
          for servers from different vendors are not comparable, it is
          expected that clients will tune this value over time for a given
          server.</p>
<div id="section-9.4.3-2" class="artwork art-text" text-align="left"><pre>
speed-vs-accuracy        =  "Speed-Vs-Accuracy" ":" FLOAT CRLF
            </pre></div></section><section id="section-9.4.4"><h4 id="name-n-best-list-length">
<a href="#section-9.4.4" class="section-number selfRef">9.4.4.Â </a><a href="#name-n-best-list-length" class="section-name selfRef">N-Best-List-Length</a>
</h4>
<p id="section-9.4.4-1">When the recognizer matches an incoming stream with the grammar,
          it may come up with more than one alternative match because of
          confidence levels in certain words or conversation paths. If this
          header field is not specified, by default, the recognizer resource
          returns only the best match above the confidence threshold. The
          client, by setting this header field, can ask the recognition
          resource to send it more than one alternative. All alternatives must
          still be above the Confidence-Threshold. A value greater than one
          does not guarantee that the recognizer will provide the requested
          number of alternatives. This header field MAY occur in RECOGNIZE,
          SET-PARAMS, or GET-PARAMS. The minimum value for this header field is
          1. The default value for this header field is 1.</p>
<div id="section-9.4.4-2" class="artwork art-text" text-align="left"><pre>
n-best-list-length       =  "N-Best-List-Length" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-9.4.5"><h4 id="name-input-type">
<a href="#section-9.4.5" class="section-number selfRef">9.4.5.Â </a><a href="#name-input-type" class="section-name selfRef">Input-Type</a>
</h4>
<p id="section-9.4.5-1">When the recognizer detects barge-in-able input and generates a
          START-OF-INPUT event, that event MUST carry this header field to
          specify whether the input that caused the barge-in was DTMF or
          speech.</p>
<div id="section-9.4.5-2" class="artwork art-text" text-align="left"><pre>
input-type         =  "Input-Type" ":"  inputs CRLF
inputs             =  "speech" / "dtmf"
            </pre></div></section><section id="section-9.4.6"><h4 id="name-no-input-timeout">
<a href="#section-9.4.6" class="section-number selfRef">9.4.6.Â </a><a href="#name-no-input-timeout" class="section-name selfRef">No-Input-Timeout</a>
</h4>
<p id="section-9.4.6-1">When recognition is started and there is no speech detected for a
          certain period of time, the recognizer can send a
          RECOGNITION-COMPLETE event to the client with a Completion-Cause of
          "no-input-timeout" and terminate the recognition operation. The
          client can use the No-Input-Timeout header field to set this
          timeout. The value is in milliseconds and can range from 0 to an
          implementation-specific maximum value. This header field MAY occur
          in RECOGNIZE, SET-PARAMS, or GET-PARAMS. The default value is
          implementation specific.</p>
<div id="section-9.4.6-2" class="artwork art-text" text-align="left"><pre>
no-input-timeout         =  "No-Input-Timeout" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-9.4.7"><h4 id="name-recognition-timeout">
<a href="#section-9.4.7" class="section-number selfRef">9.4.7.Â </a><a href="#name-recognition-timeout" class="section-name selfRef">Recognition-Timeout</a>
</h4>
<p id="section-9.4.7-1">When recognition is started and there is no match for a certain
          period of time, the recognizer can send a RECOGNITION-COMPLETE event
          to the client and terminate the recognition operation. The
          Recognition-Timeout header field allows the client to set this
          timeout value. The value is in milliseconds. The value for this
          header field ranges from 0 to an implementation-specific maximum
          value. The default value is 10 seconds. This header field MAY occur
          in RECOGNIZE, SET-PARAMS, or GET-PARAMS.</p>
<div id="section-9.4.7-2" class="artwork art-text" text-align="left"><pre>
recognition-timeout      =  "Recognition-Timeout" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-9.4.8"><h4 id="name-waveform-uri">
<a href="#section-9.4.8" class="section-number selfRef">9.4.8.Â </a><a href="#name-waveform-uri" class="section-name selfRef">Waveform-URI</a>
</h4>
<p id="section-9.4.8-1">If the Save-Waveform header field is set to "true", the recognizer
          MUST record the incoming audio stream of the recognition into a
          stored form and provide a URI for the client to access it. This
          header field MUST be present in the RECOGNITION-COMPLETE event if
          the Save-Waveform header field was set to "true". The value of the
          header field MUST be empty if there was some error condition
          preventing the server from recording. Otherwise, the URI generated
          by the server MUST be unambiguous across the server and all its
          recognition sessions. The content associated with the URI MUST be
          available to the client until the MRCPv2 session terminates.</p>
<p id="section-9.4.8-2">Similarly, if the Save-Best-Waveform header field is set to "true",
          the recognizer MUST save the audio stream for the best repetition of
          the phrase that was used during the enrollment session. The
          recognizer MUST then record the recognized audio and make it
          available to the client by returning a URI in the Waveform-URI
          header field in the response to the END-PHRASE-ENROLLMENT method.
          The value of the header field MUST be empty if there was some error
          condition preventing the server from recording. Otherwise, the URI
          generated by the server MUST be unambiguous across the server and
          all its recognition sessions. The content associated with the URI
          MUST be available to the client until the MRCPv2 session terminates.
          See the discussion on the sensitivity of saved waveforms in <a href="#sec.securityConsiderations" class="xref">Section 12</a>.</p>
<p id="section-9.4.8-3">The server MUST also return the size in octets and the duration
          in milliseconds of the recorded audio waveform as parameters
          associated with the header field.</p>
<div id="section-9.4.8-4" class="artwork art-text" text-align="left"><pre>
waveform-uri             =  "Waveform-URI" ":" ["&lt;" uri "&gt;" 
                            ";" "size" "=" 1*19DIGIT 
                            ";" "duration" "=" 1*19DIGIT] CRLF
            </pre></div></section><section id="section-9.4.9"><h4 id="name-media-type">
<a href="#section-9.4.9" class="section-number selfRef">9.4.9.Â </a><a href="#name-media-type" class="section-name selfRef">Media-Type</a>
</h4>
<p id="section-9.4.9-1">This header field MAY be specified in the SET-PARAMS, GET-PARAMS,
          or the RECOGNIZE methods and tells the server resource the media
          type in which to store captured audio or video, such as the one
          captured and returned by the Waveform-URI header field.</p>
<div id="section-9.4.9-2" class="artwork art-text" text-align="left"><pre>
media-type               =  "Media-Type" ":" media-type-value 
                            CRLF
            </pre></div></section><section id="section-9.4.10"><h4 id="name-input-waveform-uri">
<a href="#section-9.4.10" class="section-number selfRef">9.4.10.Â </a><a href="#name-input-waveform-uri" class="section-name selfRef">Input-Waveform-URI</a>
</h4>
<p id="section-9.4.10-1">This optional header field specifies a URI pointing to audio
          content to be processed by the RECOGNIZE operation. This enables the
          client to request recognition from a specified buffer or audio
          file.</p>
<div id="section-9.4.10-2" class="artwork art-text" text-align="left"><pre>
input-waveform-uri       =  "Input-Waveform-URI" ":" uri CRLF
            </pre></div></section><section id="section-9.4.11"><h4 id="name-completion-cause-2">
<a href="#section-9.4.11" class="section-number selfRef">9.4.11.Â </a><a href="#name-completion-cause-2" class="section-name selfRef">Completion-Cause</a>
</h4>
<p id="section-9.4.11-1">This header field MUST be part of a RECOGNITION-COMPLETE event
          coming from the recognizer resource to the client. It indicates the
          reason behind the RECOGNIZE method completion. This header field
          MUST be sent in the DEFINE-GRAMMAR and RECOGNIZE responses, if they
          return with a failure status and a COMPLETE state. In the ABNF
          below, the cause-code contains a numerical value selected from the
          Cause-Code column of the following table. The cause-name contains
          the corresponding token selected from the Cause-Name column.</p>
<div id="section-9.4.11-2" class="artwork art-text" text-align="left"><pre>
completion-cause         =  "Completion-Cause" ":" cause-code SP
                            cause-name CRLF
cause-code               =  3DIGIT
cause-name               =  *VCHAR
            </pre></div>
<table id="table-6">
<thead><tr>
<th>Cause- Code</th>
<th>Cause-Name</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr>
<td>000</td>
<td>success</td>
<td>RECOGNIZE completed with a match or DEFINE-GRAMMAR succeeded in
            downloading and compiling the grammar.</td>
</tr>
<tr>
<td>001</td>
<td>no-match</td>
<td>RECOGNIZE completed, but no match was found.</td>
</tr>
<tr>
<td>002</td>
<td>no-input-timeout</td>
<td>RECOGNIZE completed without a match due to a
            no-input-timeout.</td>
</tr>
<tr>
<td>003</td>
<td>hotword-maxtime</td>
<td>RECOGNIZE in hotword mode completed without a match due to a
            recognition-timeout.</td>
</tr>
<tr>
<td>004</td>
<td>grammar-load-failure</td>
<td>RECOGNIZE failed due to grammar load failure.</td>
</tr>
<tr>
<td>005</td>
<td>grammar-compilation- failure</td>
<td>RECOGNIZE failed due to grammar compilation failure.</td>
</tr>
<tr>
<td>006</td>
<td>recognizer-error</td>
<td>RECOGNIZE request terminated prematurely due to a recognizer
            error.</td>
</tr>
<tr>
<td>007</td>
<td>speech-too-early</td>
<td>RECOGNIZE request terminated because speech was too early. This
            happens when the audio stream is already "in-speech" when the
            RECOGNIZE request was received.</td>
</tr>
<tr>
<td>008</td>
<td>success-maxtime</td>
<td>RECOGNIZE request terminated because speech was too long but
            whatever was spoken till that point was a full match.</td>
</tr>
<tr>
<td>009</td>
<td>uri-failure</td>
<td>Failure accessing a URI.</td>
</tr>
<tr>
<td>010</td>
<td>language-unsupported</td>
<td>Language not supported.</td>
</tr>
<tr>
<td>011</td>
<td>cancelled</td>
<td>A new RECOGNIZE cancelled this one, or a prior RECOGNIZE failed
            while this one was still in the queue.</td>
</tr>
<tr>
<td>012</td>
<td>semantics-failure</td>
<td>Recognition succeeded, but semantic interpretation of the
            recognized input failed. The RECOGNITION-COMPLETE event MUST
            contain the Recognition result with only input text and no
            interpretation.</td>
</tr>
<tr>
<td>013</td>
<td>partial-match</td>
<td>Speech Incomplete Timeout expired before there was a full
            match. But whatever was spoken till that point was a partial
            match to one or more grammars.</td>
</tr>
<tr>
<td>014</td>
<td>partial-match-maxtime</td>
<td>The Recognition-Timeout expired before full match was achieved.
            But whatever was spoken till that point was a partial match to one
            or more grammars.</td>
</tr>
<tr>
<td>015</td>
<td>no-match-maxtime</td>
<td>The Recognition-Timeout expired. Whatever was spoken till that
            point did not match any of the grammars. This cause could
            also be returned if the recognizer does not support detecting
            partial grammar matches.</td>
</tr>
<tr>
<td>016</td>
<td>grammar-definition- failure</td>
<td>Any DEFINE-GRAMMAR error other than grammar-load-failure and
            grammar-compilation-failure.</td>
</tr>
</tbody>
</table></section><section id="section-9.4.12"><h4 id="name-completion-reason-2">
<a href="#section-9.4.12" class="section-number selfRef">9.4.12.Â </a><a href="#name-completion-reason-2" class="section-name selfRef">Completion-Reason</a>
</h4>
<p id="section-9.4.12-1">This header field MAY be specified in a RECOGNITION-COMPLETE
          event coming from the recognizer resource to the client. This
          contains the reason text behind the RECOGNIZE request completion.
          The server uses this header field to communicate text describing the
          reason for the failure, such as the specific error encountered in
          parsing a grammar markup.</p>
<p id="section-9.4.12-2">The completion reason text is provided for client use in logs and
          for debugging and instrumentation purposes. Clients MUST NOT
          interpret the completion reason text.</p>
<div id="section-9.4.12-3" class="artwork art-text" text-align="left"><pre>
completion-reason        =  "Completion-Reason" ":" 
                            quoted-string CRLF
            </pre></div></section><section id="section-9.4.13"><h4 id="name-recognizer-context-block">
<a href="#section-9.4.13" class="section-number selfRef">9.4.13.Â </a><a href="#name-recognizer-context-block" class="section-name selfRef">Recognizer-Context-Block</a>
</h4>
<p id="section-9.4.13-1">This header field MAY be sent as part of the SET-PARAMS or
          GET-PARAMS request. If the GET-PARAMS method contains this header
          field with no value, then it is a request to the recognizer to
          return the recognizer context block. The response to such a message
          MAY contain a recognizer context block as a typed media message
          body. If the server returns a recognizer context block, the response
          MUST contain this header field and its value MUST match the
          Content-ID of the corresponding media block.</p>
<p id="section-9.4.13-2">If the SET-PARAMS method contains this header field, it MUST also
          contain a message body containing the recognizer context data and a
          Content-ID matching this header field value. This Content-ID MUST
          match the Content-ID that came with the context data during the
          GETâ€‘PARAMS operation.</p>
<p id="section-9.4.13-3">An implementation choosing to use this mechanism to hand off
          recognizer context data between servers MUST distinguish its
          implementation-specific block of data by using an IANA-registered
          content type in the IANA Media Type vendor tree.</p>
<div id="section-9.4.13-4" class="artwork art-text" text-align="left"><pre>
recognizer-context-block  =  "Recognizer-Context-Block" ":"
                             [1*VCHAR] CRLF
            </pre></div></section><section id="section-9.4.14"><div id="sec.startInputTimers">
<h4 id="name-start-input-timers">
<a href="#section-9.4.14" class="section-number selfRef">9.4.14.Â </a><a href="#name-start-input-timers" class="section-name selfRef">Start-Input-Timers</a>
</h4>
<p id="section-9.4.14-1">This header field MAY be sent as part of the RECOGNIZE request. A
          value of false tells the recognizer to start recognition but not to
          start the no-input timer yet. The recognizer MUST NOT start the
          timers until the client sends a START-INPUT-TIMERS request to the
          recognizer. This is useful in the scenario when the recognizer and
          synthesizer engines are not part of the same session. In such
          configurations, when a kill-on-barge-in prompt is being played (see
          <a href="#sec.kill-on-barge-in" class="xref">Section 8.4.2</a>), the client wants the
          RECOGNIZE request to be simultaneously active so that it can detect
          and implement kill-on-barge-in. However, the recognizer SHOULD NOT
          start the no-input timers until the prompt is finished. The default
          value is "true".</p>
<div id="section-9.4.14-2" class="artwork art-text" text-align="left"><pre>
start-input-timers  =  "Start-Input-Timers" ":" BOOLEAN CRLF
            </pre></div>
</div></section><section id="section-9.4.15"><div id="sec.speechCompleteTimeout">
<h4 id="name-speech-complete-timeout">
<a href="#section-9.4.15" class="section-number selfRef">9.4.15.Â </a><a href="#name-speech-complete-timeout" class="section-name selfRef">Speech-Complete-Timeout</a>
</h4>
<p id="section-9.4.15-1">This header field specifies the length of silence required
          following user speech before the speech recognizer finalizes a
          result (either accepting it or generating a no-match result). The
          Speech-Complete-Timeout value applies when the recognizer currently
          has a complete match against an active grammar, and specifies how
          long the recognizer MUST wait for more input before declaring a
          match. By contrast, the Speech-Incomplete-Timeout is used when the speech
          is an incomplete match to an active grammar. The value is in
          milliseconds.</p>
<div id="section-9.4.15-2" class="artwork art-text" text-align="left"><pre>
speech-complete-timeout = "Speech-Complete-Timeout" ":"
                          1*19DIGIT CRLF
            </pre></div>
<p id="section-9.4.15-3">A long Speech-Complete-Timeout value delays the result to the
          client and therefore makes the application's response to a user
          slow. A short Speech-Complete-Timeout may lead to an utterance being
          broken up inappropriately. Reasonable speech complete timeout values
          are typically in the range of 0.3 seconds to 1.0 seconds. The value
          for this header field ranges from 0 to an implementation-specific
          maximum value. The default value for this header field is
          implementation specific. This header field MAY occur in RECOGNIZE,
          SET-PARAMS, or GET-PARAMS.</p>
</div></section><section id="section-9.4.16"><h4 id="name-speech-incomplete-timeout">
<a href="#section-9.4.16" class="section-number selfRef">9.4.16.Â </a><a href="#name-speech-incomplete-timeout" class="section-name selfRef">Speech-Incomplete-Timeout</a>
</h4>
<p id="section-9.4.16-1">This header field specifies the required length of silence
          following user speech after which a recognizer finalizes a result.
          The incomplete timeout applies when the speech prior to the silence
          is an incomplete match of all active grammars. In this case, once
          the timeout is triggered, the partial result is rejected (with a
          Completion-Cause of "partial-match"). The value is in milliseconds.
          The value for this header field ranges from 0 to an implementation-specific maximum value. The default value for this header field is
          implementation specific.</p>
<div id="section-9.4.16-2" class="artwork art-text" text-align="left"><pre>
speech-incomplete-timeout = "Speech-Incomplete-Timeout" ":" 1*19DIGIT 
                             CRLF
            </pre></div>
<p id="section-9.4.16-3">The Speech-Incomplete-Timeout also applies when the speech prior
          to the silence is a complete match of an active grammar, but where
          it is possible to speak further and still match the grammar. By
          contrast, the Speech-Complete-Timeout is used when the speech is a complete
          match to an active grammar and no further spoken words can continue
          to represent a match.</p>
<p id="section-9.4.16-4">A long Speech-Incomplete-Timeout value delays the result to the
          client and therefore makes the application's response to a user
          slow. A short Speech-Incomplete-Timeout may lead to an utterance
          being broken up inappropriately.</p>
<p id="section-9.4.16-5">The Speech-Incomplete-Timeout is usually longer than the
          Speech-Complete-Timeout to allow users to pause mid-utterance (for
          example, to breathe). This header field MAY occur in RECOGNIZE,
          SET-PARAMS, or GET-PARAMS.</p></section><section id="section-9.4.17"><h4 id="name-dtmf-interdigit-timeout">
<a href="#section-9.4.17" class="section-number selfRef">9.4.17.Â </a><a href="#name-dtmf-interdigit-timeout" class="section-name selfRef">DTMF-Interdigit-Timeout</a>
</h4>
<p id="section-9.4.17-1">This header field specifies the inter-digit timeout value to use
          when recognizing DTMF input. The value is in milliseconds. The value
          for this header field ranges from 0 to an implementation-specific
          maximum value. The default value is 5 seconds. This header field MAY
          occur in RECOGNIZE, SET-PARAMS, or GET-PARAMS.</p>
<div id="section-9.4.17-2" class="artwork art-text" text-align="left"><pre>
dtmf-interdigit-timeout = "DTMF-Interdigit-Timeout" ":"
                           1*19DIGIT CRLF
            </pre></div></section><section id="section-9.4.18"><h4 id="name-dtmf-term-timeout">
<a href="#section-9.4.18" class="section-number selfRef">9.4.18.Â </a><a href="#name-dtmf-term-timeout" class="section-name selfRef">DTMF-Term-Timeout</a>
</h4>
<p id="section-9.4.18-1">This header field specifies the terminating timeout to use when
          recognizing DTMF input. The DTMF-Term-Timeout applies only when no
          additional input is allowed by the grammar; otherwise, the
          DTMFâ€‘Interdigitâ€‘Timeout applies. The value is in milliseconds. The
          value for this header field ranges from 0 to an implementation-specific maximum value. The default value is 10 seconds. This header
          field MAY occur in RECOGNIZE, SET-PARAMS, or GET-PARAMS.</p>
<div id="section-9.4.18-2" class="artwork art-text" text-align="left"><pre>
dtmf-term-timeout        =  "DTMF-Term-Timeout" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-9.4.19"><h4 id="name-dtmf-term-char">
<a href="#section-9.4.19" class="section-number selfRef">9.4.19.Â </a><a href="#name-dtmf-term-char" class="section-name selfRef">DTMF-Term-Char</a>
</h4>
<p id="section-9.4.19-1">This header field specifies the terminating DTMF character for
          DTMF input recognition. The default value is NULL, which is indicated
          by an empty header field value. This header field MAY occur in
          RECOGNIZE, SET-PARAMS, or GET-PARAMS.</p>
<div id="section-9.4.19-2" class="artwork art-text" text-align="left"><pre>
dtmf-term-char           =  "DTMF-Term-Char" ":" VCHAR CRLF
            </pre></div></section><section id="section-9.4.20"><h4 id="name-failed-uri-2">
<a href="#section-9.4.20" class="section-number selfRef">9.4.20.Â </a><a href="#name-failed-uri-2" class="section-name selfRef">Failed-URI</a>
</h4>
<p id="section-9.4.20-1">When a recognizer needs to fetch or access a URI and the access
          fails, the server SHOULD provide the failed URI in this header field
          in the method response, unless there are multiple URI failures, in
          which case one of the failed URIs MUST be provided in this header
          field in the method response.</p>
<div id="section-9.4.20-2" class="artwork art-text" text-align="left"><pre>
failed-uri               =  "Failed-URI" ":" absoluteURI CRLF
            </pre></div></section><section id="section-9.4.21"><h4 id="name-failed-uri-cause-2">
<a href="#section-9.4.21" class="section-number selfRef">9.4.21.Â </a><a href="#name-failed-uri-cause-2" class="section-name selfRef">Failed-URI-Cause</a>
</h4>
<p id="section-9.4.21-1">When a recognizer method needs a recognizer to fetch or access a
          URI and the access fails, the server MUST provide the URI-specific or
          protocol-specific response code for the URI in the Failed-URI header
          field through this header field in the method response. The value
          encoding is UTF-8 (<span>[<a href="#RFC3629" class="xref">RFC 3629</a>]) to
          accommodate any access protocol, some of which might have a response
          string instead of a numeric response code.</span></p>
<div id="section-9.4.21-2" class="artwork art-text" text-align="left"><pre>
failed-uri-cause         =  "Failed-URI-Cause" ":" 1*UTFCHAR CRLF
            </pre></div></section><section id="section-9.4.22"><h4 id="name-save-waveform">
<a href="#section-9.4.22" class="section-number selfRef">9.4.22.Â </a><a href="#name-save-waveform" class="section-name selfRef">Save-Waveform</a>
</h4>
<p id="section-9.4.22-1">This header field allows the client to request the recognizer
          resource to save the audio input to the recognizer. The recognizer
          resource MUST then attempt to record the recognized audio, without
          endpointing, and make it available to the client in the form of a
          URI returned in the Waveform-URI header field in the
          RECOGNITION-COMPLETE event. If there was an error in recording the
          stream or the audio content is otherwise not available, the
          recognizer MUST return an empty Waveform-URI header field. The
          default value for this field is "false". This header field MAY occur
          in RECOGNIZE, SET-PARAMS, or GET-PARAMS. See the discussion on the
          sensitivity of saved waveforms in <a href="#sec.securityConsiderations" class="xref">Section 12</a>.</p>
<div id="section-9.4.22-2" class="artwork art-text" text-align="left"><pre>
save-waveform            =  "Save-Waveform" ":" BOOLEAN CRLF
            </pre></div></section><section id="section-9.4.23"><div id="sec.newAudioChannel">
<h4 id="name-new-audio-channel">
<a href="#section-9.4.23" class="section-number selfRef">9.4.23.Â </a><a href="#name-new-audio-channel" class="section-name selfRef">New-Audio-Channel</a>
</h4>
<p id="section-9.4.23-1">This header field MAY be specified in a RECOGNIZE request and
          allows the client to tell the server that, from this point on,
          further input audio comes from a different audio source, channel, or
          speaker. If the recognizer resource had collected any input
          statistics or adaptation state, the recognizer resource MUST do
          what is appropriate for the specific recognition technology, which
          includes but is not limited to discarding any collected input
          statistics or adaptation state before starting the RECOGNIZE
          request. Note that if there are multiple resources that are sharing
          a media stream and are collecting or using this data, and the client
          issues this header field to one of the resources, the reset
          operation applies to all resources that use the shared media stream.
          This helps in a number of use cases, including where the client
          wishes to reuse an open recognition session with an existing media
          session for multiple telephone calls.</p>
<div id="section-9.4.23-2" class="artwork art-text" text-align="left"><pre>
new-audio-channel        =  "New-Audio-Channel" ":" BOOLEAN 
                            CRLF
            </pre></div>
</div></section><section id="section-9.4.24"><h4 id="name-speech-language-2">
<a href="#section-9.4.24" class="section-number selfRef">9.4.24.Â </a><a href="#name-speech-language-2" class="section-name selfRef">Speech-Language</a>
</h4>
<p id="section-9.4.24-1">This header field specifies the language of recognition grammar
          data within a session or request, if it is not specified within the
          data. The value of this header field MUST follow <span>[<a href="#RFC5646" class="xref">RFC 5646</a>] for its values. This MAY occur in
          DEFINE-GRAMMAR, RECOGNIZE, SET-PARAMS, or GET-PARAMS requests.</span></p>
<div id="section-9.4.24-2" class="artwork art-text" text-align="left"><pre>
speech-language          =  "Speech-Language" ":" 1*VCHAR CRLF
            </pre></div></section><section id="section-9.4.25"><h4 id="name-ver-buffer-utterance">
<a href="#section-9.4.25" class="section-number selfRef">9.4.25.Â </a><a href="#name-ver-buffer-utterance" class="section-name selfRef">Ver-Buffer-Utterance</a>
</h4>
<p id="section-9.4.25-1">This header field lets the client request the server to buffer
          the utterance associated with this recognition request into a buffer
          available to a co-resident verifier resource. The buffer is shared
          across resources within a session and is allocated when a verifier
          resource is added to this session. The client MUST NOT send this
          header field unless a verifier resource is instantiated for the
          session. The buffer is released when the verifier resource is
          released from the session.</p></section><section id="section-9.4.26"><h4 id="name-recognition-mode">
<a href="#section-9.4.26" class="section-number selfRef">9.4.26.Â </a><a href="#name-recognition-mode" class="section-name selfRef">Recognition-Mode</a>
</h4>
<p id="section-9.4.26-1">This header field specifies what mode the RECOGNIZE method will
          operate in. The value choices are "normal" or "hotword". If the
          value is "normal", the RECOGNIZE starts matching speech and DTMF to
          the grammars specified in the RECOGNIZE request. If any portion of
          the speech does not match the grammar, the RECOGNIZE command
          completes with a no-match status. Timers may be active to detect
          speech in the audio (see <a href="#sec.startInputTimers" class="xref">Section 9.4.14</a>), so the RECOGNIZE method may
          complete because of a timeout waiting for speech. If the value of
          this header field is "hotword", the RECOGNIZE method operates in
          hotword mode, where it only looks for the particular keywords or
          DTMF sequences specified in the grammar and ignores silence or other
          speech in the audio stream. The default value for this header field
          is "normal". This header field MAY occur on the RECOGNIZE
          method.</p>
<div id="section-9.4.26-2" class="artwork art-text" text-align="left"><pre>
recognition-mode         =  "Recognition-Mode" ":"
                            "normal" / "hotword" CRLF

</pre></div></section><section id="section-9.4.27"><h4 id="name-cancel-if-queue">
<a href="#section-9.4.27" class="section-number selfRef">9.4.27.Â </a><a href="#name-cancel-if-queue" class="section-name selfRef">Cancel-If-Queue</a>
</h4>
<p id="section-9.4.27-1">This header field specifies what will happen if the client
          attempts to invoke another RECOGNIZE method when this RECOGNIZE
          request is already in progress for the resource. The value for this
          header field is a Boolean. A value of "true" means the server MUST
          terminate this RECOGNIZE request, with a Completion-Cause of
          "cancelled", if the client issues another RECOGNIZE request for the
          same resource. A value of "false" for this header field indicates to
          the server that this RECOGNIZE request will continue to completion,
          and if the client issues more RECOGNIZE requests to the same
          resource, they are queued. When the currently active RECOGNIZE
          request is stopped or completes with a successful match, the first
          RECOGNIZE method in the queue becomes active. If the current
          RECOGNIZE fails, all RECOGNIZE methods in the pending queue are
          cancelled, and each generates a RECOGNITION-COMPLETE event with a
          Completion-Cause of "cancelled". This header field MUST be present
          in every RECOGNIZE request. There is no default value.</p>
<div id="section-9.4.27-2" class="artwork art-text" text-align="left"><pre>
cancel-if-queue          =  "Cancel-If-Queue" ":" BOOLEAN CRLF
</pre></div></section><section id="section-9.4.28"><h4 id="name-hotword-max-duration">
<a href="#section-9.4.28" class="section-number selfRef">9.4.28.Â </a><a href="#name-hotword-max-duration" class="section-name selfRef">Hotword-Max-Duration</a>
</h4>
<p id="section-9.4.28-1">This header field MAY be sent in a hotword mode RECOGNIZE
          request. It specifies the maximum length of an utterance (in
          seconds) that will be considered for hotword recognition. This
          header field, along with Hotword-Min-Duration, can be used to tune
          performance by preventing the recognizer from evaluating utterances
          that are too short or too long to be one of the hotwords in the
          grammar(s). The value is in milliseconds. The default is
          implementation dependent. If present in a RECOGNIZE request
          specifying a mode other than "hotword", the header field is
          ignored.</p>
<div id="section-9.4.28-2" class="artwork art-text" text-align="left"><pre>
hotword-max-duration     =  "Hotword-Max-Duration" ":" 1*19DIGIT
                            CRLF
            </pre></div></section><section id="section-9.4.29"><h4 id="name-hotword-min-duration">
<a href="#section-9.4.29" class="section-number selfRef">9.4.29.Â </a><a href="#name-hotword-min-duration" class="section-name selfRef">Hotword-Min-Duration</a>
</h4>
<p id="section-9.4.29-1">This header field MAY be sent in a hotword mode RECOGNIZE
          request. It specifies the minimum length of an utterance (in
          seconds) that will be considered for hotword recognition. This
          header field, along with Hotword-Max-Duration, can be used to tune
          performance by preventing the recognizer from evaluating utterances
          that are too short or too long to be one of the hotwords in the
          grammar(s). The value is in milliseconds. The default value is
          implementation dependent. If present in a RECOGNIZE request
          specifying a mode other than "hotword", the header field is
          ignored.</p>
<div id="section-9.4.29-2" class="artwork art-text" text-align="left"><pre>
hotword-min-duration     =  "Hotword-Min-Duration" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-9.4.30"><div id="sec.interpretText">
<h4 id="name-interpret-text">
<a href="#section-9.4.30" class="section-number selfRef">9.4.30.Â </a><a href="#name-interpret-text" class="section-name selfRef">Interpret-Text</a>
</h4>
<p id="section-9.4.30-1">The value of this header field is used to provide a pointer to
          the text for which a natural language interpretation is desired. The
          value is either a URI or text. If the value is a URI, it MUST be a
          Content-ID that refers to an entity of type 'text/plain' in the body
          of the message. Otherwise, the server MUST treat the value as the
          text to be interpreted. This header field MUST be used when invoking
          the INTERPRET method.</p>
<div id="section-9.4.30-2" class="artwork art-text" text-align="left"><pre>
interpret-text           =  "Interpret-Text" ":" 1*VCHAR CRLF          
            </pre></div>
</div></section><section id="section-9.4.31"><h4 id="name-dtmf-buffer-time">
<a href="#section-9.4.31" class="section-number selfRef">9.4.31.Â </a><a href="#name-dtmf-buffer-time" class="section-name selfRef">DTMF-Buffer-Time</a>
</h4>
<p id="section-9.4.31-1">This header field MAY be specified in a GET-PARAMS or SET-PARAMS
          method and is used to specify the amount of time, in milliseconds,
          of the type-ahead buffer for the recognizer. This is the buffer that
          collects DTMF digits as they are pressed even when there is no
          RECOGNIZE command active. When a subsequent RECOGNIZE method is
          received, it MUST look to this buffer to match the RECOGNIZE request.
          If the digits in the buffer are not sufficient, then it can continue
          to listen to more digits to match the grammar. The default size of
          this DTMF buffer is platform specific.</p>
<div id="section-9.4.31-2" class="artwork art-text" text-align="left"><pre>
dtmf-buffer-time  =  "DTMF-Buffer-Time" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-9.4.32"><h4 id="name-clear-dtmf-buffer">
<a href="#section-9.4.32" class="section-number selfRef">9.4.32.Â </a><a href="#name-clear-dtmf-buffer" class="section-name selfRef">Clear-DTMF-Buffer</a>
</h4>
<p id="section-9.4.32-1">This header field MAY be specified in a RECOGNIZE method and is
          used to tell the recognizer to clear the DTMF type-ahead buffer
          before starting the RECOGNIZE. The default value of this header
          field is "false", which does not clear the type-ahead buffer before
          starting the RECOGNIZE method. If this header field is specified to
          be "true", then the RECOGNIZE will clear the DTMF buffer before
          starting recognition. This means digits pressed by the caller before
          the RECOGNIZE command was issued are discarded.</p>
<div id="section-9.4.32-2" class="artwork art-text" text-align="left"><pre>
clear-dtmf-buffer  = "Clear-DTMF-Buffer" ":" BOOLEAN CRLF
            </pre></div></section><section id="section-9.4.33"><h4 id="name-early-no-match">
<a href="#section-9.4.33" class="section-number selfRef">9.4.33.Â </a><a href="#name-early-no-match" class="section-name selfRef">Early-No-Match</a>
</h4>
<p id="section-9.4.33-1">This header field MAY be specified in a RECOGNIZE method and is
          used to tell the recognizer that it MUST NOT wait for the end of
          speech before processing the collected speech to match active
          grammars. A value of "true" indicates the recognizer MUST do early
          matching. The default value for this header field if not specified
          is "false". If the recognizer does not support the processing of the
          collected audio before the end of speech, this header field can be
          safely ignored.</p>
<div id="section-9.4.33-2" class="artwork art-text" text-align="left"><pre>
early-no-match  = "Early-No-Match" ":" BOOLEAN CRLF
            </pre></div></section><section id="section-9.4.34"><h4 id="name-num-min-consistent-pronunci">
<a href="#section-9.4.34" class="section-number selfRef">9.4.34.Â </a><a href="#name-num-min-consistent-pronunci" class="section-name selfRef">Num-Min-Consistent-Pronunciations</a>
</h4>
<p id="section-9.4.34-1">This header field MAY be specified in a START-PHRASE-ENROLLMENT,
          SETâ€‘PARAMS, or GET-PARAMS method and is used to specify the minimum
          number of consistent pronunciations that must be obtained to voice
          enroll a new phrase. The minimum value is 1. The default value is
          implementation specific and MAY be greater than 1.</p>
<div id="section-9.4.34-2" class="artwork art-text" text-align="left"><pre>
num-min-consistent-pronunciations  = 
              "Num-Min-Consistent-Pronunciations" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-9.4.35"><h4 id="name-consistency-threshold">
<a href="#section-9.4.35" class="section-number selfRef">9.4.35.Â </a><a href="#name-consistency-threshold" class="section-name selfRef">Consistency-Threshold</a>
</h4>
<p id="section-9.4.35-1">This header field MAY be sent as part of the
          START-PHRASE-ENROLLMENT, SET-PARAMS, or GET-PARAMS method. Used
          during voice enrollment, this header field specifies how similar to
          a previously enrolled pronunciation of the same phrase an utterance
          needs to be in order to be considered "consistent". The higher the
          threshold, the closer the match between an utterance and previous
          pronunciations must be for the pronunciation to be considered
          consistent. The range for this threshold is a float value between
          0.0 and 1.0. The default value for this header field is
          implementation specific.</p>
<div id="section-9.4.35-2" class="artwork art-text" text-align="left"><pre>
consistency-threshold    =  "Consistency-Threshold" ":" FLOAT CRLF
            </pre></div></section><section id="section-9.4.36"><h4 id="name-clash-threshold">
<a href="#section-9.4.36" class="section-number selfRef">9.4.36.Â </a><a href="#name-clash-threshold" class="section-name selfRef">Clash-Threshold</a>
</h4>
<p id="section-9.4.36-1">This header field MAY be sent as part of the
          START-PHRASE-ENROLLMENT, SET-PARAMS, or GET-PARAMS method. Used
          during voice enrollment, this header field specifies how similar the
          pronunciations of two different phrases can be before they are
          considered to be clashing. For example, pronunciations of phrases
          such as "John Smith" and "Jon Smits" may be so similar that they are
          difficult to distinguish correctly. A smaller threshold reduces the
          number of clashes detected. The range for this threshold is
          a float
          value between 0.0 and 1.0. The default value for this header field
          is implementation specific. Clash testing can be turned off
          completely by setting the Clash-Threshold header field value to
          0.</p>
<div id="section-9.4.36-2" class="artwork art-text" text-align="left"><pre>
clash-threshold          =  "Clash-Threshold" ":" FLOAT CRLF
            </pre></div></section><section id="section-9.4.37"><h4 id="name-personal-grammar-uri">
<a href="#section-9.4.37" class="section-number selfRef">9.4.37.Â </a><a href="#name-personal-grammar-uri" class="section-name selfRef">Personal-Grammar-URI</a>
</h4>
<p id="section-9.4.37-1">This header field specifies the speaker-trained grammar to be
          used or referenced during enrollment operations. Phrases are added
          to this grammar during enrollment. For example, a contact list for
          user "Jeff" could be stored at the Personal-Grammar-URI
          "http://myserver.example.com/myenrollmentdb/jeff-list". The
          generated grammar syntax MAY be implementation specific. There is no
          default value for this header field. This header field MAY be sent
          as part of the START-PHRASE-ENROLLMENT, SET-PARAMS, or GET-PARAMS
          method.</p>
<div id="section-9.4.37-2" class="artwork art-text" text-align="left"><pre>
personal-grammar-uri     =  "Personal-Grammar-URI" ":" uri CRLF
            </pre></div></section><section id="section-9.4.38"><h4 id="name-enroll-utterance">
<a href="#section-9.4.38" class="section-number selfRef">9.4.38.Â </a><a href="#name-enroll-utterance" class="section-name selfRef">Enroll-Utterance</a>
</h4>
<p id="section-9.4.38-1">This header field MAY be specified in the RECOGNIZE method. If
          this header field is set to "true" and an Enrollment is active, the
          RECOGNIZE command MUST add the collected utterance to the personal
          grammar that is being enrolled. The way in which this occurs is
          engine specific and may be an area of future standardization. The
          default value for this header field is "false".</p>
<div id="section-9.4.38-2" class="artwork art-text" text-align="left"><pre>
enroll-utterance     =  "Enroll-Utterance" ":" BOOLEAN CRLF
            </pre></div></section><section id="section-9.4.39"><div id="sec.phraseID">
<h4 id="name-phrase-id">
<a href="#section-9.4.39" class="section-number selfRef">9.4.39.Â </a><a href="#name-phrase-id" class="section-name selfRef">Phrase-Id</a>
</h4>
<p id="section-9.4.39-1">This header field in a request identifies a phrase in an existing
          personal grammar for which enrollment is desired. It is also
          returned to the client in the RECOGNIZE complete event. This header
          field MAY occur in START-PHRASE-ENROLLMENT, MODIFY-PHRASE, or
          DELETE-PHRASE requests. There is no default value for this header
          field.</p>
<div id="section-9.4.39-2" class="artwork art-text" text-align="left"><pre>
phrase-id                =  "Phrase-ID" ":" 1*VCHAR CRLF
            </pre></div>
</div></section><section id="section-9.4.40"><h4 id="name-phrase-nl">
<a href="#section-9.4.40" class="section-number selfRef">9.4.40.Â </a><a href="#name-phrase-nl" class="section-name selfRef">Phrase-NL</a>
</h4>
<p id="section-9.4.40-1">This string specifies the interpreted text to be returned when
          the phrase is recognized. This header field MAY occur in
          START-PHRASE-ENROLLMENT and MODIFY-PHRASE requests. There is no
          default value for this header field.</p>
<div id="section-9.4.40-2" class="artwork art-text" text-align="left"><pre>
phrase-nl                =  "Phrase-NL" ":" 1*UTFCHAR CRLF
            </pre></div></section><section id="section-9.4.41"><h4 id="name-weight">
<a href="#section-9.4.41" class="section-number selfRef">9.4.41.Â </a><a href="#name-weight" class="section-name selfRef">Weight</a>
</h4>
<p id="section-9.4.41-1">The value of this header field represents the occurrence
          likelihood of a phrase in an enrolled grammar. When using grammar
          enrollment, the system is essentially constructing a grammar segment
          consisting of a list of possible match phrases. This can be thought
          of to be similar to the dynamic construction of a &lt;one-of&gt; tag
          in the W3C grammar specification. Each enrolled-phrase becomes an
          item in the list that can be matched against spoken input similar to
          the &lt;item&gt; within a &lt;one-of&gt; list. This header field
          allows you to assign a weight to the phrase (i.e., &lt;item&gt;
          entry) in the &lt;one-of&gt; list that is enrolled. Grammar weights
          are normalized to a sum of one at grammar compilation time, so a
          weight value of 1 for each phrase in an enrolled grammar list
          indicates all items in that list have the same weight. This header
          field MAY occur in START-PHRASE-ENROLLMENT and MODIFY-PHRASE
          requests. The default value for this header field is implementation
          specific.</p>
<div id="section-9.4.41-2" class="artwork art-text" text-align="left"><pre>
weight                   =  "Weight" ":" FLOAT CRLF
            </pre></div></section><section id="section-9.4.42"><h4 id="name-save-best-waveform">
<a href="#section-9.4.42" class="section-number selfRef">9.4.42.Â </a><a href="#name-save-best-waveform" class="section-name selfRef">Save-Best-Waveform</a>
</h4>
<p id="section-9.4.42-1">This header field allows the client to request the recognizer
          resource to save the audio stream for the best repetition of the
          phrase that was used during the enrollment session. The recognizer
          MUST attempt to record the recognized audio and make it available to
          the client in the form of a URI returned in the Waveform-URI header
          field in the response to the END-PHRASE-ENROLLMENT method. If there
          was an error in recording the stream or the audio data is otherwise
          not available, the recognizer MUST return an empty Waveform-URI
          header field. This header field MAY occur in the
          START-PHRASE-ENROLLMENT, SET-PARAMS, and GET-PARAMS methods.</p>
<div id="section-9.4.42-2" class="artwork art-text" text-align="left"><pre>
save-best-waveform  =  "Save-Best-Waveform" ":" BOOLEAN CRLF
            </pre></div></section><section id="section-9.4.43"><h4 id="name-new-phrase-id">
<a href="#section-9.4.43" class="section-number selfRef">9.4.43.Â </a><a href="#name-new-phrase-id" class="section-name selfRef">New-Phrase-Id</a>
</h4>
<p id="section-9.4.43-1">This header field replaces the ID used to identify the phrase in
          a personal grammar. The recognizer returns the new ID when using an
          enrollment grammar. This header field MAY occur in MODIFY-PHRASE
          requests.</p>
<div id="section-9.4.43-2" class="artwork art-text" text-align="left"><pre>
new-phrase-id            =  "New-Phrase-ID" ":" 1*VCHAR CRLF
            </pre></div></section><section id="section-9.4.44"><h4 id="name-confusable-phrases-uri">
<a href="#section-9.4.44" class="section-number selfRef">9.4.44.Â </a><a href="#name-confusable-phrases-uri" class="section-name selfRef">Confusable-Phrases-URI</a>
</h4>
<p id="section-9.4.44-1">This header field specifies a grammar that defines invalid
          phrases for enrollment. For example, typical applications do not
          allow an enrolled phrase that is also a command word. This header
          field MAY occur in RECOGNIZE requests that are part of an enrollment
          session.</p>
<div id="section-9.4.44-2" class="artwork art-text" text-align="left"><pre>
confusable-phrases-uri   =  "Confusable-Phrases-URI" ":" uri CRLF
            </pre></div></section><section id="section-9.4.45"><h4 id="name-abort-phrase-enrollment">
<a href="#section-9.4.45" class="section-number selfRef">9.4.45.Â </a><a href="#name-abort-phrase-enrollment" class="section-name selfRef">Abort-Phrase-Enrollment</a>
</h4>
<p id="section-9.4.45-1">This header field MAY be specified in the END-PHRASE-ENROLLMENT
          method to abort the phrase enrollment, rather than committing the
          phrase to the personal grammar.</p>
<div id="section-9.4.45-2" class="artwork art-text" text-align="left"><pre>
abort-phrase-enrollment  =  "Abort-Phrase-Enrollment" ":" 
                            BOOLEAN CRLF
            </pre></div></section>
</div></section><section id="section-9.5"><div id="sec.recMessageBody">
<h3 id="name-recognizer-message-body">
<a href="#section-9.5" class="section-number selfRef">9.5.Â </a><a href="#name-recognizer-message-body" class="section-name selfRef">Recognizer Message Body</a>
</h3>
<p id="section-9.5-1">A recognizer message can carry additional data associated with the
        request, response, or event. The client MAY provide the grammar to be
        recognized in DEFINE-GRAMMAR or RECOGNIZE requests. When one or more
        grammars are specified using the DEFINE-GRAMMAR method, the server
        MUST attempt to fetch, compile, and optimize the grammar before
        returning a response to the DEFINE-GRAMMAR method. A RECOGNIZE request
        MUST completely specify the grammars to be active during the
        recognition operation, except when the RECOGNIZE method is being used
        to enroll a grammar. During grammar enrollment, such grammars are
        OPTIONAL. The server resource sends the recognition results in the
        RECOGNITION-COMPLETE event and the GET-RESULT response. Grammars and
        recognition results are carried in the message body of the
        corresponding MRCPv2 messages.</p>
<section id="section-9.5.1"><div id="sec.grammarData">
<h4 id="name-recognizer-grammar-data">
<a href="#section-9.5.1" class="section-number selfRef">9.5.1.Â </a><a href="#name-recognizer-grammar-data" class="section-name selfRef">Recognizer Grammar Data</a>
</h4>
<p id="section-9.5.1-1">Recognizer grammar data from the client to the server can be
          provided inline or by reference. Either way, grammar data is carried
          as typed media entities in the message body of the RECOGNIZE or
          DEFINE-GRAMMAR request. All MRCPv2 servers MUST accept grammars in
          the XML form (media type 'application/srgs+xml') of the W3C's
          XML-based <span>[<a href="#W3C.REC-speech-grammar-20040316" class="xref">Speech
          Grammar Markup Format (SRGS)</a>] and MAY accept grammars in other
          formats. Examples include but are not limited to:

        </span></p>
<ul>
<li id="section-9.5.1-3">the ABNF form (media type 'application/srgs') of SRGS</li>
<li id="section-9.5.1-4">Sun's <span>[<a href="#refs.javaSpeechGrammarFormat" class="xref">Java Speech
              Grammar Format (JSGF)</a>]</span>
</li>
</ul>
<p id="section-9.5.1-5">

          Additionally, MRCPv2 servers MAY support the <span>[<a href="#W3C.REC-semantic-interpretation-20070405" class="xref">Semantic
          Interpretation for Speech Recognition (SISR)</a>]
          specification.</span></p>
<p id="section-9.5.1-6">When a grammar is specified inline in the request, the client
          MUST provide a Content-ID for that grammar as part of the content
          header fields. If there is no space on the server to store the
          inline grammar, the request MUST return with a Completion-Cause code
          of 016 "grammar-definition-failure". Otherwise, the server MUST
          associate the inline grammar block with that Content-ID and MUST
          store it on the server for the duration of the session. However, if
          the Content-ID is redefined later in the session through a
          subsequent DEFINE-GRAMMAR, the inline grammar previously associated
          with the Content-ID MUST be freed. If the Content-ID is redefined
          through a subsequent DEFINE-GRAMMAR with an empty message body (i.e.,
          no grammar definition), then in addition to freeing any grammar
          previously associated with the Content-ID, the server MUST clear all
          bindings and associations to the Content-ID. Unless and until
          subsequently redefined, this URI MUST be interpreted by the server
          as one that has never been set.</p>
<p id="section-9.5.1-7">Grammars that have been associated with a Content-ID can be
          referenced through the 'session' URI scheme (see <a href="#sec.sessionURIScheme" class="xref">Section 13.6</a>). For example:</p>
<div id="section-9.5.1-8" class="artwork art-text" text-align="left"><pre>session:help@root-level.store
</pre></div>
<p id="section-9.5.1-9">Grammar data MAY be specified using external URI references. To
          do so, the client uses a body of media type 'text/uri-list' (see <span>[<a href="#RFC2483" class="xref">RFC 2483</a>] ) to list the one or more URIs that
          point to the grammar data. The client can use a body of media type
          'text/grammar-ref-list' (see </span><a href="#sec.grammar-ref-list" class="xref">Section 13.5.1</a>) if it wants to assign weights
          to the list of grammar URI. All MRCPv2 servers MUST support grammar
          access using the 'http' and 'https' URI schemes.</p>
<p id="section-9.5.1-10">If the grammar data the client wishes to be used on a request
          consists of a mix of URI and inline grammar data, the client uses the
          'multipart/mixed' media type to enclose the 'text/uri-list',
          'application/srgs', or 'application/srgs+xml' content entities. The
          character set and encoding used in the grammar data are specified
          using to standard media type definitions.</p>
<p id="section-9.5.1-11">When more than one grammar URI or inline grammar block is
          specified in a message body of the RECOGNIZE request, the server
          interprets this as a list of grammar alternatives to match
          against.</p>
<figure id="figure-20"><div><div id="section-9.5.1-12" class="artwork art-text" text-align="left"><pre>
Content-Type:application/srgs+xml
Content-ID:&lt;request1@form-level.store&gt;
Content-Length:...

&lt;?xml version="1.0"?&gt;

&lt;!-- the default grammar language is US English --&gt;
&lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
         xml:lang="en-US" version="1.0" root="request"&gt;

&lt;!-- single language attachment to tokens --&gt;
      &lt;rule id="yes"&gt;
            &lt;one-of&gt;
                  &lt;item xml:lang="fr-CA"&gt;oui&lt;/item&gt;
                  &lt;item xml:lang="en-US"&gt;yes&lt;/item&gt;
            &lt;/one-of&gt; 
      &lt;/rule&gt; 

&lt;!-- single language attachment to a rule expansion --&gt;
      &lt;rule id="request"&gt;
            may I speak to
            &lt;one-of xml:lang="fr-CA"&gt;
                  &lt;item&gt;Michel Tremblay&lt;/item&gt;
                  &lt;item&gt;Andre Roy&lt;/item&gt;
            &lt;/one-of&gt;
      &lt;/rule&gt;

      &lt;!-- multiple language attachment to a token --&gt;
      &lt;rule id="people1"&gt;
            &lt;token lexicon="en-US,fr-CA"&gt; Robert &lt;/token&gt;
      &lt;/rule&gt;

      &lt;!-- the equivalent single-language attachment expansion --&gt;
      &lt;rule id="people2"&gt;
            &lt;one-of&gt;
                  &lt;item xml:lang="en-US"&gt;Robert&lt;/item&gt;
                  &lt;item xml:lang="fr-CA"&gt;Robert&lt;/item&gt;
            &lt;/one-of&gt;
      &lt;/rule&gt;

      &lt;/grammar&gt;
</pre></div></div>
<figcaption><a href="#figure-20">Figure 20</a><a href="#name-srgs-grammar-example" id="name-srgs-grammar-example" class="selfRef">SRGS Grammar Example</a></figcaption></figure><figure id="figure-21"><div><div id="section-9.5.1-13" class="artwork art-text" text-align="left"><pre>
Content-Type:text/uri-list
Content-Length:...

session:help@root-level.store
http://www.example.com/Directory-Name-List.grxml
http://www.example.com/Department-List.grxml
http://www.example.com/TAC-Contact-List.grxml
session:menu1@menu-level.store
</pre></div></div>
<figcaption><a href="#figure-21">Figure 21</a><a href="#name-grammar-reference-example" id="name-grammar-reference-example" class="selfRef">Grammar Reference Example</a></figcaption></figure><figure id="figure-22"><div><div id="section-9.5.1-14" class="artwork art-text" text-align="left"><pre>
Content-Type:multipart/mixed; boundary="break"

--break
Content-Type:text/uri-list
Content-Length:...

http://www.example.com/Directory-Name-List.grxml
http://www.example.com/Department-List.grxml
http://www.example.com/TAC-Contact-List.grxml

--break
Content-Type:application/srgs+xml
Content-ID:&lt;request1@form-level.store&gt;
Content-Length:...

&lt;?xml version="1.0"?&gt;

&lt;!-- the default grammar language is US English --&gt;
&lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
         xml:lang="en-US" version="1.0"&gt;

&lt;!-- single language attachment to tokens --&gt;
      &lt;rule id="yes"&gt;
            &lt;one-of&gt;
                  &lt;item xml:lang="fr-CA"&gt;oui&lt;/item&gt;
                  &lt;item xml:lang="en-US"&gt;yes&lt;/item&gt;
            &lt;/one-of&gt; 
      &lt;/rule&gt; 

&lt;!-- single language attachment to a rule expansion --&gt;
      &lt;rule id="request"&gt;
            may I speak to
            &lt;one-of xml:lang="fr-CA"&gt;
                  &lt;item&gt;Michel Tremblay&lt;/item&gt;
                  &lt;item&gt;Andre Roy&lt;/item&gt;
            &lt;/one-of&gt;
      &lt;/rule&gt;

      &lt;!-- multiple language attachment to a token --&gt;
      &lt;rule id="people1"&gt;
            &lt;token lexicon="en-US,fr-CA"&gt; Robert &lt;/token&gt;
      &lt;/rule&gt;

      &lt;!-- the equivalent single-language attachment expansion --&gt;
      &lt;rule id="people2"&gt;
            &lt;one-of&gt;
                  &lt;item xml:lang="en-US"&gt;Robert&lt;/item&gt;
                  &lt;item xml:lang="fr-CA"&gt;Robert&lt;/item&gt;
            &lt;/one-of&gt;
      &lt;/rule&gt;

      &lt;/grammar&gt;
--break--
</pre></div></div>
<figcaption><a href="#figure-22">Figure 22</a><a href="#name-mixed-grammar-reference-exa" id="name-mixed-grammar-reference-exa" class="selfRef">Mixed Grammar Reference Example</a></figcaption></figure>
</div></section><section id="section-9.5.2"><h4 id="name-recognizer-result-data">
<a href="#section-9.5.2" class="section-number selfRef">9.5.2.Â </a><a href="#name-recognizer-result-data" class="section-name selfRef">Recognizer Result Data</a>
</h4>
<p id="section-9.5.2-1">Recognition results are returned to the client in the message
          body of the RECOGNITION-COMPLETE event or the GET-RESULT response
          message as described in <a href="#sec.result" class="xref">Section 6.3</a>. Element
          and attribute descriptions for the recognition portion of the NLSML
          format are provided in <a href="#sec.recognizerResults" class="xref">Section 9.6</a>
          with a normative definition of the schema in <a href="#sec.schema.NLSML" class="xref">Section 16.1</a>.</p>
<figure id="figure-23"><div><div id="section-9.5.2-2" class="artwork art-text" text-align="left"><pre>
Content-Type:application/nlsml+xml
Content-Length:...

&lt;?xml version="1.0"?&gt;
&lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
        xmlns:ex="http://www.example.com/example"
        grammar="http://www.example.com/theYesNoGrammar"&gt;
    &lt;interpretation&gt;
        &lt;instance&gt;
                &lt;ex:response&gt;yes&lt;/ex:response&gt;
        &lt;/instance&gt;
        &lt;input&gt;OK&lt;/input&gt;
    &lt;/interpretation&gt;
&lt;/result&gt;
</pre></div></div>
<figcaption><a href="#figure-23">Figure 23</a><a href="#name-result-example-2" id="name-result-example-2" class="selfRef">Result Example</a></figcaption></figure></section><section id="section-9.5.3"><h4 id="name-enrollment-result-data">
<a href="#section-9.5.3" class="section-number selfRef">9.5.3.Â </a><a href="#name-enrollment-result-data" class="section-name selfRef">Enrollment Result Data</a>
</h4>
<p id="section-9.5.3-1">Enrollment results are returned to the client in the message body
          of the RECOGNITION-COMPLETE event as described in <a href="#sec.result" class="xref">Section 6.3</a>. Element and attribute descriptions for
          the enrollment portion of the NLSML format are provided in <a href="#sec.enrollmentResults" class="xref">Section 9.7</a> with a normative definition
          of the schema in <a href="#sec.enrollmentResultsSchema" class="xref">Section 16.2</a>.</p></section><section id="section-9.5.4"><h4 id="name-recognizer-context-block-2">
<a href="#section-9.5.4" class="section-number selfRef">9.5.4.Â </a><a href="#name-recognizer-context-block-2" class="section-name selfRef">Recognizer Context Block</a>
</h4>
<p id="section-9.5.4-1">When a client changes servers while operating on the behalf of
          the same incoming communication session, this header field allows
          the client to collect a block of opaque data from one server and
          provide it to another server. This capability is desirable if the
          client needs different language support or because the server issued
          a redirect. Here, the first recognizer resource may have collected
          acoustic and other data during its execution of recognition methods.
          After a server switch, communicating this data may allow the
          recognizer resource on the new server to provide better
          recognition. This block of data is implementation specific and MUST
          be carried as media type 'application/octets' in the body of the
          message.</p>
<p id="section-9.5.4-2">This block of data is communicated in the SET-PARAMS and
          GET-PARAMS method/response messages. In the GET-PARAMS method, if an
          empty Recognizer-Context-Block header field is present, then the
          recognizer SHOULD return its vendor-specific context block, if any,
          in the message body as an entity of media type 'application/octets'
          with a specific Content-ID. The Content-ID value MUST also be
          specified in the Recognizer-Context-Block header field in the
          GET-PARAMS response. The SET-PARAMS request wishing to provide this
          vendor-specific data MUST send it in the message body as a typed
          entity with the same Content-ID that it received from the
          GET-PARAMS. The Content-ID MUST also be sent in the
          Recognizer-Context-Block header field of the SETâ€‘PARAMS message.</p>
<p id="section-9.5.4-3">Each speech recognition implementation choosing to use this
          mechanism to hand off recognizer context data among servers MUST
          distinguish its implementation-specific block of data from other
          implementations by choosing a Content-ID that is recognizable among
          the participating servers and unlikely to collide with values chosen
          by another implementation.</p></section>
</div></section><section id="section-9.6"><div id="sec.recognizerResults">
<h3 id="name-recognizer-results">
<a href="#section-9.6" class="section-number selfRef">9.6.Â </a><a href="#name-recognizer-results" class="section-name selfRef">Recognizer Results</a>
</h3>
<p id="section-9.6-1">The recognizer portion of NLSML (see <a href="#sec.NLSML" class="xref">Section 6.3.1</a>) represents information automatically
        extracted from a user's utterances by a semantic interpretation
        component, where "utterance" is to be taken in the general sense of a
        meaningful user input in any modality supported by the MRCPv2
        implementation.</p>
<section id="section-9.6.1"><h4 id="name-markup-functions">
<a href="#section-9.6.1" class="section-number selfRef">9.6.1.Â </a><a href="#name-markup-functions" class="section-name selfRef">Markup Functions</a>
</h4>
<p id="section-9.6.1-1">MRCPv2 recognizer resources employ the Natural Language
          Semantics Markup Language (NLSML) to interpret natural language
          speech input and to format the interpretation for consumption by an
          MRCPv2 client.</p>
<p id="section-9.6.1-2">The elements of the markup fall into the following general
          functional categories: interpretation, side information, and
          multi-modal integration.</p>
<section id="section-9.6.1.1"><h5 id="name-interpretation">
<a href="#section-9.6.1.1" class="section-number selfRef">9.6.1.1.Â </a><a href="#name-interpretation" class="section-name selfRef">Interpretation</a>
</h5>
<p id="section-9.6.1.1-1">Elements and attributes represent the semantics of a user's
            utterance, including the &lt;result&gt;, &lt;interpretation&gt;,
            and &lt;instance&gt; elements. The &lt;result&gt; element contains
            the full result of processing one utterance. It MAY contain
            multiple &lt;interpretation&gt; elements if the interpretation of
            the utterance results in multiple alternative meanings due to
            uncertainty in speech recognition or natural language
            understanding. There are at least two reasons for providing
            multiple interpretations: 

    </p>
<ol id="section-9.6.1.1-2">
<li id="section-9.6.1.1-3">The client application might have additional information,
                for example, information from a database, that would allow it
                to select a preferred interpretation from among the possible
                interpretations returned from the semantic interpreter.</li>
<li id="section-9.6.1.1-4">A client-based dialog manager (e.g., <span>[<a href="#W3C.REC-voicexml20-20040316" class="xref">VoiceXML</a>]) that was
                unable to select between several competing interpretations
                could use this information to go back to the user and find out
                what was intended. For example, it could issue a SPEAK request
                to a synthesizer resource to emit "Did you say 'Boston' or
                'Austin'?"</span>
</li>
</ol></section><section id="section-9.6.1.2"><h5 id="name-side-information">
<a href="#section-9.6.1.2" class="section-number selfRef">9.6.1.2.Â </a><a href="#name-side-information" class="section-name selfRef">Side Information</a>
</h5>
<p id="section-9.6.1.2-1">These are elements and attributes representing additional
            information about the interpretation, over and above the
            interpretation itself. Side information includes: </p>
<ol id="section-9.6.1.2-2">
<li id="section-9.6.1.2-3">Whether an interpretation was achieved (the &lt;nomatch&gt;
                element) and the system's confidence in an interpretation (the
                "confidence" attribute of &lt;interpretation&gt;).</li>
<li id="section-9.6.1.2-4">Alternative interpretations (&lt;interpretation&gt;)</li>
<li id="section-9.6.1.2-5">Input formats and Automatic Speech Recognition (ASR)
                information: the &lt;input&gt; element, representing the input
                to the semantic interpreter.</li>
</ol></section><section id="section-9.6.1.3"><h5 id="name-multi-modal-integration">
<a href="#section-9.6.1.3" class="section-number selfRef">9.6.1.3.Â </a><a href="#name-multi-modal-integration" class="section-name selfRef">Multi-Modal Integration</a>
</h5>
<p id="section-9.6.1.3-1">When more than one modality is available for input, the
            interpretation of the inputs needs to be coordinated. The "mode"
            attribute of &lt;input&gt; supports this by indicating whether the
            utterance was input by speech, DTMF, pointing, etc. 

  The "timestamp-start" and "timestamp-end" attributes of &lt;input&gt;
   also provide for temporal coordination by indicating when inputs
   occurred.
</p></section></section><section id="section-9.6.2"><h4 id="name-overview-of-recognizer-resu">
<a href="#section-9.6.2" class="section-number selfRef">9.6.2.Â </a><a href="#name-overview-of-recognizer-resu" class="section-name selfRef">Overview of Recognizer Result Elements and Their Relationships</a>
</h4>
<p id="section-9.6.2-1">The recognizer elements in NLSML fall into two categories: </p>
<ol id="section-9.6.2-2">
<li id="section-9.6.2-3">description of the input that was processed, and</li>
<li id="section-9.6.2-4">description of the meaning which was extracted from the
              input.</li>
</ol>
<p id="section-9.6.2-5"> Next to each element are its attributes. In addition, some
          elements can contain multiple instances of other elements. For
          example, a &lt;result&gt; can contain multiple
          &lt;interpretation&gt; elements, each of which is taken to be an
          alternative. Similarly, &lt;input&gt; can contain multiple child
          &lt;input&gt; elements, which are taken to be cumulative. To
          illustrate the basic usage of these elements, as a simple example,
          consider the utterance "OK" (interpreted as "yes"). The example
          illustrates how that utterance and its interpretation would be
          represented in the NLSML markup.</p>
<div id="section-9.6.2-6" class="artwork art-text" text-align="left"><pre>
&lt;?xml version="1.0"?&gt;
&lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
        xmlns:ex="http://www.example.com/example"
        grammar="http://www.example.com/theYesNoGrammar"&gt;
  &lt;interpretation&gt;
     &lt;instance&gt;
        &lt;ex:response&gt;yes&lt;/ex:response&gt;
      &lt;/instance&gt;
    &lt;input&gt;OK&lt;/input&gt;
  &lt;/interpretation&gt;
&lt;/result&gt;
</pre></div>
<p id="section-9.6.2-7">This example includes only the minimum required information.
          There is an overall &lt;result&gt; element, which includes one
          interpretation and an input element. The interpretation contains the
          application-specific element "&lt;response&gt;", which is the
          semantically interpreted result.</p></section><section id="section-9.6.3"><h4 id="name-elements-and-attributes">
<a href="#section-9.6.3" class="section-number selfRef">9.6.3.Â </a><a href="#name-elements-and-attributes" class="section-name selfRef">Elements and Attributes</a>
</h4>
<section id="section-9.6.3.1"><h5 id="name-result-root-element">
<a href="#section-9.6.3.1" class="section-number selfRef">9.6.3.1.Â </a><a href="#name-result-root-element" class="section-name selfRef">&lt;result&gt; Root Element</a>
</h5>
<p id="section-9.6.3.1-1">The root element of the markup is &lt;result&gt;. The
            &lt;result&gt; element includes one or more &lt;interpretation&gt;
            elements. Multiple interpretations can result from ambiguities in
            the input or in the semantic interpretation. If the "grammar"
            attribute does not apply to all of the interpretations in the
            result, it can be overridden for individual interpretations at the
            &lt;interpretation&gt; level.</p>
<p id="section-9.6.3.1-2">Attributes: </p>
<ol id="section-9.6.3.1-3"><li id="section-9.6.3.1-4">grammar: The grammar or recognition rule matched by this
                result. The format of the grammar attribute will match the
                rule reference semantics defined in the grammar specification.
                Specifically, the rule reference is in the external XML form
                for grammar rule references. The markup interpreter needs to
                know the grammar rule that is matched by the utterance because
                multiple rules may be simultaneously active. The value is the
                grammar URI used by the markup interpreter to specify the
                grammar. The grammar can be overridden by a grammar attribute
                in the &lt;interpretation&gt; element if the input was
                ambiguous as to which grammar it matched. If all
                interpretation elements within the result element contain
                their own grammar attributes, the attribute can be
                dropped from the result element.</li></ol>
<div id="section-9.6.3.1-5" class="artwork art-text" text-align="left"><pre>
&lt;?xml version="1.0"?&gt;
&lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
        grammar="http://www.example.com/grammar"&gt; 
  &lt;interpretation&gt;
   ....
  &lt;/interpretation&gt;
&lt;/result&gt;
</pre></div></section><section id="section-9.6.3.2"><h5 id="name-interpretation-element">
<a href="#section-9.6.3.2" class="section-number selfRef">9.6.3.2.Â </a><a href="#name-interpretation-element" class="section-name selfRef">&lt;interpretation&gt; Element</a>
</h5>
<p id="section-9.6.3.2-1">An &lt;interpretation&gt; element contains a single semantic
            interpretation.</p>
<p id="section-9.6.3.2-2">Attributes: </p>
<ol id="section-9.6.3.2-3">
<li id="section-9.6.3.2-4">confidence: A float value from 0.0-1.0 indicating the
                semantic analyzer's confidence in this interpretation. A value
                of 1.0 indicates maximum confidence. The values are
                implementation dependent but are intended to align with the
                value interpretation for the confidence MRCPv2 header field
                defined in <a href="#sec.confidenceThreshold" class="xref">Section 9.4.1</a>.
                This attribute is OPTIONAL.</li>
<li id="section-9.6.3.2-5">grammar: The grammar or recognition rule matched by this
                interpretation (if needed to override the grammar
                specification at the &lt;interpretation&gt; level.) This
                attribute is only needed under &lt;interpretation&gt; if it is
                necessary to override a grammar that was defined at the
                &lt;result&gt; level. Note that the grammar attribute for the
                interpretation element is optional if and only if the grammar
                attribute is specified in the &lt;result&gt; element.</li>
</ol>
<p id="section-9.6.3.2-6">Interpretations MUST be sorted best-first by some measure of
            "goodness". The goodness measure is "confidence" if present;
            otherwise, it is some implementation-specific indication of
            quality.</p>
<p id="section-9.6.3.2-7">The grammar is expected to be specified most frequently at the
            &lt;result&gt; level. However, it can be overridden at the
            &lt;interpretation&gt; level because it is possible that different
            interpretations may match different grammar rules.</p>
<p id="section-9.6.3.2-8">The &lt;interpretation&gt; element includes an optional
            &lt;input&gt; element containing the input being analyzed, and
            at least one &lt;instance&gt; element containing the interpretation of the
            utterance.</p>
<div id="section-9.6.3.2-9" class="artwork art-text" text-align="left"><pre>
&lt;interpretation confidence="0.75"
                grammar="http://www.example.com/grammar"&gt;
    ...
&lt;/interpretation&gt;
</pre></div></section><section id="section-9.6.3.3"><h5 id="name-instance-element">
<a href="#section-9.6.3.3" class="section-number selfRef">9.6.3.3.Â </a><a href="#name-instance-element" class="section-name selfRef">&lt;instance&gt; Element</a>
</h5>
<p id="section-9.6.3.3-1">The &lt;instance&gt; element contains the interpretation of the
            utterance. When the Semantic Interpretation for Speech Recognition
            format is used, the &lt;instance&gt; element contains the XML
            serialization of the result using the approach defined in that
            specification. When there is semantic markup in the grammar that
            does not create semantic objects, but instead only does a semantic
            translation of a portion of the input, such as translating "coke"
            to "coca-cola", the instance contains the whole input but with the
            translation applied. The NLSML looks like the markup in <a href="#fig.nslmlExample2" class="xref">Figure 24</a> below. If there are no semantic
            objects created, nor any semantic translation, the instance value
            is the same as the input value.</p>
<p id="section-9.6.3.3-2">Attributes: </p>
<ol id="section-9.6.3.3-3"><li id="section-9.6.3.3-4">confidence: Each element of the instance MAY have a
                confidence attribute, defined in the NLSML namespace. The
                confidence attribute contains a float value in the range from
                0.0-1.0 reflecting the system's confidence in the analysis of
                that slot. A value of 1.0 indicates maximum confidence. The
                values are implementation dependent, but are intended to align
                with the value interpretation for the MRCPv2 header
                field Confidence-Threshold defined in <a href="#sec.confidenceThreshold" class="xref">Section 9.4.1</a>. This attribute is
                OPTIONAL.</li></ol>
<div id="section-9.6.3.3-5" class="artwork art-text" text-align="left"><pre>
&lt;instance&gt;
  &lt;nameAddress&gt;
      &lt;street confidence="0.75"&gt;123 Maple Street&lt;/street&gt;
      &lt;city&gt;Mill Valley&lt;/city&gt;
      &lt;state&gt;CA&lt;/state&gt;
      &lt;zip&gt;90952&lt;/zip&gt;
  &lt;/nameAddress&gt;
&lt;/instance&gt; 
&lt;input&gt;
  My address is 123 Maple Street,
  Mill Valley, California, 90952
&lt;/input&gt;
</pre></div>
<figure id="figure-24"><div id="fig.nslmlExample2"><div id="section-9.6.3.3-6" class="artwork art-text" text-align="left"><pre>
&lt;instance&gt;
    I would like to buy a coca-cola
&lt;/instance&gt; 
&lt;input&gt;
  I would like to buy a coke
&lt;/input&gt;
</pre></div></div>
<figcaption><a href="#figure-24">Figure 24</a><a href="#name-nslml-example" id="name-nslml-example" class="selfRef">NSLML Example</a></figcaption></figure></section><section id="section-9.6.3.4"><h5 id="name-input-element">
<a href="#section-9.6.3.4" class="section-number selfRef">9.6.3.4.Â </a><a href="#name-input-element" class="section-name selfRef">&lt;input&gt; Element</a>
</h5>
<p id="section-9.6.3.4-1">The &lt;input&gt; element is the text representation of a
            user's input. It includes an optional "confidence" attribute, which
            indicates the recognizer's confidence in the recognition result
            (as opposed to the confidence in the interpretation, which is
            indicated by the "confidence" attribute of
            &lt;interpretation&gt;). Optional "timestamp-start" and
            "timestamp-end" attributes indicate the start and end times of a
            spoken utterance, in <span>[<a href="#ISO.8601.1988" class="xref">ISO 8601
            format</a>].</span></p>
<p id="section-9.6.3.4-2">Attributes: 

              </p>
<ol id="section-9.6.3.4-3">
<li id="section-9.6.3.4-4">timestamp-start: The time at which the input began.
                (optional)</li>
<li id="section-9.6.3.4-5">timestamp-end: The time at which the input ended.
                (optional)</li>
<li id="section-9.6.3.4-6">mode: The modality of the input, for example, speech, DTMF,
                etc. (optional)</li>
<li id="section-9.6.3.4-7">confidence: The confidence of the recognizer in the
                correctness of the input in the range 0.0 to 1.0.
                (optional)</li>
</ol>
<p id="section-9.6.3.4-8">

            Note that it may not make sense for temporally
            overlapping inputs to have the same mode; however, this constraint
            is not expected to be enforced by implementations.</p>
<p id="section-9.6.3.4-9">When there is no time zone designator, ISO 8601 time
            representations default to local time.</p>
<p id="section-9.6.3.4-10">There are three possible formats for the &lt;input&gt; element.
            </p>
<ol id="section-9.6.3.4-11">
<li id="section-9.6.3.4-12">
<p id="section-9.6.3.4-13">The &lt;input&gt; element can contain simple text: </p>
<div id="section-9.6.3.4-14" class="artwork art-text" text-align="left"><pre>
    &lt;input&gt;onions&lt;/input&gt;
</pre></div>
<p id="section-9.6.3.4-15">A future possibility is for &lt;input&gt; to
                contain not only text but additional markup that represents
                prosodic information that was contained in the original
                utterance and extracted by the speech recognizer. This depends
                on the availability of ASRs that are capable of producing
                prosodic information. MRCPv2 clients MUST be prepared to
                receive such markup and MAY make use of it.</p>
</li>
<li id="section-9.6.3.4-16">
<p id="section-9.6.3.4-17">An &lt;input&gt; tag can also contain additional
                &lt;input&gt; tags. Having additional input elements allows
                the representation to support future multi-modal inputs as
                well as finer-grained speech information, such as timestamps
                for individual words and word-level confidences. </p>
<div id="section-9.6.3.4-18" class="artwork art-text" text-align="left"><pre>
    &lt;input&gt; 
         &lt;input mode="speech" confidence="0.5"
             timestamp-start="2000-04-03T0:00:00" 
             timestamp-end="2000-04-03T0:00:00.2"&gt;fried&lt;/input&gt;
         &lt;input mode="speech" confidence="1.0"
             timestamp-start="2000-04-03T0:00:00.25" 
             timestamp-end="2000-04-03T0:00:00.6"&gt;onions&lt;/input&gt;
    &lt;/input&gt;
</pre></div>
</li>
<li id="section-9.6.3.4-19">Finally, the &lt;input&gt; element can contain
                &lt;nomatch&gt; and &lt;noinput&gt; elements, which describe
                situations in which the speech recognizer received input that
                it was unable to process or did not receive any input at all,
                respectively.</li>
</ol></section><section id="section-9.6.3.5"><h5 id="name-nomatch-element">
<a href="#section-9.6.3.5" class="section-number selfRef">9.6.3.5.Â </a><a href="#name-nomatch-element" class="section-name selfRef">&lt;nomatch&gt; Element</a>
</h5>
<p id="section-9.6.3.5-1">The &lt;nomatch&gt; element under &lt;input&gt; is used to
            indicate that the semantic interpreter was unable to successfully
            match any input with confidence above the threshold. It can
            optionally contain the text of the best of the (rejected)
            matches.</p>
<div id="section-9.6.3.5-2" class="artwork art-text" text-align="left"><pre>
&lt;interpretation&gt;
   &lt;instance/&gt;
      &lt;input confidence="0.1"&gt; 
         &lt;nomatch/&gt;
      &lt;/input&gt;
&lt;/interpretation&gt;
&lt;interpretation&gt;  
   &lt;instance/&gt;       
   &lt;input mode="speech" confidence="0.1"&gt;           
     &lt;nomatch&gt;I want to go to New York&lt;/nomatch&gt;       
   &lt;/input&gt;
&lt;/interpretation&gt;
</pre></div></section><section id="section-9.6.3.6"><h5 id="name-noinput-element">
<a href="#section-9.6.3.6" class="section-number selfRef">9.6.3.6.Â </a><a href="#name-noinput-element" class="section-name selfRef">&lt;noinput&gt; Element</a>
</h5>
<p id="section-9.6.3.6-1">&lt;noinput&gt; indicates that there was no input -- a timeout
            occurred in the speech recognizer due to silence.</p>
<div id="section-9.6.3.6-2" class="artwork art-text" text-align="left"><pre>&lt;interpretation&gt;
   &lt;instance/&gt;
   &lt;input&gt;
      &lt;noinput/&gt;
   &lt;/input&gt;
&lt;/interpretation&gt;</pre></div>
<p id="section-9.6.3.6-3">If there are multiple levels of inputs, the most natural place
            for &lt;nomatch&gt; and &lt;noinput&gt; elements to appear is
            under the highest level of &lt;input&gt; for &lt;noinput&gt;, and
            under the appropriate level of &lt;interpretation&gt; for
            &lt;nomatch&gt;. So, &lt;noinput&gt; means "no input at all" and
            &lt;nomatch&gt; means "no match in speech modality" or "no match
            in DTMF modality". For example, to represent garbled speech
            combined with DTMF "1 2 3 4", the markup would be:</p>
<div id="section-9.6.3.6-4" class="artwork art-text" text-align="left"><pre>&lt;input&gt; 
   &lt;input mode="speech"&gt;&lt;nomatch/&gt;&lt;/input&gt;
   &lt;input mode="dtmf"&gt;1 2 3 4&lt;/input&gt;
&lt;/input&gt;</pre></div>
<p id="section-9.6.3.6-5">Note: while &lt;noinput&gt; could be represented as an
            attribute of input, &lt;nomatch&gt; cannot, since it could
            potentially include PCDATA content with the best match. For
            parallelism, &lt;noinput&gt; is also an element.</p></section></section>
</div></section><section id="section-9.7"><div id="sec.enrollmentResults">
<h3 id="name-enrollment-results">
<a href="#section-9.7" class="section-number selfRef">9.7.Â </a><a href="#name-enrollment-results" class="section-name selfRef">Enrollment Results</a>
</h3>
<p id="section-9.7-1">All enrollment elements are contained within a single
        &lt;enrollmentâ€‘result&gt; element under &lt;result&gt;. The elements
        are described below and have the schema defined in <a href="#sec.enrollmentResultsSchema" class="xref">Section 16.2</a>. The following elements
        are defined:</p>
<ol id="section-9.7-2">
<li id="section-9.7-3">num-clashes</li>
<li id="section-9.7-4">num-good-repetitions</li>
<li id="section-9.7-5">num-repetitions-still-needed</li>
<li id="section-9.7-6">consistency-status</li>
<li id="section-9.7-7">clash-phrase-ids</li>
<li id="section-9.7-8">transcriptions</li>
<li id="section-9.7-9">confusable-phrases</li>
</ol>
<section id="section-9.7.1"><h4 id="name-num-clashes-element">
<a href="#section-9.7.1" class="section-number selfRef">9.7.1.Â </a><a href="#name-num-clashes-element" class="section-name selfRef">&lt;num-clashes&gt; Element</a>
</h4>
<p id="section-9.7.1-1">The &lt;num-clashes&gt; element contains the number of clashes
          that this pronunciation has with other pronunciations in an active
          enrollment session. The associated Clash-Threshold header field
          determines the sensitivity of the clash measurement. Note that clash
          testing can be turned off completely by setting the Clash-Threshold
          header field value to 0.</p></section><section id="section-9.7.2"><h4 id="name-num-good-repetitions-elemen">
<a href="#section-9.7.2" class="section-number selfRef">9.7.2.Â </a><a href="#name-num-good-repetitions-elemen" class="section-name selfRef">&lt;num-good-repetitions&gt; Element</a>
</h4>
<p id="section-9.7.2-1">The &lt;num-good-repetitions&gt; element contains the number of
          consistent pronunciations obtained so far in an active enrollment
          session.</p></section><section id="section-9.7.3"><h4 id="name-num-repetitions-still-neede">
<a href="#section-9.7.3" class="section-number selfRef">9.7.3.Â </a><a href="#name-num-repetitions-still-neede" class="section-name selfRef">&lt;num-repetitions-still-needed&gt; Element</a>
</h4>
<p id="section-9.7.3-1">The &lt;num-repetitions-still-needed&gt; element contains the
          number of consistent pronunciations that must still be obtained
          before the new phrase can be added to the enrollment grammar. The
          number of consistent pronunciations required is specified by the
          client in the request header field
          Num-Min-Consistent-Pronunciations. The returned value must be 0
          before the client can successfully commit a phrase to the grammar by
          ending the enrollment session.</p></section><section id="section-9.7.4"><h4 id="name-consistency-status-element">
<a href="#section-9.7.4" class="section-number selfRef">9.7.4.Â </a><a href="#name-consistency-status-element" class="section-name selfRef">&lt;consistency-status&gt; Element</a>
</h4>
<p id="section-9.7.4-1">The &lt;consistency-status&gt; element is used to indicate how
          consistent the repetitions are when learning a new phrase. It can
          have the values of consistent, inconsistent, and undecided.</p></section><section id="section-9.7.5"><h4 id="name-clash-phrase-ids-element">
<a href="#section-9.7.5" class="section-number selfRef">9.7.5.Â </a><a href="#name-clash-phrase-ids-element" class="section-name selfRef">&lt;clash-phrase-ids&gt; Element</a>
</h4>
<p id="section-9.7.5-1">The &lt;clash-phrase-ids&gt; element contains the phrase IDs of
          clashing pronunciation(s), if any. This element is absent if there
          are no clashes.</p></section><section id="section-9.7.6"><h4 id="name-transcriptions-element">
<a href="#section-9.7.6" class="section-number selfRef">9.7.6.Â </a><a href="#name-transcriptions-element" class="section-name selfRef">&lt;transcriptions&gt; Element</a>
</h4>
<p id="section-9.7.6-1">The &lt;transcriptions&gt; element contains the transcriptions
          returned in the last repetition of the phrase being enrolled.</p></section><section id="section-9.7.7"><h4 id="name-confusable-phrases-element">
<a href="#section-9.7.7" class="section-number selfRef">9.7.7.Â </a><a href="#name-confusable-phrases-element" class="section-name selfRef">&lt;confusable-phrases&gt; Element</a>
</h4>
<p id="section-9.7.7-1">The &lt;confusable-phrases&gt; element contains a list of phrases
          from a command grammar that are confusable with the phrase being
          added to the personal grammar. This element MAY be absent if there
          are no confusable phrases.</p></section>
</div></section><section id="section-9.8"><div id="sec.defineGrammar">
<h3 id="name-define-grammar">
<a href="#section-9.8" class="section-number selfRef">9.8.Â </a><a href="#name-define-grammar" class="section-name selfRef">DEFINE-GRAMMAR</a>
</h3>
<p id="section-9.8-1">The DEFINE-GRAMMAR method, from the client to the server, provides
        one or more grammars and requests the server to access, fetch, and
        compile the grammars as needed. The DEFINE-GRAMMAR method
        implementation MUST do a fetch of all external URIs that are part of
        that operation. If caching is implemented, this URI fetching MUST
        conform to the cache control hints and parameter header fields
        associated with the method in deciding whether the URIs should be fetched
        from cache or from the external server.

 If these hints/parameters are
        not specified in the method, the values set for the session using
        SET-PARAMS/GET-PARAMS apply. If it was not set for the session, their
        default values apply.</p>
<p id="section-9.8-2">If the server resource is in the recognition state, the
        DEFINE-GRAMMAR request MUST respond with a failure status.</p>
<p id="section-9.8-3">If the resource is in the idle state and is able to successfully
        process the supplied grammars, the server MUST return a success code
        status and the request-state MUST be COMPLETE.</p>
<p id="section-9.8-4">If the recognizer resource could not define the grammar for some
        reason (for example, if the download failed, the grammar failed to
        compile, or the grammar was in an unsupported form), the MRCPv2
        response for the DEFINE-GRAMMAR method MUST contain a failure
        status-code of 407 and contain a Completion-Cause header field
        describing the failure reason.</p>
<figure id="figure-25"><div><div id="section-9.8-5" class="artwork art-text" text-align="left"><pre>
C-&gt;S:MRCP/2.0 ... DEFINE-GRAMMAR 543257
Channel-Identifier:32AECB23433801@speechrecog
Content-Type:application/srgs+xml
Content-ID:&lt;request1@form-level.store&gt;
Content-Length:...

&lt;?xml version="1.0"?&gt;

&lt;!-- the default grammar language is US English --&gt;
&lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
         xml:lang="en-US" version="1.0"&gt;

&lt;!-- single language attachment to tokens --&gt;
&lt;rule id="yes"&gt;
            &lt;one-of&gt;
                  &lt;item xml:lang="fr-CA"&gt;oui&lt;/item&gt;
                  &lt;item xml:lang="en-US"&gt;yes&lt;/item&gt;
            &lt;/one-of&gt; 
      &lt;/rule&gt; 

&lt;!-- single language attachment to a rule expansion --&gt;
      &lt;rule id="request"&gt;
            may I speak to
            &lt;one-of xml:lang="fr-CA"&gt;
                  &lt;item&gt;Michel Tremblay&lt;/item&gt;
                  &lt;item&gt;Andre Roy&lt;/item&gt;
            &lt;/one-of&gt;
      &lt;/rule&gt;

      &lt;/grammar&gt;

S-&gt;C:MRCP/2.0 ... 543257 200 COMPLETE
Channel-Identifier:32AECB23433801@speechrecog
        Completion-Cause:000 success


C-&gt;S:MRCP/2.0 ... DEFINE-GRAMMAR 543258
Channel-Identifier:32AECB23433801@speechrecog
Content-Type:application/srgs+xml
Content-ID:&lt;helpgrammar@root-level.store&gt;
Content-Length:...

&lt;?xml version="1.0"?&gt;

&lt;!-- the default grammar language is US English --&gt;
&lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
         xml:lang="en-US" version="1.0"&gt;

      &lt;rule id="request"&gt;
            I need help
      &lt;/rule&gt;

S-&gt;C:MRCP/2.0 ... 543258 200 COMPLETE
Channel-Identifier:32AECB23433801@speechrecog
        Completion-Cause:000 success

C-&gt;S:MRCP/2.0 ... DEFINE-GRAMMAR 543259
Channel-Identifier:32AECB23433801@speechrecog
Content-Type:application/srgs+xml
Content-ID:&lt;request2@field-level.store&gt;
Content-Length:...

&lt;?xml version="1.0" encoding="UTF-8"?&gt;

&lt;!DOCTYPE grammar PUBLIC "-//W3C//DTD GRAMMAR 1.0//EN"
                  "http://www.w3.org/TR/speech-grammar/grammar.dtd"&gt;

&lt;grammar xmlns="http://www.w3.org/2001/06/grammar" xml:lang="en"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
       xsi:schemaLocation="http://www.w3.org/2001/06/grammar 
           http://www.w3.org/TR/speech-grammar/grammar.xsd"
           version="1.0" mode="voice" root="basicCmd"&gt;

&lt;meta name="author" content="Stephanie Williams"/&gt;

&lt;rule id="basicCmd" scope="public"&gt;
  &lt;example&gt; please move the window &lt;/example&gt;
  &lt;example&gt; open a file &lt;/example&gt;

  &lt;ruleref 
    uri="http://grammar.example.com/politeness.grxml#startPolite"/&gt;

  &lt;ruleref uri="#command"/&gt;
  &lt;ruleref
    uri="http://grammar.example.com/politeness.grxml#endPolite"/&gt;
&lt;/rule&gt;

&lt;rule id="command"&gt;
  &lt;ruleref uri="#action"/&gt; &lt;ruleref uri="#object"/&gt;
&lt;/rule&gt;

&lt;rule id="action"&gt;
   &lt;one-of&gt;
      &lt;item weight="10"&gt; open   &lt;tag&gt;open&lt;/tag&gt;   &lt;/item&gt;
      &lt;item weight="2"&gt;  close  &lt;tag&gt;close&lt;/tag&gt;  &lt;/item&gt;
      &lt;item weight="1"&gt;  delete &lt;tag&gt;delete&lt;/tag&gt; &lt;/item&gt;
      &lt;item weight="1"&gt;  move   &lt;tag&gt;move&lt;/tag&gt;   &lt;/item&gt;
   &lt;/one-of&gt;
&lt;/rule&gt;

&lt;rule id="object"&gt;
  &lt;item repeat="0-1"&gt;
    &lt;one-of&gt;
      &lt;item&gt; the &lt;/item&gt;
      &lt;item&gt; a &lt;/item&gt;
    &lt;/one-of&gt;
  &lt;/item&gt;

  &lt;one-of&gt;
      &lt;item&gt; window &lt;/item&gt;
      &lt;item&gt; file &lt;/item&gt;
      &lt;item&gt; menu &lt;/item&gt;
  &lt;/one-of&gt;
&lt;/rule&gt;

&lt;/grammar&gt;


S-&gt;C:MRCP/2.0 ... 543259 200 COMPLETE
Channel-Identifier:32AECB23433801@speechrecog
        Completion-Cause:000 success

C-&gt;S:MRCP/2.0 ... RECOGNIZE 543260
Channel-Identifier:32AECB23433801@speechrecog
        N-Best-List-Length:2
Content-Type:text/uri-list
Content-Length:...

session:request1@form-level.store
session:request2@field-level.store
session:helpgramar@root-level.store

S-&gt;C:MRCP/2.0 ... 543260 200 IN-PROGRESS
Channel-Identifier:32AECB23433801@speechrecog

S-&gt;C:MRCP/2.0 ... START-OF-INPUT 543260 IN-PROGRESS
Channel-Identifier:32AECB23433801@speechrecog
        
S-&gt;C:MRCP/2.0 ... RECOGNITION-COMPLETE 543260 COMPLETE
Channel-Identifier:32AECB23433801@speechrecog
Completion-Cause:000 success
Waveform-URI:&lt;http://web.media.com/session123/audio.wav&gt;;
             size=124535;duration=2340
Content-Type:application/x-nlsml
Content-Length:...

&lt;?xml version="1.0"?&gt;
&lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
        xmlns:ex="http://www.example.com/example"
        grammar="session:request1@form-level.store"&gt;
        &lt;interpretation&gt;
            &lt;instance name="Person"&gt;
            &lt;ex:Person&gt;
                &lt;ex:Name&gt; Andre Roy &lt;/ex:Name&gt;
            &lt;/ex:Person&gt;
         &lt;/instance&gt;
         &lt;input&gt;   may I speak to Andre Roy &lt;/input&gt;
    &lt;/interpretation&gt;
&lt;/result&gt;
</pre></div></div>
<figcaption><a href="#figure-25">Figure 25</a><a href="#name-define-grammar-example" id="name-define-grammar-example" class="selfRef">Define Grammar Example</a></figcaption></figure>
</div></section><section id="section-9.9"><div id="sec.methodRecognize">
<h3 id="name-recognize">
<a href="#section-9.9" class="section-number selfRef">9.9.Â </a><a href="#name-recognize" class="section-name selfRef">RECOGNIZE</a>
</h3>
<p id="section-9.9-1">The RECOGNIZE method from the client to the server requests the
        recognizer to start recognition and provides it with one or more
        grammar references for grammars to match against the input media. The
        RECOGNIZE method can carry header fields to control the sensitivity,
        confidence level, and the level of detail in results provided by the
        recognizer. These header field values override the current values set
        by a previous SET-PARAMS method.</p>
<p id="section-9.9-2">The RECOGNIZE method can request the recognizer resource to operate
        in normal or hotword mode as specified by the Recognition-Mode header
        field. The default value is "normal". If the resource could not start
        a recognition, the server MUST respond with a failure status-code of
        407 and a Completion-Cause header field in the response describing the
        cause of failure.</p>
<p id="section-9.9-3">The RECOGNIZE request uses the message body to specify the grammars
        applicable to the request. The active grammar(s) for the request can
        be specified in one of three ways. If the client needs to explicitly
        control grammar weights for the recognition operation, it MUST employ
        method 3 below. The order of these grammars specifies the precedence
        of the grammars that is used when more than one grammar in the list
        matches the speech; in this case, the grammar with the higher
        precedence is returned as a match. This precedence capability is
        useful in applications like VoiceXML browsers to order grammars
        specified at the dialog, document, and root level of a VoiceXML
        application.

        </p>
<ol id="section-9.9-4">
<li id="section-9.9-5">The grammar MAY be placed directly in the message body as typed
            content. If more than one grammar is included in the body, the
            order of inclusion controls the corresponding precedence for the
            grammars during recognition, with earlier grammars in the body
            having a higher precedence than later ones.</li>
<li id="section-9.9-6">The body MAY contain a list of grammar URIs specified in
            content of media type 'text/uri-list' <span>[<a href="#RFC2483" class="xref">RFC2483</a>]. The order of the URIs determines
            the corresponding precedence for the grammars during recognition,
            with highest precedence first and decreasing for each URI
            thereafter.</span>
</li>
<li id="section-9.9-7">The body MAY contain a list of grammar URIs specified in
            content of media type 'text/grammar-ref-list'. This type defines a
            list of grammar URIs and allows each grammar URI to be assigned a
            weight in the list. This weight has the same meaning as the
            weights described in Section 2.4.1 of <span>[<a href="#W3C.REC-speech-grammar-20040316" class="xref">the Speech Grammar Markup
            Format (SRGS)</a>].</span>
</li>
</ol>
<p id="section-9.9-8">

        In addition to performing recognition on the input, the
        recognizer MUST also enroll the collected utterance in a personal
        grammar if the Enroll-Utterance header field is set to true and an
        Enrollment is active (via an earlier execution of the
        START-PHRASE-ENROLLMENT method). If so, and if the RECOGNIZE request
        contains a Content-ID header field, then the resulting grammar (which
        includes the personal grammar as a sub-grammar) can be referenced
        through the 'session' URI scheme (see <a href="#sec.sessionURIScheme" class="xref">Section 13.6</a>).</p>
<p id="section-9.9-9">If the resource was able to successfully start the recognition, the
        server MUST return a success status-code and a request-state of
        INâ€‘PROGRESS. This means that the recognizer is active and that the
        client MUST be prepared to receive further events with this
        request-id.</p>
<p id="section-9.9-10">If the resource was able to queue the request, the server MUST
        return a success code and request-state of PENDING. This means that
        the recognizer is currently active with another request and that this
        request has been queued for processing.</p>
<p id="section-9.9-11">If the resource could not start a recognition, the server MUST
        respond with a failure status-code of 407 and a Completion-Cause
        header field in the response describing the cause of failure.</p>
<p id="section-9.9-12">For the recognizer resource, RECOGNIZE and INTERPRET are the only
        requests that return a request-state of IN-PROGRESS, meaning that
        recognition is in progress. When the recognition completes by matching
        one of the grammar alternatives or by a timeout without a match or
        for some other reason, the recognizer resource MUST send the client a
        RECOGNITION-COMPLETE event (or INTERPRETATION-COMPLETE, if INTERPRET
        was the request) with the result of the recognition and a
        request-state of COMPLETE.</p>
<p id="section-9.9-13">Large grammars can take a long time for the server to compile. For
        grammars that are used repeatedly, the client can improve server
        performance by issuing a DEFINE-GRAMMAR request with the grammar ahead
        of time. In such a case, the client can issue the RECOGNIZE request and
        reference the grammar through the 'session' URI scheme (see <a href="#sec.sessionURIScheme" class="xref">Section 13.6</a>). This also applies in general
        if the client wants to repeat recognition with a previous inline
        grammar.</p>
<p id="section-9.9-14">The RECOGNIZE method implementation MUST do a fetch of all external
        URIs that are part of that operation. If caching is implemented, this
        URI fetching MUST conform to the cache control hints and parameter
        header fields associated with the method in deciding whether it should
        be fetched from cache or from the external server. If these
        hints/parameters are not specified in the method, the values set for
        the session using SET-PARAMS/GET-PARAMS apply. If it was not set for
        the session, their default values apply.</p>
<p id="section-9.9-15">Note that since the audio and the messages are carried over
        separate communication paths there may be a race condition between the
        start of the flow of audio and the receipt of the RECOGNIZE method.
        For example, if an audio flow is started by the client at the same
        time as the RECOGNIZE method is sent, either the audio or the
        RECOGNIZE can arrive at the recognizer first. As another example, the
        client may choose to continuously send audio to the server and signal
        the server to recognize using the RECOGNIZE method. Mechanisms to
        resolve this condition are outside the scope of this specification.
        The recognizer can expect the media to start flowing when it receives
        the RECOGNIZE request, but it MUST NOT buffer anything it receives
        beforehand in order to preserve the semantics that application authors
        expect with respect to the input timers.</p>
<p id="section-9.9-16">When a RECOGNIZE method has been received, the recognition is
        initiated on the stream. The No-Input-Timer MUST be started at this
        time if the Start-Input-Timers header field is specified as "true". If
        this header field is set to "false", the No-Input-Timer MUST be
        started when it receives the START-INPUT-TIMERS method from the
        client. 

The Recognition-Timeout MUST be started when the recognition
        resource detects speech or a DTMF digit in the media stream.</p>
<p id="section-9.9-17">For recognition when not in hotword mode:</p>
<p id="section-9.9-18">When the recognizer resource detects speech or a DTMF digit in the
        media stream, it MUST send the START-OF-INPUT event. When enough speech
        has been collected for the server to process, the recognizer can try
        to match the collected speech with the active grammars. If the speech
        collected at this point fully matches with any of the active grammars,
        the Speech-Complete-Timer is started. If it matches partially with one
        or more of the active grammars, with more speech needed before a full
        match is achieved, then the Speech-Incomplete-Timer is started.</p>
<ol id="section-9.9-19">
<li id="section-9.9-20">When the No-Input-Timer expires, the recognizer MUST complete
        with a Completion-Cause code of "no-input-timeout".</li>
<li id="section-9.9-21">The recognizer MUST support detecting a no-match condition upon
        detecting end of speech. The recognizer MAY support detecting a
        no-match condition before waiting for end-of-speech. If this is
        supported, this capability is enabled by setting the Early-No-Match
        header field to "true". Upon detecting a no-match condition, the
        RECOGNIZE MUST return with "no-match".</li>
<li id="section-9.9-22">When the Speech-Incomplete-Timer expires, the recognizer SHOULD
        complete with a Completion-Cause code of "partial-match", unless the
        recognizer cannot differentiate a partial-match, in which case it MUST
        return a Completion-Cause code of "no-match". The recognizer MAY
        return results for the partially matched grammar.</li>
<li id="section-9.9-23">When the Speech-Complete-Timer expires, the recognizer MUST
        complete with a Completion-Cause code of "success".</li>
<li id="section-9.9-24">
<p id="section-9.9-25">When the Recognition-Timeout expires, one of the following MUST
        happen:

        </p>
<dl id="section-9.9-26" class="dlParallel">
<dt id="section-9.9-27">5.1.</dt>
<dd id="section-9.9-28"> If there was a partial-match, the recognizer SHOULD complete
        with a Completion-Cause code of "partial-match-maxtime", unless the
        recognizer cannot differentiate a partial-match, in which case it MUST
        complete with a Completion-Cause code of "no-match-maxtime". The
        recognizer MAY return results for the partially matched grammar.</dd>
<dt id="section-9.9-29">5.2.</dt>
<dd id="section-9.9-30">If there was a full-match, the recognizer MUST complete with a
        Completion-Cause code of "success-maxtime".</dd>
<dt id="section-9.9-31">5.3.</dt>
<dd id="section-9.9-32">If there was a no match, the recognizer MUST complete with a
        Completion-Cause code of "no-match-maxtime".</dd>
</dl>
</li>
</ol>
<p id="section-9.9-33">For recognition in hotword mode:</p>
<p id="section-9.9-34">Note that for recognition in hotword mode the START-OF-INPUT event is
        not generated when speech or a DTMF digit is detected.</p>
<ol id="section-9.9-35">
<li id="section-9.9-36">When the No-Input-Timer expires, the recognizer MUST complete
        with a Completion-Cause code of "no-input-timeout".</li>
<li id="section-9.9-37">If at any point a match occurs, the RECOGNIZE MUST complete with
        a Completion-Cause code of "success".</li>
<li id="section-9.9-38">When the Recognition-Timeout expires and there is not a match, the
        RECOGNIZE MUST complete with a Completion-Cause code of
        "hotword-maxtime".</li>
<li id="section-9.9-39">When the Recognition-Timeout expires and there is a match, the
        RECOGNIZE MUST complete with a Completion-Cause code of
        "success-maxtime".</li>
<li id="section-9.9-40">When the Recognition-Timeout is running but the detected
        speech/DTMF has not resulted in a match, the Recognition-Timeout MUST be
        stopped and reset. It MUST then be restarted when speech/DTMF is again
        detected.</li>
</ol>
<p id="section-9.9-41">
Below is a complete example of using RECOGNIZE.  It shows the call to
RECOGNIZE, the IN-PROGRESS and START-OF-INPUT status messages, and the final
RECOGNITION-COMPLETE message containing the result.
</p>
<div id="section-9.9-42" class="artwork art-text" text-align="left"><pre>
C-&gt;S:MRCP/2.0 ... RECOGNIZE 543257
Channel-Identifier:32AECB23433801@speechrecog
        Confidence-Threshold:0.9
Content-Type:application/srgs+xml
Content-ID:&lt;request1@form-level.store&gt;
Content-Length:...

&lt;?xml version="1.0"?&gt;

&lt;!-- the default grammar language is US English --&gt;
&lt;grammar xmlns="http://www.w3.org/2001/06/grammar" 
         xml:lang="en-US" version="1.0" root="request"&gt;

&lt;!-- single language attachment to tokens --&gt;
    &lt;rule id="yes"&gt;
            &lt;one-of&gt;
                  &lt;item xml:lang="fr-CA"&gt;oui&lt;/item&gt;
                  &lt;item xml:lang="en-US"&gt;yes&lt;/item&gt;
            &lt;/one-of&gt; 
      &lt;/rule&gt; 

&lt;!-- single language attachment to a rule expansion --&gt;
      &lt;rule id="request"&gt;
            may I speak to
            &lt;one-of xml:lang="fr-CA"&gt;
                  &lt;item&gt;Michel Tremblay&lt;/item&gt;
                  &lt;item&gt;Andre Roy&lt;/item&gt;
            &lt;/one-of&gt;
      &lt;/rule&gt;

  &lt;/grammar&gt;

S-&gt;C: MRCP/2.0 ... 543257 200 IN-PROGRESS
Channel-Identifier:32AECB23433801@speechrecog

S-&gt;C:MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS
Channel-Identifier:32AECB23433801@speechrecog
        
S-&gt;C:MRCP/2.0 ... RECOGNITION-COMPLETE 543257 COMPLETE
Channel-Identifier:32AECB23433801@speechrecog
Completion-Cause:000 success
Waveform-URI:&lt;http://web.media.com/session123/audio.wav&gt;;
              size=424252;duration=2543
Content-Type:application/nlsml+xml
Content-Length:...

&lt;?xml version="1.0"?&gt;
&lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
        xmlns:ex="http://www.example.com/example"
        grammar="session:request1@form-level.store"&gt;
    &lt;interpretation&gt;
        &lt;instance name="Person"&gt;
            &lt;ex:Person&gt;
                &lt;ex:Name&gt; Andre Roy &lt;/ex:Name&gt;
            &lt;/ex:Person&gt;
        &lt;/instance&gt;
            &lt;input&gt;   may I speak to Andre Roy &lt;/input&gt;
    &lt;/interpretation&gt;
&lt;/result&gt;
</pre></div>
<p id="section-9.9-43">
Below is an example of calling RECOGNIZE with a different grammar.  No status
or completion messages are shown in this example, although they would of course
occur in normal usage.
</p>
<div id="section-9.9-44" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... RECOGNIZE 543257 
        Channel-Identifier:32AECB23433801@speechrecog 
        Confidence-Threshold:0.9 
        Fetch-Timeout:20
        Content-Type:application/srgs+xml 
        Content-Length:...
        
        &lt;?xml version="1.0"? Version="1.0" mode="voice" 
              root="Basic md"&gt;
         &lt;rule id="rule_list" scope="public"&gt;
             &lt;one-of&gt;
                 &lt;item weight=10&gt;
                     &lt;ruleref uri=
            "http://grammar.example.com/world-cities.grxml#canada"/&gt;
                &lt;/item&gt;
                &lt;item weight=1.5&gt;
                    &lt;ruleref uri=
            "http://grammar.example.com/world-cities.grxml#america"/&gt;
                &lt;/item&gt;
               &lt;item weight=0.5&gt;
                    &lt;ruleref uri=
            "http://grammar.example.com/world-cities.grxml#india"/&gt;
               &lt;/item&gt;
           &lt;/one-of&gt;
        &lt;/rule&gt;
</pre></div>
</div></section><section id="section-9.10"><h3 id="name-stop-2">
<a href="#section-9.10" class="section-number selfRef">9.10.Â </a><a href="#name-stop-2" class="section-name selfRef">STOP</a>
</h3>
<p id="section-9.10-1">The STOP method from the client to the server tells the resource to
        stop recognition if a request is active. If a RECOGNIZE request is
        active and the STOP request successfully terminated it, then the
        response header section contains an Active-Request-Id-List header
        field containing the request-id of the RECOGNIZE request that was
        terminated. In this case, no RECOGNITION-COMPLETE event is sent for
        the terminated request. If there was no recognition active, then the
        response MUST NOT contain an Active-Request-Id-List header field.
        Either way, the response MUST contain a status-code of 200
        "Success".</p>
<div id="section-9.10-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... RECOGNIZE 543257
        Channel-Identifier:32AECB23433801@speechrecog
        Confidence-Threshold:0.9
        Content-Type:application/srgs+xml
        Content-ID:&lt;request1@form-level.store&gt;
        Content-Length:...
        
        &lt;?xml version="1.0"?&gt;

        &lt;!-- the default grammar language is US English --&gt;
        &lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
                 xml:lang="en-US" version="1.0" root="request"&gt;

        &lt;!-- single language attachment to tokens --&gt;
            &lt;rule id="yes"&gt;
                &lt;one-of&gt;
                      &lt;item xml:lang="fr-CA"&gt;oui&lt;/item&gt;
                      &lt;item xml:lang="en-US"&gt;yes&lt;/item&gt;
                &lt;/one-of&gt; 
            &lt;/rule&gt; 

        &lt;!-- single language attachment to a rule expansion --&gt;
            &lt;rule id="request"&gt;
            may I speak to
                &lt;one-of xml:lang="fr-CA"&gt;
                      &lt;item&gt;Michel Tremblay&lt;/item&gt;
                      &lt;item&gt;Andre Roy&lt;/item&gt;
                &lt;/one-of&gt;
            &lt;/rule&gt;
        &lt;/grammar&gt;

S-&gt;C:   MRCP/2.0 ... 543257 200 IN-PROGRESS
        Channel-Identifier:32AECB23433801@speechrecog

C-&gt;S:   MRCP/2.0 ... STOP 543258 200
        Channel-Identifier:32AECB23433801@speechrecog

S-&gt;C:   MRCP/2.0 ... 543258 200 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
        Active-Request-Id-List:543257
</pre></div></section><section id="section-9.11"><h3 id="name-get-result">
<a href="#section-9.11" class="section-number selfRef">9.11.Â </a><a href="#name-get-result" class="section-name selfRef">GET-RESULT</a>
</h3>
<p id="section-9.11-1">The GET-RESULT method from the client to the server MAY be issued
        when the recognizer resource is in the recognized state. This request
        allows the client to retrieve results for a completed recognition.
        This is useful if the client decides it wants more alternatives or
        more information. When the server receives this request, it re-computes
        and returns the results according to the recognition constraints
        provided in the GET-RESULT request.</p>
<p id="section-9.11-2">The GET-RESULT request can specify constraints such as a different
        confidence-threshold or n-best-list-length. This capability is
        OPTIONAL for MRCPv2 servers and the automatic speech recognition
        engine in the server MUST return a status of unsupported feature if
        not supported.</p>
<div id="section-9.11-3" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... GET-RESULT 543257
        Channel-Identifier:32AECB23433801@speechrecog
        Confidence-Threshold:0.9
        

S-&gt;C:   MRCP/2.0 ... 543257 200 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
        Content-Type:application/nlsml+xml
        Content-Length:...
        
        &lt;?xml version="1.0"?&gt;
        &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                xmlns:ex="http://www.example.com/example"
                grammar="session:request1@form-level.store"&gt;
            &lt;interpretation&gt;
                &lt;instance name="Person"&gt;
                    &lt;ex:Person&gt;
                        &lt;ex:Name&gt; Andre Roy &lt;/ex:Name&gt;
                    &lt;/ex:Person&gt;
                &lt;/instance&gt;
                &lt;input&gt;   may I speak to Andre Roy &lt;/input&gt;
            &lt;/interpretation&gt;
        &lt;/result&gt;
</pre></div></section><section id="section-9.12"><h3 id="name-start-of-input">
<a href="#section-9.12" class="section-number selfRef">9.12.Â </a><a href="#name-start-of-input" class="section-name selfRef">START-OF-INPUT</a>
</h3>
<p id="section-9.12-1">This is an event from the server to the client indicating that the
        recognizer resource has detected speech or a DTMF digit in the media
        stream. This event is useful in implementing kill-on-barge-in
        scenarios when a synthesizer resource is in a different session from
        the recognizer resource and hence is not aware of an incoming audio
        source (see <a href="#sec.kill-on-barge-in" class="xref">Section 8.4.2</a>). In these
        cases, it is up to the client to act as an intermediary and respond to
        this event by issuing a BARGE-IN-OCCURRED event to the synthesizer
        resource. The recognizer resource also MUST send a Proxy-Sync-Id
        header field with a unique value for this event.</p>
<p id="section-9.12-2">This event MUST be generated by the server, irrespective of
        whether or not
        the synthesizer and recognizer are on the same server.</p></section><section id="section-9.13"><h3 id="name-start-input-timers-2">
<a href="#section-9.13" class="section-number selfRef">9.13.Â </a><a href="#name-start-input-timers-2" class="section-name selfRef">START-INPUT-TIMERS</a>
</h3>
<p id="section-9.13-1">This request is sent from the client to the recognizer resource
        when it knows that a kill-on-barge-in prompt has finished playing (see
        <a href="#sec.kill-on-barge-in" class="xref">Section 8.4.2</a>). This is useful in the
        scenario when the recognition and synthesizer engines are not in the
        same session. When a kill-on-barge-in prompt is being played, the
        client may want a RECOGNIZE request to be simultaneously active so
        that it can detect and implement kill-on-barge-in. But at the same
        time the client doesn't want the recognizer to start the no-input
        timers until the prompt is finished. The Start-Input-Timers header
        field in the RECOGNIZE request allows the client to say
        whether or not the
        timers should be started immediately. If not, the recognizer
        resource MUST NOT start the timers until the client sends a
        START-INPUT-TIMERS method to the recognizer.</p></section><section id="section-9.14"><h3 id="name-recognition-complete">
<a href="#section-9.14" class="section-number selfRef">9.14.Â </a><a href="#name-recognition-complete" class="section-name selfRef">RECOGNITION-COMPLETE</a>
</h3>
<p id="section-9.14-1">This is an event from the recognizer resource to the client
        indicating that the recognition completed. The recognition result is
        sent in the body of the MRCPv2 message. The request-state field MUST
        be COMPLETE indicating that this is the last event with that
        request-id and that the request with that request-id is now complete.
        The server MUST maintain the recognizer context containing the results
        and the audio waveform input of that recognition until the next
        RECOGNIZE request is issued for that resource or the session
        terminates. If the server returns a URI to the audio waveform, it MUST
        do so in a Waveform-URI header field in the RECOGNITION-COMPLETE
        event. The client can use this URI to retrieve or playback the
        audio.</p>
<p id="section-9.14-2">Note, if an enrollment session was active, the RECOGNITION-COMPLETE
        event can contain either recognition or enrollment results depending
        on what was spoken. The following example shows a complete exchange
        with a recognition result.</p>
<div id="section-9.14-3" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... RECOGNIZE 543257
        Channel-Identifier:32AECB23433801@speechrecog
        Confidence-Threshold:0.9
        Content-Type:application/srgs+xml
        Content-ID:&lt;request1@form-level.store&gt;
        Content-Length:...
        
        &lt;?xml version="1.0"?&gt;

        &lt;!-- the default grammar language is US English --&gt;
        &lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
                 xml:lang="en-US" version="1.0" root="request"&gt;

        &lt;!-- single language attachment to tokens --&gt;
            &lt;rule id="yes"&gt;
                   &lt;one-of&gt;
                       &lt;item xml:lang="fr-CA"&gt;oui&lt;/item&gt;
                       &lt;item xml:lang="en-US"&gt;yes&lt;/item&gt;
                   &lt;/one-of&gt; 
              &lt;/rule&gt; 

        &lt;!-- single language attachment to a rule expansion --&gt;
              &lt;rule id="request"&gt;
                  may I speak to
                   &lt;one-of xml:lang="fr-CA"&gt;
                          &lt;item&gt;Michel Tremblay&lt;/item&gt;
                          &lt;item&gt;Andre Roy&lt;/item&gt;
                   &lt;/one-of&gt;
              &lt;/rule&gt;
        &lt;/grammar&gt;

S-&gt;C:   MRCP/2.0 ... 543257 200 IN-PROGRESS
        Channel-Identifier:32AECB23433801@speechrecog

S-&gt;C:   MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS
        Channel-Identifier:32AECB23433801@speechrecog
        
S-&gt;C:   MRCP/2.0 ... RECOGNITION-COMPLETE 543257 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
        Completion-Cause:000 success
        Waveform-URI:&lt;http://web.media.com/session123/audio.wav&gt;;
                     size=342456;duration=25435
        Content-Type:application/nlsml+xml
        Content-Length:...
        
        &lt;?xml version="1.0"?&gt;
        &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                xmlns:ex="http://www.example.com/example"
                grammar="session:request1@form-level.store"&gt;
            &lt;interpretation&gt;
                &lt;instance name="Person"&gt;
                    &lt;ex:Person&gt;
                        &lt;ex:Name&gt; Andre Roy &lt;/ex:Name&gt;
                    &lt;/ex:Person&gt;
                &lt;/instance&gt;
                &lt;input&gt;   may I speak to Andre Roy &lt;/input&gt;
            &lt;/interpretation&gt;
        &lt;/result&gt;
</pre></div>
<p id="section-9.14-4">If the result were instead an enrollment result, the final message
        from the server above could have been:</p>
<div id="section-9.14-5" class="artwork art-text" text-align="left"><pre>
S-&gt;C:   MRCP/2.0 ... RECOGNITION-COMPLETE 543257 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
        Completion-Cause:000 success
        Content-Type:application/nlsml+xml
        Content-Length:...
        
        &lt;?xml version= "1.0"?&gt;
        &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                grammar="Personal-Grammar-URI"&gt;
            &lt;enrollment-result&gt;
                &lt;num-clashes&gt; 2 &lt;/num-clashes&gt;
                &lt;num-good-repetitions&gt; 1 &lt;/num-good-repetitions&gt;
                &lt;num-repetitions-still-needed&gt; 
                   1 
                &lt;/num-repetitions-still-needed&gt;
                &lt;consistency-status&gt; consistent &lt;/consistency-status&gt;
                &lt;clash-phrase-ids&gt; 
                    &lt;item&gt; Jeff &lt;/item&gt; &lt;item&gt; Andre &lt;/item&gt; 
                &lt;/clash-phrase-ids&gt;
                &lt;transcriptions&gt;
                     &lt;item&gt; m ay b r ow k er &lt;/item&gt; 
                     &lt;item&gt; m ax r aa k ah &lt;/item&gt;
                &lt;/transcriptions&gt;
                &lt;confusable-phrases&gt;
                     &lt;item&gt;
                          &lt;phrase&gt; call &lt;/phrase&gt;
                          &lt;confusion-level&gt; 10 &lt;/confusion-level&gt;
                     &lt;/item&gt;
                &lt;/confusable-phrases&gt;
            &lt;/enrollment-result&gt;
        &lt;/result&gt;
</pre></div></section><section id="section-9.15"><h3 id="name-start-phrase-enrollment">
<a href="#section-9.15" class="section-number selfRef">9.15.Â </a><a href="#name-start-phrase-enrollment" class="section-name selfRef">START-PHRASE-ENROLLMENT</a>
</h3>
<p id="section-9.15-1">The START-PHRASE-ENROLLMENT method from the client to the server
        starts a new phrase enrollment session during which the client can
        call RECOGNIZE multiple times to enroll a new utterance in a grammar.
        An enrollment session consists of a set of calls to RECOGNIZE in which
        the caller speaks a phrase several times so the system can "learn" it.
        The phrase is then added to a personal grammar (speaker-trained
        grammar), so that the system can recognize it later.</p>
<p id="section-9.15-2">Only one phrase enrollment session can be active at a time for a
        resource. The Personal-Grammar-URI identifies the grammar that is used
        during enrollment to store the personal list of phrases. Once
        RECOGNIZE is called, the result is returned in a RECOGNITION-COMPLETE
        event and will contain either an enrollment result OR a recognition
        result for a regular recognition.</p>
<p id="section-9.15-3">Calling END-PHRASE-ENROLLMENT ends the ongoing phrase enrollment
        session, which is typically done after a sequence of successful calls
        to RECOGNIZE. This method can be called to commit the new phrase to
        the personal grammar or to abort the phrase enrollment session.</p>
<p id="section-9.15-4">The grammar to contain the new enrolled phrase, specified by
        Personal-Grammar-URI, is created if it does not exist. Also, the
        personal grammar MUST ONLY contain phrases added via a phrase
        enrollment session.</p>
<p id="section-9.15-5">The Phrase-ID passed to this method is used to identify this phrase
        in the grammar and will be returned as the speech input when doing a
        RECOGNIZE on the grammar. The Phrase-NL similarly is returned in a
        RECOGNITION-COMPLETE event in the same manner as other Natural
        Language (NL) in a grammar. The tag-format of this NL is
        implementation specific.</p>
<p id="section-9.15-6">If the client has specified Save-Best-Waveform as true, then the
        response after ending the phrase enrollment session MUST contain the
        location/URI of a recording of the best repetition of the learned
        phrase.</p>
<div id="section-9.15-7" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... START-PHRASE-ENROLLMENT 543258
        Channel-Identifier:32AECB23433801@speechrecog
        Num-Min-Consistent-Pronunciations:2
        Consistency-Threshold:30
        Clash-Threshold:12
        Personal-Grammar-URI:&lt;personal grammar uri&gt;
        Phrase-Id:&lt;phrase id&gt;
        Phrase-NL:&lt;NL phrase&gt;
        Weight:1
        Save-Best-Waveform:true

S-&gt;C:   MRCP/2.0 ... 543258 200 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
</pre></div></section><section id="section-9.16"><h3 id="name-enrollment-rollback">
<a href="#section-9.16" class="section-number selfRef">9.16.Â </a><a href="#name-enrollment-rollback" class="section-name selfRef">ENROLLMENT-ROLLBACK</a>
</h3>
<p id="section-9.16-1">The ENROLLMENT-ROLLBACK method discards the last live utterance
        from the RECOGNIZE operation. The client can invoke this method when
        the caller provides undesirable input such as non-speech noises,
        side-speech, commands, utterance from the RECOGNIZE grammar, etc. Note
        that this method does not provide a stack of rollback states.
        Executing ENROLLMENT-ROLLBACK twice in succession without an
        intervening recognition operation has no effect the second time.</p>
<div id="section-9.16-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... ENROLLMENT-ROLLBACK 543261
        Channel-Identifier:32AECB23433801@speechrecog

S-&gt;C:   MRCP/2.0 ... 543261 200 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
</pre></div></section><section id="section-9.17"><h3 id="name-end-phrase-enrollment">
<a href="#section-9.17" class="section-number selfRef">9.17.Â </a><a href="#name-end-phrase-enrollment" class="section-name selfRef">END-PHRASE-ENROLLMENT</a>
</h3>
<p id="section-9.17-1">The client MAY call the END-PHRASE-ENROLLMENT method ONLY during an
        active phrase enrollment session. It MUST NOT be called during an
        ongoing RECOGNIZE operation. To commit the new phrase in the grammar,
        the client MAY call this method once successive calls to RECOGNIZE
        have succeeded and Num-Repetitions-Still-Needed has been returned as 0
        in the RECOGNITION-COMPLETE event. Alternatively, the client MAY abort
        the phrase enrollment session by calling this method with the
        Abort-Phrase-Enrollment header field.</p>
<p id="section-9.17-2">If the client has specified Save-Best-Waveform as "true" in the
        START-PHRASE-ENROLLMENT request, then the response MUST contain a
        Waveform-URI header whose value is the location/URI of a recording of
        the best repetition of the learned phrase.</p>
<div id="section-9.17-3" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... END-PHRASE-ENROLLMENT 543262
        Channel-Identifier:32AECB23433801@speechrecog
    

S-&gt;C:   MRCP/2.0 ... 543262 200 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
        Waveform-URI:&lt;http://mediaserver.com/recordings/file1324.wav&gt;
                     ;size=242453;duration=25432
</pre></div></section><section id="section-9.18"><h3 id="name-modify-phrase">
<a href="#section-9.18" class="section-number selfRef">9.18.Â </a><a href="#name-modify-phrase" class="section-name selfRef">MODIFY-PHRASE</a>
</h3>
<p id="section-9.18-1">The MODIFY-PHRASE method sent from the client to the server is used
        to change the phrase ID, NL phrase, and/or weight for a given phrase in
        a personal grammar.</p>
<p id="section-9.18-2">If no fields are supplied, then calling this method has no
        effect.</p>
<div id="section-9.18-3" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... MODIFY-PHRASE 543265    
        Channel-Identifier:32AECB23433801@speechrecog
        Personal-Grammar-URI:&lt;personal grammar uri&gt;
        Phrase-Id:&lt;phrase id&gt;
        New-Phrase-Id:&lt;new phrase id&gt;
        Phrase-NL:&lt;NL phrase&gt;
        Weight:1

S-&gt;C:   MRCP/2.0 ... 543265 200 COMPLETE 
        Channel-Identifier:32AECB23433801@speechrecog</pre></div></section><section id="section-9.19"><h3 id="name-delete-phrase">
<a href="#section-9.19" class="section-number selfRef">9.19.Â </a><a href="#name-delete-phrase" class="section-name selfRef">DELETE-PHRASE</a>
</h3>
<p id="section-9.19-1">The DELETE-PHRASE method sent from the client to the server is used
        to delete a phase that is in a personal grammar and was added through voice enrollment
        or text enrollment. If the specified phrase does not exist, this
        method has no effect.</p>
<div id="section-9.19-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... DELETE-PHRASE 543266
        Channel-Identifier:32AECB23433801@speechrecog
        Personal-Grammar-URI:&lt;personal grammar uri&gt;
        Phrase-Id:&lt;phrase id&gt;

S-&gt;C:   MRCP/2.0 ... 543266 200 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
</pre></div></section><section id="section-9.20"><div id="sec.interpret">
<h3 id="name-interpret">
<a href="#section-9.20" class="section-number selfRef">9.20.Â </a><a href="#name-interpret" class="section-name selfRef">INTERPRET</a>
</h3>
<p id="section-9.20-1">The INTERPRET method from the client to the server takes as input
        an Interpret-Text header field containing the text for which the
        semantic interpretation is desired, and returns, via the
        INTERPRETATION-COMPLETE event, an interpretation result that is very
        similar to the one returned from a RECOGNIZE method invocation. Only
        portions of the result relevant to acoustic matching are excluded from
        the result. The Interpret-Text header field MUST be included in the
        INTERPRET request.</p>
<p id="section-9.20-2">Recognizer grammar data is treated in the same way as it is when
        issuing a RECOGNIZE method call.</p>
<p id="section-9.20-3">If a RECOGNIZE, RECORD, or another INTERPRET operation is already in
        progress for the resource, the server MUST reject the request with a
        response having a status-code of 402 "Method not valid in this state",
        and a COMPLETE request state.</p>
<div id="section-9.20-4" class="artwork art-text" text-align="left"><pre>
C-&gt;S:   MRCP/2.0 ... INTERPRET 543266
        Channel-Identifier:32AECB23433801@speechrecog 
        Interpret-Text:may I speak to Andre Roy 
        Content-Type:application/srgs+xml  
        Content-ID:&lt;request1@form-level.store&gt;  
        Content-Length:...
        
        &lt;?xml version="1.0"?&gt;  
        &lt;!-- the default grammar language is US English --&gt;  
        &lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
                 xml:lang="en-US" version="1.0" root="request"&gt;  
        &lt;!-- single language attachment to tokens --&gt;  
            &lt;rule id="yes"&gt;  
                &lt;one-of&gt;  
                    &lt;item xml:lang="fr-CA"&gt;oui&lt;/item&gt;  
                    &lt;item xml:lang="en-US"&gt;yes&lt;/item&gt;  
                &lt;/one-of&gt;   
            &lt;/rule&gt;   
        
        &lt;!-- single language attachment to a rule expansion --&gt;  
            &lt;rule id="request"&gt;  
                may I speak to  
                &lt;one-of xml:lang="fr-CA"&gt;  
                    &lt;item&gt;Michel Tremblay&lt;/item&gt;  
                    &lt;item&gt;Andre Roy&lt;/item&gt;  
                &lt;/one-of&gt;  
            &lt;/rule&gt;  
        &lt;/grammar&gt;  
              
S-&gt;C:   MRCP/2.0 ... 543266 200 IN-PROGRESS
        Channel-Identifier:32AECB23433801@speechrecog
                   
S-&gt;C:   MRCP/2.0 ... INTERPRETATION-COMPLETE 543266 200 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
        Completion-Cause:000 success  
        Content-Type:application/nlsml+xml  
        Content-Length:...
        
        &lt;?xml version="1.0"?&gt;  
        &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                xmlns:ex="http://www.example.com/example"
                grammar="session:request1@form-level.store"&gt;  
            &lt;interpretation&gt;  
                &lt;instance name="Person"&gt;  
                    &lt;ex:Person&gt;  
                        &lt;ex:Name&gt; Andre Roy &lt;/ex:Name&gt;  
                    &lt;/ex:Person&gt;  
                &lt;/instance&gt;  
                &lt;input&gt;   may I speak to Andre Roy &lt;/input&gt;  
            &lt;/interpretation&gt;  
        &lt;/result&gt; 
</pre></div>
</div></section><section id="section-9.21"><h3 id="name-interpretation-complete">
<a href="#section-9.21" class="section-number selfRef">9.21.Â </a><a href="#name-interpretation-complete" class="section-name selfRef">INTERPRETATION-COMPLETE</a>
</h3>
<p id="section-9.21-1">This event from the recognizer resource to the client indicates
        that the INTERPRET operation is complete. The interpretation result is
        sent in the body of the MRCP message. The request state MUST be set to
        COMPLETE.</p>
<p id="section-9.21-2">The Completion-Cause header field MUST be included in this event
        and MUST be set to an appropriate value from the list of cause
        codes.</p>
<div id="section-9.21-3" class="artwork art-text" text-align="left"><pre>
C-&gt;S:    MRCP/2.0 ... INTERPRET 543266
        Channel-Identifier:32AECB23433801@speechrecog 
        Interpret-Text:may I speak to Andre Roy 
        Content-Type:application/srgs+xml  
        Content-ID:&lt;request1@form-level.store&gt;  
        Content-Length:...
        
        &lt;?xml version="1.0"?&gt;  
        &lt;!-- the default grammar language is US English --&gt;  
        &lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
                 xml:lang="en-US" version="1.0" root="request"&gt;  
        &lt;!-- single language attachment to tokens --&gt;  
            &lt;rule id="yes"&gt;  
                &lt;one-of&gt;  
                    &lt;item xml:lang="fr-CA"&gt;oui&lt;/item&gt;
                    &lt;item xml:lang="en-US"&gt;yes&lt;/item&gt;
                &lt;/one-of&gt;
            &lt;/rule&gt;
        
        &lt;!-- single language attachment to a rule expansion --&gt;  
            &lt;rule id="request"&gt;  
                may I speak to  
                &lt;one-of xml:lang="fr-CA"&gt;  
                    &lt;item&gt;Michel Tremblay&lt;/item&gt;  
                    &lt;item&gt;Andre Roy&lt;/item&gt;  
                &lt;/one-of&gt;  
            &lt;/rule&gt;      
        &lt;/grammar&gt;  
              
S-&gt;C:    MRCP/2.0 ... 543266 200 IN-PROGRESS
        Channel-Identifier:32AECB23433801@speechrecog
                   
S-&gt;C:    MRCP/2.0 ... INTERPRETATION-COMPLETE 543266 200 COMPLETE
        Channel-Identifier:32AECB23433801@speechrecog
        Completion-Cause:000 success  
        Content-Type:application/nlsml+xml  
        Content-Length:...
        
        &lt;?xml version="1.0"?&gt;  
        &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                xmlns:ex="http://www.example.com/example"
                grammar="session:request1@form-level.store"&gt;  
            &lt;interpretation&gt;  
                &lt;instance name="Person"&gt;  
                    &lt;ex:Person&gt;  
                        &lt;ex:Name&gt; Andre Roy &lt;/ex:Name&gt;  
                    &lt;/ex:Person&gt;  
                &lt;/instance&gt;  
                &lt;input&gt;   may I speak to Andre Roy &lt;/input&gt;  
            &lt;/interpretation&gt;  
        &lt;/result&gt;
</pre></div></section><section id="section-9.22"><h3 id="name-dtmf-detection">
<a href="#section-9.22" class="section-number selfRef">9.22.Â </a><a href="#name-dtmf-detection" class="section-name selfRef">DTMF Detection</a>
</h3>
<p id="section-9.22-1">Digits received as DTMF tones are delivered to the recognition
        resource in the MRCPv2 server in the RTP stream according to <span>[<a href="#RFC4733" class="xref">RFC 4733</a>]. The Automatic Speech Recognizer (ASR)
        MUST support RFC 4733 to recognize digits, and it MAY support
        recognizing </span><span>[<a href="#Q.23" class="xref">DTMF tones</a>] in the audio.</span></p></section>
</div></section><section id="section-10"><div id="sec.recorderResource">
<h2 id="name-recorder-resource">
<a href="#section-10" class="section-number selfRef">10.Â </a><a href="#name-recorder-resource" class="section-name selfRef">Recorder Resource</a>
</h2>
<p id="section-10-1">This resource captures received audio and video and stores it as
      content pointed to by a URI. The main usages of recorders are

        </p>
<ol id="section-10-2">
<li id="section-10-3">to capture speech audio that may be submitted for recognition at
          a later time, and</li>
<li id="section-10-4">recording voice or video mails.</li>
</ol>
<p id="section-10-5">

      Both these applications require functionality above and beyond
      those specified by protocols such as <span>[<a href="#RFC2326" class="xref">RTSP</a>].
      This includes audio endpointing (i.e., detecting speech or silence). The
      support for video is OPTIONAL and is mainly capturing video mails that
      may require the speech or audio processing mentioned above.</span></p>
<p id="section-10-6">A recorder MUST provide endpointing capabilities for suppressing
      silence at the beginning and end of a recording, and it MAY also suppress
      silence in the middle of a recording. If such suppression is done, the
      recorder MUST maintain timing metadata to indicate the actual time
      stamps of the recorded media.</p>
<p id="section-10-7">See the discussion on the sensitivity of saved waveforms in <a href="#sec.securityConsiderations" class="xref">Section 12</a>.</p>
<section id="section-10.1"><h3 id="name-recorder-state-machine">
<a href="#section-10.1" class="section-number selfRef">10.1.Â </a><a href="#name-recorder-state-machine" class="section-name selfRef">Recorder State Machine</a>
</h3>
<figure id="figure-26"><div><div id="section-10.1-1" class="artwork art-text" text-align="left"><pre>
Idle                   Recording
State                  State
 |                       |
 |---------RECORD-------&gt;|
 |                       |
 |&lt;------STOP------------|
 |                       |
 |&lt;--RECORD-COMPLETE-----|
 |                       |
 |              |--------|
 |       START-OF-INPUT  |
 |              |-------&gt;|
 |                       |
 |              |--------|
 |    START-INPUT-TIMERS |
 |              |-------&gt;|
 |                       |
</pre></div></div>
<figcaption><a href="#figure-26">Figure 26</a><a href="#name-recorder-state-machine-2" id="name-recorder-state-machine-2" class="selfRef">Recorder State Machine</a></figcaption></figure></section><section id="section-10.2"><h3 id="name-recorder-methods">
<a href="#section-10.2" class="section-number selfRef">10.2.Â </a><a href="#name-recorder-methods" class="section-name selfRef">Recorder Methods</a>
</h3>
<p id="section-10.2-1">The recorder resource supports the following methods.</p>
<div id="section-10.2-2" class="artwork art-text" text-align="left"><pre>
recorder-method      =  "RECORD"
                     /  "STOP"
                     /  "START-INPUT-TIMERS"
                    </pre></div></section><section id="section-10.3"><h3 id="name-recorder-events">
<a href="#section-10.3" class="section-number selfRef">10.3.Â </a><a href="#name-recorder-events" class="section-name selfRef">Recorder Events</a>
</h3>
<p id="section-10.3-1">The recorder resource can generate the following events.</p>
<div id="section-10.3-2" class="artwork art-text" text-align="left"><pre>
recorder-event       =  "START-OF-INPUT"
                     /  "RECORD-COMPLETE"
                    </pre></div></section><section id="section-10.4"><h3 id="name-recorder-header-fields">
<a href="#section-10.4" class="section-number selfRef">10.4.Â </a><a href="#name-recorder-header-fields" class="section-name selfRef">Recorder Header Fields</a>
</h3>
<p id="section-10.4-1">Method invocations for the recorder resource can contain
        resource-specific header fields containing request options and
        information to augment the Method, Response, or Event message it is
        associated with.</p>
<div id="section-10.4-2" class="artwork art-text" text-align="left"><pre>
recorder-header      =  sensitivity-level        
                     /  no-input-timeout
                     /  completion-cause
                     /  completion-reason
                     /  failed-uri
                     /  failed-uri-cause
                     /  record-uri
                     /  media-type
                     /  max-time
                     /  trim-length
                     /  final-silence
                     /  capture-on-speech
                     /  ver-buffer-utterance
                     /  start-input-timers
                     /  new-audio-channel
                    </pre></div>
<section id="section-10.4.1"><h4 id="name-sensitivity-level-2">
<a href="#section-10.4.1" class="section-number selfRef">10.4.1.Â </a><a href="#name-sensitivity-level-2" class="section-name selfRef">Sensitivity-Level</a>
</h4>
<p id="section-10.4.1-1">To filter out background noise and not mistake it for speech, the
          recorder can support a variable level of sound sensitivity. The
          Sensitivity-Level header field is a float value between 0.0 and 1.0
          and allows the client to set the sensitivity level for the recorder.
          This header field MAY occur in RECORD, SET-PARAMS, or GETâ€‘PARAMS. A
          higher value for this header field means higher sensitivity. The
          default value for this header field is implementation specific.</p>
<div id="section-10.4.1-2" class="artwork art-text" text-align="left"><pre>
sensitivity-level    =     "Sensitivity-Level" ":" FLOAT CRLF
            </pre></div></section><section id="section-10.4.2"><h4 id="name-no-input-timeout-2">
<a href="#section-10.4.2" class="section-number selfRef">10.4.2.Â </a><a href="#name-no-input-timeout-2" class="section-name selfRef">No-Input-Timeout</a>
</h4>
<p id="section-10.4.2-1">When recording is started and there is no speech detected for a
          certain period of time, the recorder can send a RECORD-COMPLETE
          event to the client and terminate the record operation. The
          No-Input-Timeout header field can set this timeout value. The value
          is in milliseconds. This header field MAY occur in RECORD,
          SET-PARAMS, or GET-PARAMS. The value for this header field ranges
          from 0 to an implementation-specific maximum value. The default
          value for this header field is implementation specific.</p>
<div id="section-10.4.2-2" class="artwork art-text" text-align="left"><pre>
no-input-timeout    =     "No-Input-Timeout" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-10.4.3"><h4 id="name-completion-cause-3">
<a href="#section-10.4.3" class="section-number selfRef">10.4.3.Â </a><a href="#name-completion-cause-3" class="section-name selfRef">Completion-Cause</a>
</h4>
<p id="section-10.4.3-1">This header field MUST be part of a RECORD-COMPLETE event from
          the recorder resource to the client. This indicates the reason
          behind the RECORD method completion. This header field MUST be sent
          in the RECORD responses if they return with a failure status and a
          COMPLETE state. In the ABNF below, the 'cause-code' contains a
          numerical value selected from the Cause-Code column of the following
          table. The 'cause-name' contains the corresponding token selected
          from the Cause-Name column.</p>
<div id="section-10.4.3-2" class="artwork art-text" text-align="left"><pre>
completion-cause         =  "Completion-Cause" ":" cause-code SP
                            cause-name CRLF
cause-code               =  3DIGIT
cause-name               =  *VCHAR
            </pre></div>
<table id="table-7">
<thead><tr>
<th>Cause-Code</th>
<th>Cause-Name</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr>
<td>000</td>
<td>success-silence</td>
<td>RECORD completed with a silence at the end.</td>
</tr>
<tr>
<td>001</td>
<td>success-maxtime</td>
<td>RECORD completed after reaching maximum recording time
            specified in record method.</td>
</tr>
<tr>
<td>002</td>
<td>no-input-timeout</td>
<td>RECORD failed due to no input.</td>
</tr>
<tr>
<td>003</td>
<td>uri-failure</td>
<td>Failure accessing the record URI.</td>
</tr>
<tr>
<td>004</td>
<td>error</td>
<td>RECORD request terminated prematurely due to a recorder
            error.</td>
</tr>
</tbody>
</table></section><section id="section-10.4.4"><h4 id="name-completion-reason-3">
<a href="#section-10.4.4" class="section-number selfRef">10.4.4.Â </a><a href="#name-completion-reason-3" class="section-name selfRef">Completion-Reason</a>
</h4>
<p id="section-10.4.4-1">This header field MAY be present in a RECORD-COMPLETE event
          coming from the recorder resource to the client. It contains the
          reason text behind the RECORD request completion. This header field
          communicates text describing the reason for the failure.</p>
<p id="section-10.4.4-2">The completion reason text is provided for client use in logs and
          for debugging and instrumentation purposes. Clients MUST NOT
          interpret the completion reason text.</p>
<div id="section-10.4.4-3" class="artwork art-text" text-align="left"><pre>
completion-reason        =  "Completion-Reason" ":"
                            quoted-string CRLF
                        </pre></div></section><section id="section-10.4.5"><h4 id="name-failed-uri-3">
<a href="#section-10.4.5" class="section-number selfRef">10.4.5.Â </a><a href="#name-failed-uri-3" class="section-name selfRef">Failed-URI</a>
</h4>
<p id="section-10.4.5-1">When a recorder method needs to post the audio to a URI and
          access to the URI fails, the server MUST provide the failed URI in
          this header field in the method response.</p>
<div id="section-10.4.5-2" class="artwork art-text" text-align="left"><pre>
failed-uri               =  "Failed-URI" ":" absoluteURI CRLF
            </pre></div></section><section id="section-10.4.6"><h4 id="name-failed-uri-cause-3">
<a href="#section-10.4.6" class="section-number selfRef">10.4.6.Â </a><a href="#name-failed-uri-cause-3" class="section-name selfRef">Failed-URI-Cause</a>
</h4>
<p id="section-10.4.6-1">When a recorder method needs to post the audio to a URI and
          access to the URI fails, the server MAY provide the URI-specific or
          protocol-specific response code through this header field in the
          method response. The value encoding is UTF-8 (<span>[<a href="#RFC3629" class="xref">RFC 3629</a>]) to accommodate any access
          protocol --
          some access protocols might have a response string instead of a numeric
          response code.</span></p>
<div id="section-10.4.6-2" class="artwork art-text" text-align="left"><pre>
failed-uri-cause         =  "Failed-URI-Cause" ":" 1*UTFCHAR 
                            CRLF
            </pre></div></section><section id="section-10.4.7"><div id="sec.recordURI">
<h4 id="name-record-uri">
<a href="#section-10.4.7" class="section-number selfRef">10.4.7.Â </a><a href="#name-record-uri" class="section-name selfRef">Record-URI</a>
</h4>
<p id="section-10.4.7-1">When a recorder method contains this header field, the server MUST
          capture the audio and store it. If the header field is present but
          specified with no value, the server MUST store the content locally
          and generate a URI that points to it. This URI is then returned in
          either the STOP response or the RECORD-COMPLETE event. If the header
          field in the RECORD method specifies a URI, the server MUST attempt
          to capture and store the audio at that location. If this header
          field is not specified in the RECORD request, the server MUST
          capture the audio, MUST encode it, and MUST send it in the STOP
          response or the RECORD-COMPLETE event as a message body. In this
          case, the response carrying the audio content MUST include a <span>[<a href="#RFC2392" class="xref">Content ID (cid)</a>] value in this header
          pointing to the Content-ID in the message body.</span></p>
<p id="section-10.4.7-2">The server MUST also return the size in octets and the duration
          in milliseconds of the recorded audio waveform as parameters
          associated with the header field.</p>
<p id="section-10.4.7-3">Implementations MUST support <span>[<a href="#RFC2616" class="xref">'http'</a>], </span><span>[<a href="#RFC2818" class="xref">'https'</a>], </span><span>[<a href="#RFC3986" class="xref">'file'</a>], and </span><span>[<a href="#RFC2392" class="xref">'cid'</a>] schemes in the URI. Note that
          implementations already exist that support other schemes.</span></p>
<div id="section-10.4.7-4" class="artwork art-text" text-align="left"><pre>
record-uri               =  "Record-URI" ":" ["&lt;" uri "&gt;" 
                            ";" "size" "=" 1*19DIGIT 
                            ";" "duration" "=" 1*19DIGIT] CRLF
            </pre></div>
</div></section><section id="section-10.4.8"><h4 id="name-media-type-2">
<a href="#section-10.4.8" class="section-number selfRef">10.4.8.Â </a><a href="#name-media-type-2" class="section-name selfRef">Media-Type</a>
</h4>
<p id="section-10.4.8-1">A RECORD method MUST contain this header field, which specifies
          to the server the media type of the captured audio or video.</p>
<div id="section-10.4.8-2" class="artwork art-text" text-align="left"><pre>
media-type               =  "Media-Type" ":" media-type-value 
                            CRLF
            </pre></div></section><section id="section-10.4.9"><h4 id="name-max-time">
<a href="#section-10.4.9" class="section-number selfRef">10.4.9.Â </a><a href="#name-max-time" class="section-name selfRef">Max-Time</a>
</h4>
<p id="section-10.4.9-1">When recording is started, this specifies the maximum length of
          the recording in milliseconds, calculated from the time the actual
          capture and store begins and is not necessarily the time the RECORD
          method is received. It specifies the duration before silence
          suppression, if any, has been applied by the recorder resource.
          After this time, the recording stops and the server MUST return a
          RECORD-COMPLETE event to the client having a request-state of
          COMPLETE. This header field MAY occur in RECORD, SET-PARAMS, or
          GET-PARAMS. The value for this header field ranges from 0 to an
          implementation-specific maximum value. A value of 0 means
          infinity, and hence the recording continues until one or more of the
          other stop conditions are met. The default value for this header
          field is 0.</p>
<div id="section-10.4.9-2" class="artwork art-text" text-align="left"><pre>
max-time                 =  "Max-Time" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-10.4.10"><h4 id="name-trim-length">
<a href="#section-10.4.10" class="section-number selfRef">10.4.10.Â </a><a href="#name-trim-length" class="section-name selfRef">Trim-Length</a>
</h4>
<p id="section-10.4.10-1">This header field MAY be sent on a STOP method and specifies the
          length of audio to be trimmed from the end of the recording after
          the stop. The length is interpreted to be in milliseconds. The
          default value for this header field is 0.</p>
<div id="section-10.4.10-2" class="artwork art-text" text-align="left"><pre>
trim-length                 =  "Trim-Length" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-10.4.11"><h4 id="name-final-silence">
<a href="#section-10.4.11" class="section-number selfRef">10.4.11.Â </a><a href="#name-final-silence" class="section-name selfRef">Final-Silence</a>
</h4>
<p id="section-10.4.11-1">When the recorder is started and the actual capture begins, this
          header field specifies the length of silence in the audio that is to
          be interpreted as the end of the recording. This header field MAY
          occur in RECORD, SET-PARAMS, or GET-PARAMS. The value for this header
          field ranges from 0 to an implementation-specific maximum value and
          is interpreted to be in milliseconds. A value of 0 means infinity,
          and hence the recording will continue until one of the other stop
          conditions are met. The default value for this header field is
          implementation specific.</p>
<div id="section-10.4.11-2" class="artwork art-text" text-align="left"><pre>
final-silence            =  "Final-Silence" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-10.4.12"><h4 id="name-capture-on-speech">
<a href="#section-10.4.12" class="section-number selfRef">10.4.12.Â </a><a href="#name-capture-on-speech" class="section-name selfRef">Capture-On-Speech</a>
</h4>
<p id="section-10.4.12-1">If "false", the recorder MUST start capturing immediately when
          started. If "true", the recorder MUST wait for the endpointing
          functionality to detect speech before it starts capturing. This
          header field MAY occur in the RECORD, SET-PARAMS, or GET-PARAMS. The
          value for this header field is a Boolean. The default value for this
          header field is "false".</p>
<div id="section-10.4.12-2" class="artwork art-text" text-align="left"><pre>
capture-on-speech        =  "Capture-On-Speech " ":" BOOLEAN CRLF
            </pre></div></section><section id="section-10.4.13"><h4 id="name-ver-buffer-utterance-2">
<a href="#section-10.4.13" class="section-number selfRef">10.4.13.Â </a><a href="#name-ver-buffer-utterance-2" class="section-name selfRef">Ver-Buffer-Utterance</a>
</h4>
<p id="section-10.4.13-1">This header field is the same as the one described for the
          verifier resource (see <a href="#sec.verBufferUtterance" class="xref">Section 11.4.14</a>). This tells the server to
          buffer the utterance associated with this recording request into the
          verification buffer. Sending this header field is permitted only if
          the verification buffer is for the session. This buffer is shared
          across resources within a session. It gets instantiated when a
          verifier resource is added to this session and is released when the
          verifier resource is released from the session.</p></section><section id="section-10.4.14"><h4 id="name-start-input-timers-3">
<a href="#section-10.4.14" class="section-number selfRef">10.4.14.Â </a><a href="#name-start-input-timers-3" class="section-name selfRef">Start-Input-Timers</a>
</h4>
<p id="section-10.4.14-1">This header field MAY be sent as part of the RECORD request. A
          value of "false" tells the recorder resource to start the operation,
          but not to start the no-input timer until the client sends a
          START-INPUT-TIMERS request to the recorder resource. This is useful
          in the scenario when the recorder and synthesizer resources are not
          part of the same session. When a kill-on-barge-in prompt is being
          played, the client may want the RECORD request to be simultaneously
          active so that it can detect and implement kill-on-barge-in (see
          <a href="#sec.kill-on-barge-in" class="xref">Section 8.4.2</a>). But at the same time,
          the client doesn't want the recorder resource to start the no-input
          timers until the prompt is finished. The default value is
          "true".</p>
<div id="section-10.4.14-2" class="artwork art-text" text-align="left"><pre>
start-input-timers       =  "Start-Input-Timers" ":"
                            BOOLEAN CRLF
                        </pre></div></section><section id="section-10.4.15"><h4 id="name-new-audio-channel-2">
<a href="#section-10.4.15" class="section-number selfRef">10.4.15.Â </a><a href="#name-new-audio-channel-2" class="section-name selfRef">New-Audio-Channel</a>
</h4>
<p id="section-10.4.15-1">This header field is the same as the one described for the
          recognizer resource (see <a href="#sec.newAudioChannel" class="xref">Section 9.4.23</a>).</p></section></section><section id="section-10.5"><h3 id="name-recorder-message-body">
<a href="#section-10.5" class="section-number selfRef">10.5.Â </a><a href="#name-recorder-message-body" class="section-name selfRef">Recorder Message Body</a>
</h3>
<p id="section-10.5-1">If the RECORD request did not have a Record-URI header field, the
        STOP response or the RECORD-COMPLETE event MUST contain a message body
        carrying the captured audio. In this case, the message carrying the
        audio content has a Record-URI header field with a Content ID value
        pointing to the message body entity that contains the recorded audio.
        See <a href="#sec.recordURI" class="xref">Section 10.4.7</a> for details.</p></section><section id="section-10.6"><h3 id="name-record">
<a href="#section-10.6" class="section-number selfRef">10.6.Â </a><a href="#name-record" class="section-name selfRef">RECORD</a>
</h3>
<p id="section-10.6-1">The RECORD request places the recorder resource in the recording
        state. Depending on the header fields specified in the RECORD method,
        the resource may start recording the audio immediately or wait for the
        endpointing functionality to detect speech in the audio. The audio is
        then made available to the client either in the message body or as
        specified by Record-URI.</p>
<p id="section-10.6-2">The server MUST support the 'https' URI scheme and MAY support
        other schemes. Note that, due to the sensitive nature of voice
        recordings, any protocols used for dereferencing SHOULD employ
        integrity and confidentiality, unless other means, such as use of a
        controlled environment (see <a href="#sec.resourceControl" class="xref">Section 4.2</a>), are employed.</p>
<p id="section-10.6-3">If a RECORD operation is already in progress, invoking this method
        causes the server to issue a response having a status-code of 402
        "Method not valid in this state" and a request-state of COMPLETE.</p>
<p id="section-10.6-4">If the Record-URI is not valid, a status-code of 404 "Illegal
        Value for Header Field" is returned in the response. If it is
        impossible for the server to create the requested stored content, a
        status-code of 407 "Method or Operation Failed" is returned.</p>
<p id="section-10.6-5">If the type specified in the Media-Type header field is not
        supported, the server MUST respond with a status-code of 409
        "Unsupported Header Field Value" with the Media-Type header field in
        its response.</p>
<p id="section-10.6-6">When the recording operation is initiated, the response indicates
        an IN-PROGRESS request state. The server MAY generate a subsequent
        START-OF-INPUT event when speech is detected. Upon completion of the
        recording operation, the server generates a RECORD-COMPLETE event.</p>
<figure id="figure-27"><div><div id="section-10.6-7" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... RECORD 543257
       Channel-Identifier:32AECB23433802@recorder
       Record-URI:&lt;file://mediaserver/recordings/myfile.wav&gt;  
       Media-Type:audio/wav
       Capture-On-Speech:true
       Final-Silence:300
       Max-Time:6000
           
S-&gt;C:  MRCP/2.0 ... 543257 200 IN-PROGRESS 
       Channel-Identifier:32AECB23433802@recorder           

S-&gt;C:  MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS 
       Channel-Identifier:32AECB23433802@recorder           
            
S-&gt;C:  MRCP/2.0 ... RECORD-COMPLETE 543257 COMPLETE 
       Channel-Identifier:32AECB23433802@recorder          
       Completion-Cause:000 success-silence
       Record-URI:&lt;file://mediaserver/recordings/myfile.wav&gt;;
                  size=242552;duration=25645
</pre></div></div>
<figcaption><a href="#figure-27">Figure 27</a><a href="#name-record-example" id="name-record-example" class="selfRef">RECORD Example</a></figcaption></figure></section><section id="section-10.7"><h3 id="name-stop-3">
<a href="#section-10.7" class="section-number selfRef">10.7.Â </a><a href="#name-stop-3" class="section-name selfRef">STOP</a>
</h3>
<p id="section-10.7-1">The STOP method moves the recorder from the recording state back to
        the idle state. If a RECORD request is active and the STOP request
        successfully terminates it, then the STOP response MUST contain an
        Active-Request-Id-List header field containing the RECORD request-id
        that was terminated. In this case, no RECORD-COMPLETE event is sent
        for the terminated request. If there was no recording active, then the
        response MUST NOT contain an Active-Request-Id-List header field. If
        the recording was a success, the STOP response MUST contain a
        Record-URI header field pointing to the recorded audio content or to
        a typed entity in the body of the STOP response containing the
        recorded audio. The STOP method MAY have a Trim-Length header field,
        in which case the specified length of audio is trimmed from the end of
        the recording after the stop. In any case, the response MUST contain a
        status-code of 200 "Success".</p>
<figure id="figure-28"><div><div id="section-10.7-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... RECORD 543257
       Channel-Identifier:32AECB23433802@recorder
       Record-URI:&lt;file://mediaserver/recordings/myfile.wav&gt;  
       Capture-On-Speech:true
       Final-Silence:300
       Max-Time:6000
           
S-&gt;C:  MRCP/2.0 ... 543257 200 IN-PROGRESS 
       Channel-Identifier:32AECB23433802@recorder           

S-&gt;C:  MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS 
       Channel-Identifier:32AECB23433802@recorder           
            
C-&gt;S:  MRCP/2.0 ... STOP 543257
       Channel-Identifier:32AECB23433802@recorder           
       Trim-Length:200
           
S-&gt;C:  MRCP/2.0 ... 543257 200 COMPLETE 
       Channel-Identifier:32AECB23433802@recorder           
       Record-URI:&lt;file://mediaserver/recordings/myfile.wav&gt;;
                  size=324253;duration=24561
       Active-Request-Id-List:543257
</pre></div></div>
<figcaption><a href="#figure-28">Figure 28</a><a href="#name-stop-example-2" id="name-stop-example-2" class="selfRef">STOP Example</a></figcaption></figure></section><section id="section-10.8"><h3 id="name-record-complete">
<a href="#section-10.8" class="section-number selfRef">10.8.Â </a><a href="#name-record-complete" class="section-name selfRef">RECORD-COMPLETE</a>
</h3>
<p id="section-10.8-1">If the recording completes due to no input, silence after speech,
        or reaching the max-time, the server MUST generate the RECORD-COMPLETE event to the
        client with a request-state of COMPLETE. If the recording was a
        success, the RECORD-COMPLETE event contains a Record-URI header field
        pointing to the recorded audio file on the server or to a typed entity
        in the message body containing the recorded audio.</p>
<figure id="figure-29"><div><div id="section-10.8-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... RECORD 543257
       Channel-Identifier:32AECB23433802@recorder
       Record-URI:&lt;file://mediaserver/recordings/myfile.wav&gt;  
       Capture-On-Speech:true
       Final-Silence:300
       Max-Time:6000
           
S-&gt;C:  MRCP/2.0 ... 543257 200 IN-PROGRESS 
       Channel-Identifier:32AECB23433802@recorder           

S-&gt;C:  MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS 
       Channel-Identifier:32AECB23433802@recorder           
            
S-&gt;C:  MRCP/2.0 ... RECORD-COMPLETE 543257 COMPLETE 
       Channel-Identifier:32AECB23433802@recorder           
       Completion-Cause:000 success
       Record-URI:&lt;file://mediaserver/recordings/myfile.wav&gt;;
                  size=325325;duration=24652
</pre></div></div>
<figcaption><a href="#figure-29">Figure 29</a><a href="#name-record-complete-example" id="name-record-complete-example" class="selfRef">RECORD-COMPLETE Example</a></figcaption></figure></section><section id="section-10.9"><h3 id="name-start-input-timers-4">
<a href="#section-10.9" class="section-number selfRef">10.9.Â </a><a href="#name-start-input-timers-4" class="section-name selfRef">START-INPUT-TIMERS</a>
</h3>
<p id="section-10.9-1">This request is sent from the client to the recorder resource when
        it discovers that a kill-on-barge-in prompt has finished playing (see
        <a href="#sec.kill-on-barge-in" class="xref">Section 8.4.2</a>). This is useful in the
        scenario when the recorder and synthesizer resources are not in the
        same MRCPv2 session. When a kill-on-barge-in prompt is being played,
        the client wants the RECORD request to be simultaneously active so
        that it can detect and implement kill-on-barge-in. But at the same
        time, the client doesn't want the recorder resource to start the
        no-input timers until the prompt is finished. The Start-Input-Timers
        header field in the RECORD request allows the client to say if the
        timers should be started or not. In the above case, the recorder
        resource does not start the timers until the client sends a
        START-INPUT-TIMERS method to the recorder.</p></section><section id="section-10.10"><h3 id="name-start-of-input-2">
<a href="#section-10.10" class="section-number selfRef">10.10.Â </a><a href="#name-start-of-input-2" class="section-name selfRef">START-OF-INPUT</a>
</h3>
<p id="section-10.10-1">The START-OF-INPUT event is returned from the server to the client
        once the server has detected speech. This event is always returned by
        the recorder resource when speech has been detected. The recorder
        resource also MUST send a Proxy-Sync-Id header field with a unique
        value for this event.</p>
<div id="section-10.10-2" class="artwork art-text" text-align="left"><pre>
S-&gt;C:  MRCP/2.0 ... START-OF-INPUT 543259 IN-PROGRESS
       Channel-Identifier:32AECB23433801@recorder
       Proxy-Sync-Id:987654321
</pre></div></section>
</div></section><section id="section-11"><div id="sec.verifierResource">
<h2 id="name-speaker-verification-and-id">
<a href="#section-11" class="section-number selfRef">11.Â </a><a href="#name-speaker-verification-and-id" class="section-name selfRef">Speaker Verification and Identification</a>
</h2>
<p id="section-11-1">This section describes the methods, responses and events employed by
      MRCPv2 for doing speaker verification/identification.</p>
<p id="section-11-2">Speaker verification is a voice authentication methodology
      that can be used to identify the speaker in order to grant the
      user access to sensitive information and transactions. Because
      speech is a biometric, a number of essential security
      considerations related to biometric authentication technologies
      apply to its implementation and usage.  Implementers should
      carefully read <a href="#sec.securityConsiderations" class="xref">Section 12</a>
      in this document and the corresponding section
      of <span>[<a href="#RFC4313" class="xref">the SPEECHSC requirements</a>].
      Implementers and deployers of this technology are strongly
      encouraged to check the state of the art for any new risks and
      solutions that might have been developed.</span></p>
<p id="section-11-3">In speaker verification, a recorded utterance is compared to a
      previously stored voiceprint, which is in turn associated with a claimed
      identity for that user. Verification typically consists of two phases: a
      designation phase to establish the claimed identity of the caller and an
      execution phase in which a voiceprint is either created (training) or
      used to authenticate the claimed identity (verification).</p>
<p id="section-11-4">Speaker identification is the process of associating an unknown
      speaker with a member in a population. It does not employ a claim of
      identity. When an individual claims to belong to a group (e.g., one of
      the owners of a joint bank account) a group authentication is performed.
      This is generally implemented as a kind of verification involving
      comparison with more than one voice model. It is sometimes called
      'multi-verification'. If the individual speaker can be identified from
      the group, this may be useful for applications where multiple users
      share the same access privileges to some data or application. Speaker
      identification and group authentication are also done in two phases, a
      designation phase and an execution phase. Note that, from a functionality
      standpoint, identification can be thought of as a special case of group
      authentication (if the individual is identified) where the group is the
      entire population, although the implementation of speaker identification
      may be different from the way group authentication is performed. To
      accommodate single-voiceprint verification, verification against
      multiple voiceprints, group authentication, and identification, this
      specification provides a single set of methods that can take a list of
      identifiers, called "voiceprint identifiers", and return a
      list of identifiers, with a score for each that represents how well the
      input speech matched each identifier. The input and output lists of
      identifiers do not have to match, allowing a vendor-specific group
      identifier to be used as input to indicate that identification is to be
      performed. In this specification, the terms "identification"
      and "multi-verification" are used to indicate that the input
      represents a group (potentially the entire population) and that results
      for multiple voiceprints may be returned.</p>
<p id="section-11-5">It is possible for a verifier resource to share the same session with
      a recognizer resource or to operate independently. In order to share the
      same session, the verifier and recognizer resources MUST be allocated
      from within the same SIP dialog. Otherwise, an independent verifier
      resource, running on the same physical server or a separate one, will be
      set up. Note that, in addition to allowing both resources to be allocated
      in the same INVITE, it is possible to allocate one initially and the
      other later via a re-INVITE.</p>
<p id="section-11-6">Some of the speaker verification methods, described below, apply only
      to a specific mode of operation.</p>
<p id="section-11-7">The verifier resource has a verification buffer associated with it
      (see <a href="#sec.verBufferUtterance" class="xref">Section 11.4.14</a>). This allows the
      storage of speech utterances for the purposes of verification,
      identification, or training from the buffered speech. This buffer is
      owned by the verifier resource, but other input resources (such as the
      recognizer resource or recorder resource) may write to it. This allows
      the speech received as part of a recognition or recording operation to
      be later used for verification, identification, or training. Access to
      the buffer is limited to one operation at time. Hence, when the resource
      is doing read, write, or delete operations, such as a RECOGNIZE with
      verâ€‘bufferâ€‘utterance turned on, another operation involving the buffer
      fails with a status-code of 402. The verification buffer can be cleared
      by a CLEAR-BUFFER request from the client and is freed when the verifier
      resource is deallocated or the session with the server terminates.</p>
<p id="section-11-8">The verification buffer is different from collecting waveforms and
      processing them using either the real-time audio stream or stored audio,
      because this buffering mechanism does not simply accumulate speech to a
      buffer. The verification buffer MAY contain additional information
      gathered by the recognizer resource that serves to improve verification
      performance.</p>
<section id="section-11.1"><h3 id="name-speaker-verification-state-">
<a href="#section-11.1" class="section-number selfRef">11.1.Â </a><a href="#name-speaker-verification-state-" class="section-name selfRef">Speaker Verification State Machine</a>
</h3>
<p id="section-11.1-1">Speaker verification may operate in a training or a verification
        session. Starting one of these sessions does not change the state of
        the verifier resource, i.e., it remains idle. Once a verification or
        training session is started, then utterances are trained or verified
        by calling the VERIFY or VERIFY-FROM-BUFFER method. The state of the
        verifier resources goes from IDLE to VERIFYING state each time VERIFY
        or VERIFY-FROM-BUFFER is called.</p>
<figure id="figure-30"><div><div id="section-11.1-2" class="artwork art-text" text-align="left"><pre>
  Idle              Session Opened       Verifying/Training
  State             State                State
   |                   |                         |
   |--START-SESSION---&gt;|                         |
   |                   |                         |
   |                   |----------|              |
   |                   |     START-SESSION       |
   |                   |&lt;---------|              |
   |                   |                         |
   |&lt;--END-SESSION-----|                         |
   |                   |                         |
   |                   |---------VERIFY---------&gt;|
   |                   |                         |
   |                   |---VERIFY-FROM-BUFFER---&gt;|
   |                   |                         |
   |                   |----------|              |
   |                   |  VERIFY-ROLLBACK        |
   |                   |&lt;---------|              |
   |                   |                         |
   |                   |                |--------|
   |                   | GET-INTERMEDIATE-RESULT |
   |                   |                |-------&gt;|
   |                   |                         |
   |                   |                |--------|
   |                   |     START-INPUT-TIMERS  |
   |                   |                |-------&gt;|
   |                   |                         |
   |                   |                |--------|
   |                   |         START-OF-INPUT  |
   |                   |                |-------&gt;|
   |                   |                         |
   |                   |&lt;-VERIFICATION-COMPLETE--|
   |                   |                         |
   |                   |&lt;--------STOP------------|
   |                   |                         |
   |                   |----------|              |
   |                   |         STOP            |
   |                   |&lt;---------|              |
   |                   |                         |
   |----------|        |                         |
   |         STOP      |                         |    
   |&lt;---------|        |                         |
   |                   |----------|              |
   |                   |    CLEAR-BUFFER         |
   |                   |&lt;---------|              |
   |                   |                         |
   |----------|        |                         |
   |   CLEAR-BUFFER    |                         |    
   |&lt;---------|        |                         |
   |                   |                         |
   |                   |----------|              |
   |                   |   QUERY-VOICEPRINT      |
   |                   |&lt;---------|              |
   |                   |                         |
   |----------|        |                         |
   | QUERY-VOICEPRINT  |                         |
   |&lt;---------|        |                         |
   |                   |                         |
   |                   |----------|              |
   |                   |  DELETE-VOICEPRINT      |
   |                   |&lt;---------|              |
   |                   |                         |
   |----------|        |                         |
   | DELETE-VOICEPRINT |                         |
   |&lt;---------|        |                         |
</pre></div></div>
<figcaption><a href="#figure-30">Figure 30</a><a href="#name-verifier-resource-state-mac" id="name-verifier-resource-state-mac" class="selfRef">Verifier Resource State Machine</a></figcaption></figure></section><section id="section-11.2"><h3 id="name-speaker-verification-method">
<a href="#section-11.2" class="section-number selfRef">11.2.Â </a><a href="#name-speaker-verification-method" class="section-name selfRef">Speaker Verification Methods</a>
</h3>
<p id="section-11.2-1">The verifier resource supports the following methods.</p>
<div id="section-11.2-2" class="artwork art-text" text-align="left"><pre>
verifier-method          =  "START-SESSION"
                         / "END-SESSION"
                         / "QUERY-VOICEPRINT"
                         / "DELETE-VOICEPRINT"
                         / "VERIFY"
                         / "VERIFY-FROM-BUFFER"
                         / "VERIFY-ROLLBACK"
                         / "STOP"
                         / "CLEAR-BUFFER"
                         / "START-INPUT-TIMERS"
                         / "GET-INTERMEDIATE-RESULT"
                        </pre></div>
<p id="section-11.2-3">These methods allow the client to control the mode and target of
        verification or identification operations within the context of a
        session. All the verification input operations that occur within a
        session can be used to create, update, or validate against the
        voiceprint specified during the session. At the beginning of each
        session, the verifier resource is reset to the state it had prior to
        any previous verification session.</p>
<p id="section-11.2-4">Verification/identification operations can be executed against live
        or buffered audio. The verifier resource provides methods for
        collecting and evaluating live audio data, and methods for controlling
        the verifier resource and adjusting its configured behavior.</p>
<p id="section-11.2-5">There are no dedicated methods for collecting buffered audio data.
        This is accomplished by calling VERIFY, RECOGNIZE, or RECORD as
        appropriate for the resource, with the header field
        Verâ€‘Bufferâ€‘Utterance. Then, when the following method is called,
        verification is performed using the set of buffered audio. </p>
<ol id="section-11.2-6"><li id="section-11.2-7">VERIFY-FROM-BUFFER</li></ol>
<p id="section-11.2-8">The following methods are used for verification of live audio
        utterances: </p>
<ol id="section-11.2-9">
<li id="section-11.2-10">VERIFY</li>
<li id="section-11.2-11">START-INPUT-TIMERS</li>
</ol>
<p id="section-11.2-12">The following methods are used for configuring the verifier
        resource and for establishing resource states: </p>
<ol id="section-11.2-13">
<li id="section-11.2-14">START-SESSION</li>
<li id="section-11.2-15">END-SESSION</li>
<li id="section-11.2-16">QUERY-VOICEPRINT</li>
<li id="section-11.2-17">DELETE-VOICEPRINT</li>
<li id="section-11.2-18">VERIFY-ROLLBACK</li>
<li id="section-11.2-19">STOP</li>
<li id="section-11.2-20">CLEAR-BUFFER</li>
</ol>
<p id="section-11.2-21">The following method allows the polling of a verification in progress
        for intermediate results. </p>
<ol id="section-11.2-22"><li id="section-11.2-23">GET-INTERMEDIATE-RESULT</li></ol></section><section id="section-11.3"><h3 id="name-verification-events">
<a href="#section-11.3" class="section-number selfRef">11.3.Â </a><a href="#name-verification-events" class="section-name selfRef">Verification Events</a>
</h3>
<p id="section-11.3-1">The verifier resource generates the following events.</p>
<div id="section-11.3-2" class="artwork art-text" text-align="left"><pre>
verifier-event       =  "VERIFICATION-COMPLETE"
                     /  "START-OF-INPUT"
                        </pre></div></section><section id="section-11.4"><h3 id="name-verification-header-fields">
<a href="#section-11.4" class="section-number selfRef">11.4.Â </a><a href="#name-verification-header-fields" class="section-name selfRef">Verification Header Fields</a>
</h3>
<p id="section-11.4-1">A verifier resource message can contain header fields containing
        request options and information to augment the Request, Response, or
        Event message it is associated with.</p>
<div id="section-11.4-2" class="artwork art-text" text-align="left"><pre>
verification-header      =  repository-uri
                         /  voiceprint-identifier
                         /  verification-mode
                         /  adapt-model
                         /  abort-model
                         /  min-verification-score
                         /  num-min-verification-phrases
                         /  num-max-verification-phrases
                         /  no-input-timeout
                         /  save-waveform
                         /  media-type
                         /  waveform-uri
                         /  voiceprint-exists
                         /  ver-buffer-utterance
                         /  input-waveform-uri
                         /  completion-cause
                         /  completion-reason
                         /  speech-complete-timeout
                         /  new-audio-channel
                         /  abort-verification
                         /  start-input-timers
          </pre></div>
<section id="section-11.4.1"><div id="sec.repositoryURI">
<h4 id="name-repository-uri">
<a href="#section-11.4.1" class="section-number selfRef">11.4.1.Â </a><a href="#name-repository-uri" class="section-name selfRef">Repository-URI</a>
</h4>
<p id="section-11.4.1-1">This header field specifies the voiceprint repository to be used
          or referenced during speaker verification or identification
          operations. This header field is required in the START-SESSION,
          QUERY-VOICEPRINT, and DELETE-VOICEPRINT methods.</p>
<div id="section-11.4.1-2" class="artwork art-text" text-align="left"><pre>
repository-uri           =  "Repository-URI" ":" uri CRLF
           </pre></div>
</div></section><section id="section-11.4.2"><h4 id="name-voiceprint-identifier">
<a href="#section-11.4.2" class="section-number selfRef">11.4.2.Â </a><a href="#name-voiceprint-identifier" class="section-name selfRef">Voiceprint-Identifier</a>
</h4>
<p id="section-11.4.2-1">This header field specifies the claimed identity for verification
          applications. The claimed identity MAY be used to specify an
          existing voiceprint or to establish a new voiceprint. This header
          field MUST be present in the QUERY-VOICEPRINT and DELETE-VOICEPRINT
          methods. The Voiceprint-Identifier MUST be present in the
          START-SESSION method for verification operations. For identification
          or multi-verification operations, this header field MAY contain a
          list of voiceprint identifiers separated by semicolons. For
          identification operations, the client MAY also specify a voiceprint
          group identifier instead of a list of voiceprint identifiers.</p>
<div id="section-11.4.2-2" class="artwork art-text" text-align="left"><pre>
voiceprint-identifier        =  "Voiceprint-Identifier" ":" 
                                vid *[";" vid] CRLF
vid                          =  1*VCHAR ["." 1*VCHAR]
                            </pre></div></section><section id="section-11.4.3"><h4 id="name-verification-mode">
<a href="#section-11.4.3" class="section-number selfRef">11.4.3.Â </a><a href="#name-verification-mode" class="section-name selfRef">Verification-Mode</a>
</h4>
<p id="section-11.4.3-1">This header field specifies the mode of the verifier resource and
          is set by the START-SESSION method. Acceptable values indicate
          whether the verification session will train a voiceprint ("train")
          or verify/identify using an existing voiceprint ("verify").</p>
<p id="section-11.4.3-2">Training and verification sessions both require the voiceprint
          Repository-URI to be specified in the START-SESSION. In many usage
          scenarios, however, the system does not know the speaker's claimed
          identity until a recognition operation has, for example, recognized
          an account number to which the user desires access. In order to
          allow the first few utterances of a dialog to be both recognized and
          verified, the verifier resource on the MRCPv2 server retains a
          buffer. In this buffer, the MRCPv2 server accumulates recognized
          utterances. The client can later execute a verification method and
          apply the buffered utterances to the current verification
          session.</p>
<p id="section-11.4.3-3">Some voice user interfaces may require additional user input that
          should not be subject to verification. For example, the user's input
          may have been recognized with low confidence and thus require a
          confirmation cycle. In such cases, the client SHOULD NOT execute the
          VERIFY or VERIFY-FROM-BUFFER methods to collect and analyze the
          caller's input. A separate recognizer resource can analyze the
          caller's response without any participation by the verifier
          resource.</p>
<p id="section-11.4.3-4">Once the following conditions have been met: </p>
<ol id="section-11.4.3-5">
<li id="section-11.4.3-6">the voiceprint identity has been successfully established through
              the Voiceprint-Identifier header fields of the START-SESSION
              method, and</li>
<li id="section-11.4.3-7">the verification mode has been set to one of "train" or
              "verify",</li>
</ol>
<p id="section-11.4.3-8">the verifier resource can begin providing verification
          information during verification operations. If the verifier resource
          does not reach one of the two major states ("train" or "verify") ,
          it MUST report an error condition in the MRCPv2 status code to
          indicate why the verifier resource is not ready for the
          corresponding usage.</p>
<p id="section-11.4.3-9">The value of verification-mode is persistent within a
          verification session. If the client attempts to change the mode
          during a verification session, the verifier resource reports an
          error and the mode retains its current value.</p>
<div id="section-11.4.3-10" class="artwork art-text" text-align="left"><pre>
verification-mode            =  "Verification-Mode" ":" 
                                verification-mode-string

verification-mode-string     =  "train"
                             /  "verify"
            </pre></div></section><section id="section-11.4.4"><h4 id="name-adapt-model">
<a href="#section-11.4.4" class="section-number selfRef">11.4.4.Â </a><a href="#name-adapt-model" class="section-name selfRef">Adapt-Model</a>
</h4>
<p id="section-11.4.4-1">This header field indicates the desired behavior of the verifier
          resource after a successful verification operation. If the value of
          this header field is "true", the server SHOULD use audio collected
          during the verification session to update the voiceprint to account
          for ongoing changes in a speaker's incoming speech characteristics,
          unless local policy prohibits updating the voiceprint. If the value
          is "false" (the default), the server MUST NOT update the voiceprint.
          This header field MAY occur in the START-SESSION method.</p>
<div id="section-11.4.4-2" class="artwork art-text" text-align="left"><pre>
adapt-model              = "Adapt-Model" ":" BOOLEAN CRLF
            </pre></div></section><section id="section-11.4.5"><h4 id="name-abort-model">
<a href="#section-11.4.5" class="section-number selfRef">11.4.5.Â </a><a href="#name-abort-model" class="section-name selfRef">Abort-Model</a>
</h4>
<p id="section-11.4.5-1">The Abort-Model header field indicates the desired behavior of
          the verifier resource upon session termination. If the value of this
          header field is "true", the server MUST discard any pending changes
          to a voiceprint due to verification training or verification
          adaptation. If the value is "false" (the default), the server MUST
          commit any pending changes for a training session or a successful
          verification session to the voiceprint repository. A value of "true"
          for Abort-Model overrides a value of "true" for the Adapt-Model
          header field. This header field MAY occur in the END-SESSION
          method.</p>
<div id="section-11.4.5-2" class="artwork art-text" text-align="left"><pre>
abort-model             = "Abort-Model" ":" BOOLEAN CRLF
            </pre></div></section><section id="section-11.4.6"><h4 id="name-min-verification-score">
<a href="#section-11.4.6" class="section-number selfRef">11.4.6.Â </a><a href="#name-min-verification-score" class="section-name selfRef">Min-Verification-Score</a>
</h4>
<p id="section-11.4.6-1">The Min-Verification-Score header field, when used with a
          verifier resource through a SET-PARAMS, GET-PARAMS, or START-SESSION
          method, determines the minimum verification score for which a
          verification decision of "accepted" may be declared by the server.
          This is a float value between -1.0 and 1.0. The default value for
          this header field is implementation specific.</p>
<div id="section-11.4.6-2" class="artwork art-text" text-align="left"><pre>
min-verification-score  = "Min-Verification-Score" ":" 
                          [ %x2D ] FLOAT CRLF
            </pre></div></section><section id="section-11.4.7"><h4 id="name-num-min-verification-phrase">
<a href="#section-11.4.7" class="section-number selfRef">11.4.7.Â </a><a href="#name-num-min-verification-phrase" class="section-name selfRef">Num-Min-Verification-Phrases</a>
</h4>
<p id="section-11.4.7-1">The Num-Min-Verification-Phrases header field is used to specify
          the minimum number of valid utterances before a positive decision is
          given for verification. The value for this header field is an
          integer and the default value is 1. The verifier resource MUST NOT
          declare a verification 'accepted' unless
          Num-Min-Verification-Phrases valid utterances have been received.
          The minimum value is 1. This header field MAY occur in
          START-SESSION, SET-PARAMS, or GET-PARAMS.</p>
<div id="section-11.4.7-2" class="artwork art-text" text-align="left"><pre>
num-min-verification-phrases =  "Num-Min-Verification-Phrases" ":" 
                                1*19DIGIT CRLF
            </pre></div></section><section id="section-11.4.8"><h4 id="name-num-max-verification-phrase">
<a href="#section-11.4.8" class="section-number selfRef">11.4.8.Â </a><a href="#name-num-max-verification-phrase" class="section-name selfRef">Num-Max-Verification-Phrases</a>
</h4>
<p id="section-11.4.8-1">The Num-Max-Verification-Phrases header field is used to specify
          the number of valid utterances required before a decision is forced
          for verification. The verifier resource MUST NOT return a decision
          of 'undecided' once Num-Max-Verification-Phrases have been collected
          and used to determine a verification score. The value for this
          header field is an integer and the minimum value is 1. The default
          value is implementation specific. This header field MAY occur in
          START-SESSION, SET-PARAMS, or GET-PARAMS.</p>
<div id="section-11.4.8-2" class="artwork art-text" text-align="left"><pre>
num-max-verification-phrases =  "Num-Max-Verification-Phrases" ":" 
                                 1*19DIGIT CRLF
            </pre></div></section><section id="section-11.4.9"><h4 id="name-no-input-timeout-3">
<a href="#section-11.4.9" class="section-number selfRef">11.4.9.Â </a><a href="#name-no-input-timeout-3" class="section-name selfRef">No-Input-Timeout</a>
</h4>
<p id="section-11.4.9-1">
   The No-Input-Timeout header field sets the length of time from the
   start of the verification timers (see START-INPUT-TIMERS) until the
   VERIFICATION-COMPLETE server event message declares that no input
   has been received (i.e., has a Completion-Cause of no-input-timeout).

 The value is in milliseconds. This header
          field MAY occur in VERIFY, SET-PARAMS, or GET-PARAMS. The value for
          this header field ranges from 0 to an implementation-specific
          maximum value. The default value for this header field is
          implementation specific.</p>
<div id="section-11.4.9-2" class="artwork art-text" text-align="left"><pre>
no-input-timeout         = "No-Input-Timeout" ":" 1*19DIGIT CRLF
            </pre></div></section><section id="section-11.4.10"><h4 id="name-save-waveform-2">
<a href="#section-11.4.10" class="section-number selfRef">11.4.10.Â </a><a href="#name-save-waveform-2" class="section-name selfRef">Save-Waveform</a>
</h4>
<p id="section-11.4.10-1">This header field allows the client to request that the verifier
          resource save the audio stream that was used for
          verification/identification. The verifier resource MUST attempt to
          record the audio and make it available to the client in the form of
          a URI returned in the Waveform-URI header field in the
          VERIFICATION-COMPLETE event. If there was an error in recording the
          stream, or the audio content is otherwise not available, the verifier
          resource MUST return an empty Waveform-URI header field. The default
          value for this header field is "false". This header field MAY appear
          in the VERIFY method. Note that this header field does not appear in
          the VERIFY-FROM-BUFFER method since it only controls whether or not
          to save the waveform for live verification/identification
          operations.</p>
<div id="section-11.4.10-2" class="artwork art-text" text-align="left"><pre>
save-waveform            =  "Save-Waveform" ":" BOOLEAN CRLF
           </pre></div></section><section id="section-11.4.11"><h4 id="name-media-type-3">
<a href="#section-11.4.11" class="section-number selfRef">11.4.11.Â </a><a href="#name-media-type-3" class="section-name selfRef">Media-Type</a>
</h4>
<p id="section-11.4.11-1">This header field MAY be specified in the SET-PARAMS, GET-PARAMS,
          or the VERIFY methods and tells the server resource the media type
          of the captured audio or video such as the one captured and returned
          by the Waveform-URI header field.</p>
<div id="section-11.4.11-2" class="artwork art-text" text-align="left"><pre>
media-type               =  "Media-Type" ":" media-type-value 
                            CRLF
            </pre></div></section><section id="section-11.4.12"><h4 id="name-waveform-uri-2">
<a href="#section-11.4.12" class="section-number selfRef">11.4.12.Â </a><a href="#name-waveform-uri-2" class="section-name selfRef">Waveform-URI</a>
</h4>
<p id="section-11.4.12-1">If the Save-Waveform header field is set to "true", the verifier
          resource MUST attempt to record the incoming audio stream of the
          verification into a file and provide a URI for the client to access
          it. This header field MUST be present in the VERIFICATION-COMPLETE
          event if the Save-Waveform header field was set to true by the
          client. The value of the header field MUST be empty if there was
          some error condition preventing the server from recording.
          Otherwise, the URI generated by the server MUST be globally unique
          across the server and all its verification sessions. The content
          MUST be available via the URI until the verification session ends.
          Since the Save-Waveform header field applies only to live
          verification/identification operations, the server can return the
          Waveform-URI only in the VERIFICATION-COMPLETE event for live
          verification/identification operations.</p>
<p id="section-11.4.12-2">The server MUST also return the size in octets and the duration
          in milliseconds of the recorded audio waveform as parameters
          associated with the header field.</p>
<div id="section-11.4.12-3" class="artwork art-text" text-align="left"><pre>
waveform-uri             =  "Waveform-URI" ":" ["&lt;" uri "&gt;" 
                            ";" "size" "=" 1*19DIGIT 
                            ";" "duration" "=" 1*19DIGIT] CRLF
            </pre></div></section><section id="section-11.4.13"><h4 id="name-voiceprint-exists">
<a href="#section-11.4.13" class="section-number selfRef">11.4.13.Â </a><a href="#name-voiceprint-exists" class="section-name selfRef">Voiceprint-Exists</a>
</h4>
<p id="section-11.4.13-1">This header field MUST be returned in QUERY-VOICEPRINT and
          DELETE-VOICEPRINT responses. This is the status of the voiceprint
          specified in the QUERY-VOICEPRINT method. For the DELETE-VOICEPRINT
          method, this header field indicates the status of the voiceprint at
          the moment the method execution started.</p>
<div id="section-11.4.13-2" class="artwork art-text" text-align="left"><pre>
voiceprint-exists    =  "Voiceprint-Exists" ":" BOOLEAN CRLF
            </pre></div></section><section id="section-11.4.14"><div id="sec.verBufferUtterance">
<h4 id="name-ver-buffer-utterance-3">
<a href="#section-11.4.14" class="section-number selfRef">11.4.14.Â </a><a href="#name-ver-buffer-utterance-3" class="section-name selfRef">Ver-Buffer-Utterance</a>
</h4>
<p id="section-11.4.14-1">This header field is used to indicate that this utterance could
          be later considered for speaker verification. This way, a client can
          request the server to buffer utterances while doing regular
          recognition or verification activities, and speaker verification can
          later be requested on the buffered utterances. This header field is
          optional in the RECOGNIZE, VERIFY, and RECORD methods. The default
          value for this header field is "false".</p>
<div id="section-11.4.14-2" class="artwork art-text" text-align="left"><pre>
ver-buffer-utterance     = "Ver-Buffer-Utterance" ":" BOOLEAN
                           CRLF
            </pre></div>
</div></section><section id="section-11.4.15"><h4 id="name-input-waveform-uri-2">
<a href="#section-11.4.15" class="section-number selfRef">11.4.15.Â </a><a href="#name-input-waveform-uri-2" class="section-name selfRef">Input-Waveform-URI</a>
</h4>
<p id="section-11.4.15-1">This header field specifies stored audio content that the client
          requests the server to fetch and process according to the current
          verification mode, either to train the voiceprint or verify a
          claimed identity. This header field enables the client to implement
          the buffering use case where the recognizer and verifier resources
          are in different sessions and the verification buffer technique
          cannot be used. It MAY be specified on the VERIFY request.</p>
<div id="section-11.4.15-2" class="artwork art-text" text-align="left"><pre>
input-waveform-uri           =  "Input-Waveform-URI" ":" uri CRLF
            </pre></div></section><section id="section-11.4.16"><h4 id="name-completion-cause-4">
<a href="#section-11.4.16" class="section-number selfRef">11.4.16.Â </a><a href="#name-completion-cause-4" class="section-name selfRef">Completion-Cause</a>
</h4>
<p id="section-11.4.16-1">This header field MUST be part of a VERIFICATION-COMPLETE event
          from the verifier resource to the client. This indicates the cause
          of VERIFY or VERIFY-FROM-BUFFER method completion. This header field
          MUST be sent in the VERIFY, VERIFY-FROM-BUFFER, and QUERY-VOICEPRINT
          responses, if they return with a failure status and a COMPLETE
          state. In the ABNF below, the 'cause-code' contains a numerical
          value selected from the Cause-Code column of the following table.
          The 'cause-name' contains the corresponding token selected from the
          Cause-Name column.</p>
<div id="section-11.4.16-2" class="artwork art-text" text-align="left"><pre>
completion-cause         =  "Completion-Cause" ":" cause-code SP
                            cause-name CRLF
cause-code               =  3DIGIT
cause-name               =  *VCHAR
            </pre></div>
<table id="table-8">
<thead><tr>
<th>Cause-Code</th>
<th>Cause-Name</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr>
<td>000</td>
<td>success</td>
<td>VERIFY or VERIFY-FROM-BUFFER request completed successfully.
            The verify decision can be "accepted", "rejected", or
            "undecided".</td>
</tr>
<tr>
<td>001</td>
<td>error</td>
<td>VERIFY or VERIFY-FROM-BUFFER request terminated prematurely due
            to a verifier resource or system error.</td>
</tr>
<tr>
<td>002</td>
<td>no-input-timeout</td>
<td>VERIFY request completed with no result due to a
            no-input-timeout.</td>
</tr>
<tr>
<td>003</td>
<td>too-much-speech-timeout</td>
<td>VERIFY request completed with no result due to too much
            speech.</td>
</tr>
<tr>
<td>004</td>
<td>speech-too-early</td>
<td>VERIFY request completed with no result due to speech too
            soon.</td>
</tr>
<tr>
<td>005</td>
<td>buffer-empty</td>
<td>VERIFY-FROM-BUFFER request completed with no result due to
            empty buffer.</td>
</tr>
<tr>
<td>006</td>
<td>out-of-sequence</td>
<td>Verification operation failed due to out-of-sequence method
            invocations, for example, calling VERIFY before
            QUERY-VOICEPRINT.</td>
</tr>
<tr>
<td>007</td>
<td>repository-uri-failure</td>
<td>Failure accessing Repository URI.</td>
</tr>
<tr>
<td>008</td>
<td>repository-uri-missing</td>
<td>Repository-URI is not specified.</td>
</tr>
<tr>
<td>009</td>
<td>voiceprint-id-missing</td>
<td>Voiceprint-Identifier is not specified.</td>
</tr>
<tr>
<td>010</td>
<td>voiceprint-id-not-exist</td>
<td>Voiceprint-Identifier does not exist in the voiceprint
            repository.</td>
</tr>
<tr>
<td>011</td>
<td>speech-not-usable</td>
<td>VERIFY request completed with no result because the speech was
            not usable (too noisy, too short, etc.)</td>
</tr>
</tbody>
</table></section><section id="section-11.4.17"><h4 id="name-completion-reason-4">
<a href="#section-11.4.17" class="section-number selfRef">11.4.17.Â </a><a href="#name-completion-reason-4" class="section-name selfRef">Completion-Reason</a>
</h4>
<p id="section-11.4.17-1">This header field MAY be specified in a VERIFICATION-COMPLETE
          event coming from the verifier resource to the client. It contains
          the reason text behind the VERIFY request completion. This header
          field communicates text describing the reason for the failure.</p>
<p id="section-11.4.17-2">The completion reason text is provided for client use in logs and
          for debugging and instrumentation purposes. Clients MUST NOT
          interpret the completion reason text.</p>
<div id="section-11.4.17-3" class="artwork art-text" text-align="left"><pre>
completion-reason        =  "Completion-Reason" ":" 
                            quoted-string CRLF
            </pre></div></section><section id="section-11.4.18"><h4 id="name-speech-complete-timeout-2">
<a href="#section-11.4.18" class="section-number selfRef">11.4.18.Â </a><a href="#name-speech-complete-timeout-2" class="section-name selfRef">Speech-Complete-Timeout</a>
</h4>
<p id="section-11.4.18-1">This header field is the same as the one described for the
          Recognizer resource. See <a href="#sec.speechCompleteTimeout" class="xref">Section 9.4.15</a>. This header field MAY
          occur in VERIFY, SET-PARAMS, or GET-PARAMS.</p></section><section id="section-11.4.19"><h4 id="name-new-audio-channel-3">
<a href="#section-11.4.19" class="section-number selfRef">11.4.19.Â </a><a href="#name-new-audio-channel-3" class="section-name selfRef">New-Audio-Channel</a>
</h4>
<p id="section-11.4.19-1">This header field is the same as the one described for the
          Recognizer resource. See <a href="#sec.newAudioChannel" class="xref">Section 9.4.23</a>.
          This header field MAY be specified in a VERIFY request.</p></section><section id="section-11.4.20"><h4 id="name-abort-verification">
<a href="#section-11.4.20" class="section-number selfRef">11.4.20.Â </a><a href="#name-abort-verification" class="section-name selfRef">Abort-Verification</a>
</h4>
<p id="section-11.4.20-1">This header field MUST be sent in a STOP request to indicate
          whether or not to abort a VERIFY method in progress. A value of
          "true" requests the server to discard the results. A value of
          "false" requests the server to return in the STOP response the
          verification results obtained up to the point it received the STOP
          request.</p>
<div id="section-11.4.20-2" class="artwork art-text" text-align="left"><pre>
abort-verification   =  "Abort-Verification " ":" BOOLEAN CRLF
            </pre></div></section><section id="section-11.4.21"><h4 id="name-start-input-timers-5">
<a href="#section-11.4.21" class="section-number selfRef">11.4.21.Â </a><a href="#name-start-input-timers-5" class="section-name selfRef">Start-Input-Timers</a>
</h4>
<p id="section-11.4.21-1">This header field MAY be sent as part of a VERIFY request. A
          value of "false" tells the verifier resource to start the VERIFY
          operation but not to start the no-input timer yet. The verifier
          resource MUST NOT start the timers until the client sends a
          START-INPUT-TIMERS request to the resource. This is useful in the
          scenario when the verifier and synthesizer resources are not part of
          the same session. In this scenario, when a kill-on-barge-in prompt
          is being played, the client may want the VERIFY request to be
          simultaneously active so that it can detect and implement
          kill-on-barge-in (see <a href="#sec.kill-on-barge-in" class="xref">Section 8.4.2</a>).
          But at the same time, the client doesn't want the verifier resource
          to start the no-input timers until the prompt is finished. The
          default value is "true".</p>
<div id="section-11.4.21-2" class="artwork art-text" text-align="left"><pre>
start-input-timers       =  "Start-Input-Timers" ":"
                            BOOLEAN CRLF
            </pre></div></section></section><section id="section-11.5"><h3 id="name-verification-message-body">
<a href="#section-11.5" class="section-number selfRef">11.5.Â </a><a href="#name-verification-message-body" class="section-name selfRef">Verification Message Body</a>
</h3>
<p id="section-11.5-1">A verification response or event message can carry additional data
        as described in the following subsection.</p>
<section id="section-11.5.1"><h4 id="name-verification-result-data">
<a href="#section-11.5.1" class="section-number selfRef">11.5.1.Â </a><a href="#name-verification-result-data" class="section-name selfRef">Verification Result Data</a>
</h4>
<p id="section-11.5.1-1">Verification results are returned to the client in the message
          body of the VERIFICATION-COMPLETE event or the
          GET-INTERMEDIATE-RESULT response message as described in <a href="#sec.result" class="xref">Section 6.3</a>. Element and attribute descriptions for
          the verification portion of the NLSML format are provided in <a href="#sec.verificationResults" class="xref">Section 11.5.2</a> with a normative definition
          of the schema in <a href="#sec.verificationResultsSchema" class="xref">Section 16.3</a>.</p></section><section id="section-11.5.2"><div id="sec.verificationResults">
<h4 id="name-verification-result-element">
<a href="#section-11.5.2" class="section-number selfRef">11.5.2.Â </a><a href="#name-verification-result-element" class="section-name selfRef">Verification Result Elements</a>
</h4>
<p id="section-11.5.2-1">All verification elements are contained within a single
          &lt;verification-result&gt; element under &lt;result&gt;. The
          elements are described below and have the schema defined in <a href="#sec.enrollmentResultsSchema" class="xref">Section 16.2</a>. The following elements
          are defined:</p>
<ol id="section-11.5.2-2">
<li id="section-11.5.2-3">&lt;voiceprint&gt;</li>
<li id="section-11.5.2-4">&lt;incremental&gt;</li>
<li id="section-11.5.2-5">&lt;cumulative&gt;</li>
<li id="section-11.5.2-6">&lt;decision&gt;</li>
<li id="section-11.5.2-7">&lt;utterance-length&gt;</li>
<li id="section-11.5.2-8">&lt;device&gt;</li>
<li id="section-11.5.2-9">&lt;gender&gt;</li>
<li id="section-11.5.2-10">&lt;adapted&gt;</li>
<li id="section-11.5.2-11">&lt;verification-score&gt;</li>
<li id="section-11.5.2-12">&lt;vendor-specific-results&gt;</li>
</ol>
<section id="section-11.5.2.1"><h5 id="name-voiceprint-element">
<a href="#section-11.5.2.1" class="section-number selfRef">11.5.2.1.Â </a><a href="#name-voiceprint-element" class="section-name selfRef">&lt;voiceprint&gt; Element</a>
</h5>
<p id="section-11.5.2.1-1">This element in the verification results provides information
            on how the speech data matched a single voiceprint. The result
            data returned MAY have more than one such entity in the case of
            identification or multi-verification. Each &lt;voiceprint&gt;
            element and the XML data within the element describe verification
            result information for how well the speech data matched that
            particular voiceprint. The list of &lt;voiceprint&gt; element data are
            ordered according to their cumulative verification match scores,
            with the highest score first.</p></section><section id="section-11.5.2.2"><h5 id="name-cumulative-element">
<a href="#section-11.5.2.2" class="section-number selfRef">11.5.2.2.Â </a><a href="#name-cumulative-element" class="section-name selfRef">&lt;cumulative&gt; Element</a>
</h5>
<p id="section-11.5.2.2-1">Within each &lt;voiceprint&gt; element there MUST be a
            &lt;cumulative&gt; element with the cumulative scores of how well
            multiple utterances matched the voiceprint.</p></section><section id="section-11.5.2.3"><h5 id="name-incremental-element">
<a href="#section-11.5.2.3" class="section-number selfRef">11.5.2.3.Â </a><a href="#name-incremental-element" class="section-name selfRef">&lt;incremental&gt; Element</a>
</h5>
<p id="section-11.5.2.3-1">The first &lt;voiceprint&gt; element MAY contain an
            &lt;incremental&gt; element with the incremental scores of how
            well the last utterance matched the voiceprint.</p></section><section id="section-11.5.2.4"><h5 id="name-decision-element">
<a href="#section-11.5.2.4" class="section-number selfRef">11.5.2.4.Â </a><a href="#name-decision-element" class="section-name selfRef">&lt;Decision&gt; Element</a>
</h5>
<p id="section-11.5.2.4-1">This element is found within the &lt;incremental&gt; or
            &lt;cumulative&gt; element within the verification results. Its
            value indicates the verification decision. It can have the values
            of "accepted", "rejected", or "undecided".</p></section><section id="section-11.5.2.5"><h5 id="name-utterance-length-element">
<a href="#section-11.5.2.5" class="section-number selfRef">11.5.2.5.Â </a><a href="#name-utterance-length-element" class="section-name selfRef">&lt;utterance-length&gt; Element</a>
</h5>
<p id="section-11.5.2.5-1">This element MAY occur within either the &lt;incremental&gt; or
            &lt;cumulative&gt; elements within the first &lt;voiceprint&gt;
            element. Its value indicates the size in milliseconds,
            respectively, of the last utterance or the cumulated set of
            utterances.</p></section><section id="section-11.5.2.6"><h5 id="name-device-element">
<a href="#section-11.5.2.6" class="section-number selfRef">11.5.2.6.Â </a><a href="#name-device-element" class="section-name selfRef">&lt;device&gt; Element</a>
</h5>
<p id="section-11.5.2.6-1">This element is found within the &lt;incremental&gt; or &lt;cumulative&gt;
            element within the verification results. Its value indicates the
            apparent type of device used by the caller as determined by the
            verifier resource. It can have the values of "cellular-phone",
            "electret-phone", "carbon-button-phone", or "unknown".</p></section><section id="section-11.5.2.7"><h5 id="name-gender-element">
<a href="#section-11.5.2.7" class="section-number selfRef">11.5.2.7.Â </a><a href="#name-gender-element" class="section-name selfRef">&lt;gender&gt; Element</a>
</h5>
<p id="section-11.5.2.7-1">This element is found within the &lt;incremental&gt; or &lt;cumulative&gt;
            element within the verification results. Its value indicates the
            apparent gender of the speaker as determined by the verifier
            resource. It can have the values of "male", "female", or
            "unknown".</p></section><section id="section-11.5.2.8"><h5 id="name-adapted-element">
<a href="#section-11.5.2.8" class="section-number selfRef">11.5.2.8.Â </a><a href="#name-adapted-element" class="section-name selfRef">&lt;adapted&gt; Element</a>
</h5>
<p id="section-11.5.2.8-1">This element is found within the first &lt;voiceprint&gt;
            element within the verification results. When verification is
            trying to confirm the voiceprint, this indicates if the voiceprint
            has been adapted as a consequence of analyzing the source
            utterances. It is not returned during verification training. The
            value can be "true" or "false".</p></section><section id="section-11.5.2.9"><h5 id="name-verification-score-element">
<a href="#section-11.5.2.9" class="section-number selfRef">11.5.2.9.Â </a><a href="#name-verification-score-element" class="section-name selfRef">&lt;verification-score&gt; Element</a>
</h5>
<p id="section-11.5.2.9-1">This element is found within the &lt;incremental&gt; or &lt;cumulative&gt;
            element within the verification results. Its value indicates the
            score of the last utterance as determined by verification.</p>
<p id="section-11.5.2.9-2">During verification, the higher the score, the more likely it is
            that the speaker is the same one as the one who spoke the
            voiceprint utterances. During training, the higher the score, the
            more likely the speaker is to have spoken all of the analyzed
            utterances. The value is a floating point between -1.0 and 1.0. If
            there are no such utterances, the score is -1. Note that the
            verification score is not a probability value.</p></section><section id="section-11.5.2.10"><h5 id="name-vendor-specific-results-ele">
<a href="#section-11.5.2.10" class="section-number selfRef">11.5.2.10.Â </a><a href="#name-vendor-specific-results-ele" class="section-name selfRef">&lt;vendor-specific-results&gt; Element</a>
</h5>
<p id="section-11.5.2.10-1">MRCPv2 servers MAY send verification results that contain
            implementation-specific data that augment the information
            provided by the MRCPv2-defined elements. Such data might be useful
            to clients who have private knowledge of how to interpret these
            schema extensions. Implementation-specific additions to the
            verification results schema MUST belong to the vendor's own
            namespace. In the result structure, either they MUST be indicated
            by a namespace prefix declared within the result, or they MUST be
            children of an element identified as belonging to the respective
            namespace.</p>
<p id="section-11.5.2.10-2">The following example shows the results of three voiceprints.
            Note that the first one has crossed the verification score
            threshold, and the speaker has been accepted. The voiceprint was
            also adapted with the most recent utterance.</p>
<figure id="figure-31"><div><div id="section-11.5.2.10-3" class="artwork art-text" text-align="left"><pre>
&lt;?xml version="1.0"?&gt;
&lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
        grammar="What-Grammar-URI"&gt;
  &lt;verification-result&gt;
    &lt;voiceprint id="johnsmith"&gt;
      &lt;adapted&gt; true &lt;/adapted&gt;
      &lt;incremental&gt;
        &lt;utterance-length&gt; 500 &lt;/utterance-length&gt;
        &lt;device&gt; cellular-phone &lt;/device&gt;
        &lt;gender&gt; male &lt;/gender&gt;
        &lt;decision&gt; accepted &lt;/decision&gt;
        &lt;verification-score&gt; 0.98514 &lt;/verification-score&gt;
      &lt;/incremental&gt;
      &lt;cumulative&gt;
        &lt;utterance-length&gt; 10000 &lt;/utterance-length&gt;
        &lt;device&gt; cellular-phone &lt;/device&gt;
        &lt;gender&gt; male &lt;/gender&gt;
        &lt;decision&gt; accepted &lt;/decision&gt;
        &lt;verification-score&gt; 0.96725&lt;/verification-score&gt;
      &lt;/cumulative&gt;
    &lt;/voiceprint&gt;
    &lt;voiceprint id="marysmith"&gt;
      &lt;cumulative&gt;
        &lt;verification-score&gt; 0.93410 &lt;/verification-score&gt;
      &lt;/cumulative&gt;
    &lt;/voiceprint&gt;
    &lt;voiceprint uri="juniorsmith"&gt;
      &lt;cumulative&gt;
        &lt;verification-score&gt; 0.74209 &lt;/verification-score&gt;
      &lt;/cumulative&gt;
    &lt;/voiceprint&gt;
  &lt;/verification-result&gt;
&lt;/result&gt;
</pre></div></div>
<figcaption><a href="#figure-31">Figure 31</a><a href="#name-verification-results-exampl" id="name-verification-results-exampl" class="selfRef">Verification Results Example 1</a></figcaption></figure><p id="section-11.5.2.10-4">In this next example, the verifier has enough information to
            decide to reject the speaker.</p>
<figure id="figure-32"><div><div id="section-11.5.2.10-5" class="artwork art-text" text-align="left"><pre>
&lt;?xml version="1.0"?&gt;
&lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
        xmlns:xmpl="http://www.example.org/2003/12/mrcpv2"
        grammar="What-Grammar-URI"&gt;
  &lt;verification-result&gt;
    &lt;voiceprint id="johnsmith"&gt;
      &lt;incremental&gt;
        &lt;utterance-length&gt; 500 &lt;/utterance-length&gt;
        &lt;device&gt; cellular-phone &lt;/device&gt;
        &lt;gender&gt; male &lt;/gender&gt;
        &lt;verification-score&gt; 0.88514 &lt;/verification-score&gt;
        &lt;xmpl:raspiness&gt; high &lt;/xmpl:raspiness&gt;
        &lt;xmpl:emotion&gt; sadness &lt;/xmpl:emotion&gt;
      &lt;/incremental&gt;
      &lt;cumulative&gt;
        &lt;utterance-length&gt; 10000 &lt;/utterance-length&gt;
        &lt;device&gt; cellular-phone &lt;/device&gt;
        &lt;gender&gt; male &lt;/gender&gt;
        &lt;decision&gt; rejected &lt;/decision&gt;
        &lt;verification-score&gt; 0.9345 &lt;/verification-score&gt;
      &lt;/cumulative&gt;
    &lt;/voiceprint&gt;
  &lt;/verification-result&gt;
&lt;/result&gt;
</pre></div></div>
<figcaption><a href="#figure-32">Figure 32</a><a href="#name-verification-results-example" id="name-verification-results-example" class="selfRef">Verification Results Example 2</a></figcaption></figure></section>
</div></section></section><section id="section-11.6"><h3 id="name-start-session">
<a href="#section-11.6" class="section-number selfRef">11.6.Â </a><a href="#name-start-session" class="section-name selfRef">START-SESSION</a>
</h3>
<p id="section-11.6-1">The START-SESSION method starts a speaker verification or
        speaker identification session. Execution of this method places the verifier
        resource into its initial state. If this method is called during an
        ongoing verification session, the previous session is implicitly
        aborted. If this method is invoked when VERIFY or VERIFY-FROM-BUFFER
        is active, the method fails and the server returns a status-code of
        402.</p>
<p id="section-11.6-2">Upon completion of the START-SESSION method, the verifier resource
        MUST have terminated any ongoing verification session and cleared any
        voiceprint designation.</p>
<p id="section-11.6-3">A verification session is associated with the voiceprint repository
        to be used during the session. This is specified through the
        Repository-URI header field (see <a href="#sec.repositoryURI" class="xref">Section 11.4.1</a>).</p>
<p id="section-11.6-4">The START-SESSION method also establishes, through the
        Voiceprint-Identifier header field, which voiceprints are to be
        matched or trained during the verification session. If this is an
        Identification session or if the client wants to do
        Multi-Verification, the Voiceprint-Identifier header field contains a
        list of semicolon-separated voiceprint identifiers.</p>
<p id="section-11.6-5">The Adapt-Model header field MAY also be present in the
        START-SESSION request to indicate whether or not to adapt a voiceprint
        based on data collected during the session (if the voiceprint
        verification phase succeeds). By default, the voiceprint model MUST
        NOT be adapted with data from a verification session.</p>
<p id="section-11.6-6">The START-SESSION also determines whether the session is for a
        train or verify of a voiceprint. Hence, the Verification-Mode header
        field MUST be sent in every START-SESSION request. The value of the
        Verification-Mode header field MUST be one of either "train" or
        "verify".</p>
<p id="section-11.6-7">Before a verification/identification session is started, the client
        may only request that VERIFY-ROLLBACK and generic SET-PARAMS and
        GETâ€‘PARAMS operations be performed on the verifier resource. The
        server MUST return status-code 402 "Method not valid in this state"
        for all other verification operations.</p>
<p id="section-11.6-8">A verifier resource MUST NOT have more than a single session active
        at one time.</p>
<div id="section-11.6-9" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... START-SESSION 314161
       Channel-Identifier:32AECB23433801@speakverify
       Repository-URI:http://www.example.com/voiceprintdbase/
       Voiceprint-Mode:verify
       Voiceprint-Identifier:johnsmith.voiceprint
       Adapt-Model:true

S-&gt;C:  MRCP/2.0 ... 314161 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
</pre></div></section><section id="section-11.7"><h3 id="name-end-session">
<a href="#section-11.7" class="section-number selfRef">11.7.Â </a><a href="#name-end-session" class="section-name selfRef">END-SESSION</a>
</h3>
<p id="section-11.7-1">The END-SESSION method terminates an ongoing verification session
        and releases the verification voiceprint resources. The session may
        terminate in one of three ways: </p>
<ol id="section-11.7-2">
<li id="section-11.7-3">abort - the voiceprint adaptation or creation may be aborted so
            that the voiceprint remains unchanged (or is not created).</li>
<li id="section-11.7-4">commit - when terminating a voiceprint training session, the
            new voiceprint is committed to the repository.</li>
<li id="section-11.7-5">adapt - an existing voiceprint is modified using a successful
            verification.</li>
</ol>
<p id="section-11.7-6">The Abort-Model header field MAY be included in the END-SESSION to
        control whether or not to abort any pending changes to the voiceprint.
        The default behavior is to commit (not abort) any pending changes to
        the designated voiceprint.</p>
<p id="section-11.7-7">The END-SESSION method may be safely executed multiple times
        without first executing the START-SESSION method. Any additional
        executions of this method without an intervening use of the
        START-SESSION method have no effect on the verifier resource.</p>
<p id="section-11.7-8">The following example assumes there is either a training session or
        a verification session in progress.</p>
<div id="section-11.7-9" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... END-SESSION 314174
       Channel-Identifier:32AECB23433801@speakverify
       Abort-Model:true

S-&gt;C:  MRCP/2.0 ... 314174 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
          </pre></div></section><section id="section-11.8"><h3 id="name-query-voiceprint">
<a href="#section-11.8" class="section-number selfRef">11.8.Â </a><a href="#name-query-voiceprint" class="section-name selfRef">QUERY-VOICEPRINT</a>
</h3>
<p id="section-11.8-1">The QUERY-VOICEPRINT method is used to get status information on a
        particular voiceprint and can be used by the client to ascertain if a
        voiceprint or repository exists and if it contains trained
        voiceprints.</p>
<p id="section-11.8-2">The response to the QUERY-VOICEPRINT request contains an indication
        of the status of the designated voiceprint in the Voiceprint-Exists
        header field, allowing the client to determine whether to use the
        current voiceprint for verification, train a new voiceprint, or choose
        a different voiceprint.</p>
<p id="section-11.8-3">A voiceprint is completely specified by providing a repository
        location and a voiceprint identifier. The particular voiceprint or
        identity within the repository is specified by a string identifier
        that is unique within the repository. The Voiceprint-Identifier header
        field carries this unique voiceprint identifier within a given
        repository.</p>
<p id="section-11.8-4">The following example assumes a verification session is in progress
        and the voiceprint exists in the voiceprint repository.</p>
<div id="section-11.8-5" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... QUERY-VOICEPRINT 314168
       Channel-Identifier:32AECB23433801@speakverify
       Repository-URI:http://www.example.com/voiceprints/
       Voiceprint-Identifier:johnsmith.voiceprint

S-&gt;C:  MRCP/2.0 ... 314168 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
       Repository-URI:http://www.example.com/voiceprints/
       Voiceprint-Identifier:johnsmith.voiceprint
       Voiceprint-Exists:true
          </pre></div>
<p id="section-11.8-6">The following example assumes that the URI provided in the
        Repository-URI header field is a bad URI.</p>
<div id="section-11.8-7" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... QUERY-VOICEPRINT 314168
       Channel-Identifier:32AECB23433801@speakverify
       Repository-URI:http://www.example.com/bad-uri/
       Voiceprint-Identifier:johnsmith.voiceprint

S-&gt;C:  MRCP/2.0 ... 314168 405 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
       Repository-URI:http://www.example.com/bad-uri/
       Voiceprint-Identifier:johnsmith.voiceprint
       Completion-Cause:007 repository-uri-failure
</pre></div></section><section id="section-11.9"><div id="sec.DeleteVoiceprint">
<h3 id="name-delete-voiceprint">
<a href="#section-11.9" class="section-number selfRef">11.9.Â </a><a href="#name-delete-voiceprint" class="section-name selfRef">DELETE-VOICEPRINT</a>
</h3>
<p id="section-11.9-1">The DELETE-VOICEPRINT method removes a voiceprint from a
        repository. This method MUST carry the Repository-URI and
        Voiceprint-Identifier header fields.</p>
<p id="section-11.9-2">An MRCPv2 server MUST reject a DELETE-VOICEPRINT request
        with a 401 status code unless the MRCPv2 client has been
        authenticated and authorized.  Note that MRCPv2 does not have
        a standard mechanism for this.  See
        <a href="#sec.DelVPAuth" class="xref">Section 12.8</a>.</p>
<p id="section-11.9-3">If the corresponding voiceprint does not exist, the
        DELETE-VOICEPRINT method MUST return a 200 status code.</p>
<p id="section-11.9-4">The following example demonstrates a DELETE-VOICEPRINT operation to
        remove a specific voiceprint.</p>
<div id="section-11.9-5" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... DELETE-VOICEPRINT 314168
       Channel-Identifier:32AECB23433801@speakverify
       Repository-URI:http://www.example.com/bad-uri/
       Voiceprint-Identifier:johnsmith.voiceprint

S-&gt;C:  MRCP/2.0 ... 314168 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
</pre></div>
</div></section><section id="section-11.10"><h3 id="name-verify">
<a href="#section-11.10" class="section-number selfRef">11.10.Â </a><a href="#name-verify" class="section-name selfRef">VERIFY</a>
</h3>
<p id="section-11.10-1">The VERIFY method is used to request that the verifier resource
        either train/adapt the voiceprint or verify/identify a claimed
        identity. If the voiceprint is new or was deleted by a previous
        DELETE-VOICEPRINT method, the VERIFY method trains the voiceprint. If
        the voiceprint already exists, it is adapted and not retrained by the
        VERIFY command.</p>
<div id="section-11.10-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... VERIFY 543260
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... 543260 200 IN-PROGRESS
       Channel-Identifier:32AECB23433801@speakverify
</pre></div>
<p id="section-11.10-3">When the VERIFY request completes, the MRCPv2 server MUST send a
        VERIFICATION-COMPLETE event to the client.</p></section><section id="section-11.11"><h3 id="name-verify-from-buffer">
<a href="#section-11.11" class="section-number selfRef">11.11.Â </a><a href="#name-verify-from-buffer" class="section-name selfRef">VERIFY-FROM-BUFFER</a>
</h3>
<p id="section-11.11-1">The VERIFY-FROM-BUFFER method directs the verifier resource to
        verify buffered audio against a voiceprint. Only one VERIFY or
        VERIFY-FROM-BUFFER method may be active for a verifier resource at a
        time.</p>
<p id="section-11.11-2">The buffered audio is not consumed by this method and thus
        VERIFY-FROM-BUFFER may be invoked multiple times by the client to
        attempt verification against different voiceprints.</p>
<p id="section-11.11-3">For the VERIFY-FROM-BUFFER method, the server MAY optionally return
        an IN-PROGRESS response before the VERIFICATION-COMPLETE event.</p>
<p id="section-11.11-4">When the VERIFY-FROM-BUFFER method is invoked and the verification
        buffer is in use by another resource sharing it, the server MUST
        return an IN-PROGRESS response and wait until the buffer is available
        to it. The verification buffer is owned by the verifier resource but
        is shared with write access from other input resources on the same
        session. Hence, it is considered to be in use if there is a read or
        write operation such as a RECORD or RECOGNIZE with the
        Verâ€‘Bufferâ€‘Utterance header field set to "true" on a resource that
        shares this buffer. Note that if a RECORD or RECOGNIZE method returns
        with a failure cause code, the VERIFY-FROM-BUFFER request waiting to
        process that buffer MUST also fail with a Completion-Cause of 005
        (bufferâ€‘empty).</p>
<p id="section-11.11-5">The following example illustrates the usage of some buffering
        methods. In this scenario, the client first performed a live
        verification, but the utterance had been rejected. In the meantime,
        the utterance is also saved to the audio buffer. Then, another
        voiceprint is used to do verification against the audio buffer and the
        utterance is accepted. For the example, we assume both
        Numâ€‘Minâ€‘Verificationâ€‘Phrases and Numâ€‘Maxâ€‘Verificationâ€‘Phrases are
        1.</p>
<figure id="figure-33"><div><div id="section-11.11-6" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... START-SESSION 314161
       Channel-Identifier:32AECB23433801@speakverify
       Verification-Mode:verify
       Adapt-Model:true
       Repository-URI:http://www.example.com/voiceprints
       Voiceprint-Identifier:johnsmith.voiceprint

S-&gt;C:  MRCP/2.0 ... 314161 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify

C-&gt;S:  MRCP/2.0 ... VERIFY 314162
       Channel-Identifier:32AECB23433801@speakverify
       Ver-buffer-utterance:true

S-&gt;C:  MRCP/2.0 ... 314162 200 IN-PROGRESS
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... VERIFICATION-COMPLETE 314162 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
       Completion-Cause:000 success
       Content-Type:application/nlsml+xml
       Content-Length:...
       
       &lt;?xml version="1.0"?&gt;
       &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
               grammar="What-Grammar-URI"&gt;
         &lt;verification-result&gt;
           &lt;voiceprint id="johnsmith"&gt;
             &lt;incremental&gt;
               &lt;utterance-length&gt; 500 &lt;/utterance-length&gt;
               &lt;device&gt; cellular-phone &lt;/device&gt;
               &lt;gender&gt; female &lt;/gender&gt;
               &lt;decision&gt; rejected &lt;/decision&gt;
               &lt;verification-score&gt; 0.05465 &lt;/verification-score&gt;
             &lt;/incremental&gt;
             &lt;cumulative&gt;
               &lt;utterance-length&gt; 500 &lt;/utterance-length&gt;
               &lt;device&gt; cellular-phone &lt;/device&gt;
               &lt;gender&gt; female &lt;/gender&gt;
               &lt;decision&gt; rejected &lt;/decision&gt;
               &lt;verification-score&gt; 0.05465 &lt;/verification-score&gt;
             &lt;/cumulative&gt;
           &lt;/voiceprint&gt;
         &lt;/verification-result&gt;
       &lt;/result&gt;

C-&gt;S:  MRCP/2.0 ... QUERY-VOICEPRINT 314163
       Channel-Identifier:32AECB23433801@speakverify
       Repository-URI:http://www.example.com/voiceprints/
       Voiceprint-Identifier:johnsmith

S-&gt;C:  MRCP/2.0 ... 314163 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
       Repository-URI:http://www.example.com/voiceprints/
       Voiceprint-Identifier:johnsmith.voiceprint
       Voiceprint-Exists:true

C-&gt;S:  MRCP/2.0 ... START-SESSION 314164
       Channel-Identifier:32AECB23433801@speakverify
       Verification-Mode:verify
       Adapt-Model:true
       Repository-URI:http://www.example.com/voiceprints
       Voiceprint-Identifier:marysmith.voiceprint

S-&gt;C:  MRCP/2.0 ... 314164 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify

C-&gt;S:  MRCP/2.0 ... VERIFY-FROM-BUFFER 314165
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... 314165 200 IN-PROGRESS
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... VERIFICATION-COMPLETE 314165 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
       Completion-Cause:000 success
       Content-Type:application/nlsml+xml
       Content-Length:...
       
       &lt;?xml version="1.0"?&gt;
       &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
               grammar="What-Grammar-URI"&gt;
         &lt;verification-result&gt;
           &lt;voiceprint id="marysmith"&gt;
             &lt;incremental&gt;
               &lt;utterance-length&gt; 1000 &lt;/utterance-length&gt;
               &lt;device&gt; cellular-phone &lt;/device&gt;
               &lt;gender&gt; female &lt;/gender&gt;
               &lt;decision&gt; accepted &lt;/decision&gt;
               &lt;verification-score&gt; 0.98 &lt;/verification-score&gt;
             &lt;/incremental&gt;
             &lt;cumulative&gt;
               &lt;utterance-length&gt; 1000 &lt;/utterance-length&gt;
               &lt;device&gt; cellular-phone &lt;/device&gt;
               &lt;gender&gt; female &lt;/gender&gt;
               &lt;decision&gt; accepted &lt;/decision&gt;
               &lt;verification-score&gt; 0.98 &lt;/verification-score&gt;
             &lt;/cumulative&gt;
           &lt;/voiceprint&gt;
         &lt;/verification-result&gt;
       &lt;/result&gt;


C-&gt;S:  MRCP/2.0 ... END-SESSION 314166
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... 314166 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
</pre></div></div>
<figcaption><a href="#figure-33">Figure 33</a><a href="#name-verify-from-buffer-example" id="name-verify-from-buffer-example" class="selfRef">VERIFY-FROM-BUFFER Example</a></figcaption></figure></section><section id="section-11.12"><h3 id="name-verify-rollback">
<a href="#section-11.12" class="section-number selfRef">11.12.Â </a><a href="#name-verify-rollback" class="section-name selfRef">VERIFY-ROLLBACK</a>
</h3>
<p id="section-11.12-1">The VERIFY-ROLLBACK method discards the last buffered utterance or
        discards the last live utterances (when the mode is "train" or
        "verify"). The client will likely want to invoke this method when the
        user provides undesirable input such as non-speech noises,
        side-speech, out-of-grammar utterances, commands, etc. Note that this
        method does not provide a stack of rollback states. Executing
        VERIFY-ROLLBACK twice in succession without an intervening recognition
        operation has no effect on the second attempt.</p>
<figure id="figure-34"><div><div id="section-11.12-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... VERIFY-ROLLBACK 314165
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... 314165 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
</pre></div></div>
<figcaption><a href="#figure-34">Figure 34</a><a href="#name-verify-rollback-example" id="name-verify-rollback-example" class="selfRef">VERIFY-ROLLBACK Example</a></figcaption></figure></section><section id="section-11.13"><h3 id="name-stop-4">
<a href="#section-11.13" class="section-number selfRef">11.13.Â </a><a href="#name-stop-4" class="section-name selfRef">STOP</a>
</h3>
<p id="section-11.13-1">The STOP method from the client to the server tells the verifier
        resource to stop the VERIFY or VERIFYâ€‘FROMâ€‘BUFFER request if one is
        active. If such a request is active and the STOP request successfully
        terminated it, then the response header section contains an
        Active-Request-Id-List header field containing the request-id of the
        VERIFY or VERIFY-FROM-BUFFER request that was terminated. In this
        case, no VERIFICATION-COMPLETE event is sent for the terminated
        request. If there was no verify request active, then the response MUST
        NOT contain an Active-Request-Id-List header field. Either way, the
        response MUST contain a status-code of 200 "Success".</p>
<p id="section-11.13-2">The STOP method can carry an Abort-Verification header field, which
        specifies if the verification result until that point should be
        discarded or returned. If this header field is not present or if the
        value is "true", the verification result is discarded and the STOP
        response does not contain any result data. If the header field is
        present and its value is "false", the STOP response MUST contain a
        Completion-Cause header field and carry the Verification result data
        in its body.</p>
<p id="section-11.13-3">An aborted VERIFY request does an automatic rollback and hence
        does not affect the cumulative score. A VERIFY request that was
        stopped with no Abort-Verification header field or with the
        Abort-Verification header field set to "false" does affect cumulative
        scores and would need to be explicitly rolled back if the client does
        not want the verification result considered in the cumulative
        scores.</p>
<p id="section-11.13-4">The following example assumes a voiceprint identity has already
        been established.</p>
<figure id="figure-35"><div><div id="section-11.13-5" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... VERIFY 314177
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... 314177 200 IN-PROGRESS 
       Channel-Identifier:32AECB23433801@speakverify
     
C-&gt;S:  MRCP/2.0 ... STOP 314178
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... 314178 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
       Active-Request-Id-List:314177
</pre></div></div>
<figcaption><a href="#figure-35">Figure 35</a><a href="#name-stop-verification-example" id="name-stop-verification-example" class="selfRef">STOP Verification Example</a></figcaption></figure></section><section id="section-11.14"><h3 id="name-start-input-timers-6">
<a href="#section-11.14" class="section-number selfRef">11.14.Â </a><a href="#name-start-input-timers-6" class="section-name selfRef">START-INPUT-TIMERS</a>
</h3>
<p id="section-11.14-1">This request is sent from the client to the verifier resource to
        start the no-input timer, usually once the client has ascertained that
        any audio prompts to the user have played to completion.</p>
<div id="section-11.14-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... START-INPUT-TIMERS 543260
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... 543260 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
</pre></div></section><section id="section-11.15"><h3 id="name-verification-complete">
<a href="#section-11.15" class="section-number selfRef">11.15.Â </a><a href="#name-verification-complete" class="section-name selfRef">VERIFICATION-COMPLETE</a>
</h3>
<p id="section-11.15-1">The VERIFICATION-COMPLETE event follows a call to VERIFY or
        VERIFY-FROM-BUFFER and is used to communicate the verification results
        to the client. The event message body contains only verification
        results.</p>
<div id="section-11.15-2" class="artwork art-text" text-align="left"><pre>
S-&gt;C:  MRCP/2.0 ... VERIFICATION-COMPLETE 543259 COMPLETE
       Completion-Cause:000 success
       Content-Type:application/nlsml+xml
       Content-Length:...
       
       &lt;?xml version="1.0"?&gt;
       &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
               grammar="What-Grammar-URI"&gt;
         &lt;verification-result&gt;
           &lt;voiceprint id="johnsmith"&gt;
             &lt;incremental&gt;
               &lt;utterance-length&gt; 500 &lt;/utterance-length&gt;
               &lt;device&gt; cellular-phone &lt;/device&gt;
               &lt;gender&gt; male &lt;/gender&gt;
               &lt;decision&gt; accepted &lt;/decision&gt;
               &lt;verification-score&gt; 0.85 &lt;/verification-score&gt;
             &lt;/incremental&gt;
             &lt;cumulative&gt;
               &lt;utterance-length&gt; 1500 &lt;/utterance-length&gt;
               &lt;device&gt; cellular-phone &lt;/device&gt;
               &lt;gender&gt; male &lt;/gender&gt;
               &lt;decision&gt; accepted &lt;/decision&gt;
               &lt;verification-score&gt; 0.75 &lt;/verification-score&gt;
             &lt;/cumulative&gt;
           &lt;/voiceprint&gt;
         &lt;/verification-result&gt;
       &lt;/result&gt;
</pre></div></section><section id="section-11.16"><h3 id="name-start-of-input-3">
<a href="#section-11.16" class="section-number selfRef">11.16.Â </a><a href="#name-start-of-input-3" class="section-name selfRef">START-OF-INPUT</a>
</h3>
<p id="section-11.16-1">The START-OF-INPUT event is returned from the server to the client
        once the server has detected speech. This event is always returned by
        the verifier resource when speech has been detected, irrespective of
        whether or not the recognizer and verifier resources share the same session.</p>
<div id="section-11.16-2" class="artwork art-text" text-align="left"><pre>
S-&gt;C:  MRCP/2.0 ... START-OF-INPUT 543259 IN-PROGRESS
       Channel-Identifier:32AECB23433801@speakverify
</pre></div></section><section id="section-11.17"><h3 id="name-clear-buffer">
<a href="#section-11.17" class="section-number selfRef">11.17.Â </a><a href="#name-clear-buffer" class="section-name selfRef">CLEAR-BUFFER</a>
</h3>
<p id="section-11.17-1">The CLEAR-BUFFER method can be used to clear the verification
        buffer. This buffer is used to buffer speech during recognition,
        record, or verification operations that may later be used by
        VERIFY-FROM-BUFFER. As noted before, the buffer associated with the
        verifier resource is shared by other input resources like recognizers
        and recorders. Hence, a CLEAR-BUFFER request fails if the verification
        buffer is in use. This can happen when any one of the input resources
        that share this buffer has an active read or write operation such as
        RECORD, RECOGNIZE, or VERIFY with the Ver-Buffer-Utterance header field
        set to "true".</p>
<div id="section-11.17-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... CLEAR-BUFFER 543260
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... 543260 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
</pre></div></section><section id="section-11.18"><h3 id="name-get-intermediate-result">
<a href="#section-11.18" class="section-number selfRef">11.18.Â </a><a href="#name-get-intermediate-result" class="section-name selfRef">GET-INTERMEDIATE-RESULT</a>
</h3>
<p id="section-11.18-1">A client can use the GET-INTERMEDIATE-RESULT method to poll for
        intermediate results of a verification request that is in progress.
        Invoking this method does not change the state of the resource. The
        verifier resource collects the accumulated verification results and
        returns the information in the method response. The message body in
        the response to a GET-INTERMEDIATE-RESULT REQUEST contains only
        verification results. The method response MUST NOT contain a
        Completion-Cause header field as the request is not yet complete. If
        the resource does not have a verification in progress, the response has
        a 402 failure status-code and no result in the body.</p>
<div id="section-11.18-2" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... GET-INTERMEDIATE-RESULT 543260
       Channel-Identifier:32AECB23433801@speakverify

S-&gt;C:  MRCP/2.0 ... 543260 200 COMPLETE
       Channel-Identifier:32AECB23433801@speakverify
       Content-Type:application/nlsml+xml
       Content-Length:...
       
       &lt;?xml version="1.0"?&gt;  
       &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
               grammar="What-Grammar-URI"&gt;
         &lt;verification-result&gt;
           &lt;voiceprint id="marysmith"&gt;
             &lt;incremental&gt;
               &lt;utterance-length&gt; 50 &lt;/utterance-length&gt;
               &lt;device&gt; cellular-phone &lt;/device&gt;
               &lt;gender&gt; female &lt;/gender&gt;
               &lt;decision&gt; undecided &lt;/decision&gt;
               &lt;verification-score&gt; 0.85 &lt;/verification-score&gt;
             &lt;/incremental&gt;
             &lt;cumulative&gt;
               &lt;utterance-length&gt; 150 &lt;/utterance-length&gt;
               &lt;device&gt; cellular-phone &lt;/device&gt;
               &lt;gender&gt; female &lt;/gender&gt;
               &lt;decision&gt; undecided &lt;/decision&gt;
               &lt;verification-score&gt; 0.65 &lt;/verification-score&gt;
             &lt;/cumulative&gt;
           &lt;/voiceprint&gt;
         &lt;/verification-result&gt;
       &lt;/result&gt;
</pre></div></section>
</div></section><section id="section-12"><div id="sec.securityConsiderations">
<h2 id="name-security-considerations">
<a href="#section-12" class="section-number selfRef">12.Â </a><a href="#name-security-considerations" class="section-name selfRef">Security Considerations</a>
</h2>
<p id="section-12-1">MRCPv2 is designed to comply with the security-related requirements
      documented in <span>[<a href="#RFC4313" class="xref">the SPEECHSC requirements</a>].
      Implementers and users of MRCPv2 are strongly encouraged to read the
      Security Considerations section of </span><span>[<a href="#RFC4313" class="xref">RFC4313</a>],
      because that document contains discussion of a number of important
      security issues associated with the utilization of speech as biometric
      authentication technology, and on the threats against systems which
      store recorded speech, contain large corpora of voiceprints, and send
      and receive sensitive information based on voice input to a recognizer
      or speech output from a synthesizer. Specific security measures employed
      by MRCPv2 are summarized in the following subsections. See the
      corresponding sections of this specification for how the
      security-related machinery is invoked by individual protocol
      operations.</span></p>
<section id="section-12.1"><h3 id="name-rendezvous-and-session-esta">
<a href="#section-12.1" class="section-number selfRef">12.1.Â </a><a href="#name-rendezvous-and-session-esta" class="section-name selfRef">Rendezvous and Session Establishment</a>
</h3>
<p id="section-12.1-1">MRCPv2 control sessions are established as media sessions described
        by SDP within the context of a SIP dialog. In order to ensure secure
        rendezvous between MRCPv2 clients and servers, the following are
        required:</p>
<ol id="section-12.1-2">
<li id="section-12.1-3">The SIP implementation in MRCPv2 clients and servers MUST
            support SIP digest authentication <span>[<a href="#RFC3261" class="xref">RFC3261</a>]
            and SHOULD employ it.</span>
</li>
<li id="section-12.1-4">  The SIP implementation in MRCPv2 clients and servers MUST support
       'sips' URIs and SHOULD employ 'sips' URIs; this includes that clients
       and servers SHOULD set 
            up TLS <span>[<a href="#RFC5246" class="xref">RFC5246</a>] connections.</span>
</li>
<li id="section-12.1-5">If media stream cryptographic keying is done through SDP (e.g.
            using <span>[<a href="#RFC4568" class="xref">RFC4568</a>]), the MRCPv2 clients and
            servers MUST employ the 'sips' URI.</span>
</li>
<li id="section-12.1-6">When TLS is used for SIP, the client MUST verify the identity
            of the server to which it connects, following the rules and
            guidelines defined in <span>[<a href="#RFC5922" class="xref">RFC5922</a>].</span>
</li>
</ol></section><section id="section-12.2"><h3 id="name-control-channel-protection">
<a href="#section-12.2" class="section-number selfRef">12.2.Â </a><a href="#name-control-channel-protection" class="section-name selfRef">Control Channel Protection</a>
</h3>
<p id="section-12.2-1">Sensitive data is carried over the MRCPv2 control channel. This
        includes things like the output of speech recognition operations,
        speaker verification results, input to text-to-speech conversion,
        personally identifying grammars, etc. For this reason, MRCPv2 servers
        must be properly authenticated, and the control channel must permit the
        use of both confidentiality and integrity for the data. To ensure
        control channel protection, MRCPv2 clients and servers MUST support
        TLS and SHOULD utilize it by default unless alternative control
        channel protection is used. When TLS is used, the client MUST verify
        the identity of the server to which it connects, following the rules
        and guidelines defined in <span>[<a href="#RFC4572" class="xref">RFC4572</a>]. If there are
        multiple TLS-protected channels between the client and the server, the
        server MUST NOT send a response to the client over a channel for which
        the TLS identities of the server or client differ from the channel
        over which the server received the corresponding request. Alternative
        control-channel protection MAY be used if desired (e.g., </span><span>[<a href="#RFC4301" class="xref">Security Architecture for the Internet Protocol
        (IPsec)</a>]).</span></p></section><section id="section-12.3"><h3 id="name-media-session-protection">
<a href="#section-12.3" class="section-number selfRef">12.3.Â </a><a href="#name-media-session-protection" class="section-name selfRef">Media Session Protection</a>
</h3>
<p id="section-12.3-1">Sensitive data is also carried on media sessions terminating on
        MRCPv2 servers (the other end of a media channel may or may not be on
        the MRCPv2 client). This data includes the user's spoken utterances
        and the output of text-to-speech operations. MRCPv2 servers MUST
        support a security mechanism for protection of audio media sessions.
        MRCPv2 clients that originate or consume audio similarly MUST support
        a security mechanism for protection of the audio. One such mechanism
        is the <span>[<a href="#RFC3711" class="xref">Secure Real-time Transport
        Protocol (SRTP)</a>].</span></p></section><section id="section-12.4"><h3 id="name-indirect-content-access">
<a href="#section-12.4" class="section-number selfRef">12.4.Â </a><a href="#name-indirect-content-access" class="section-name selfRef">Indirect Content Access</a>
</h3>
<p id="section-12.4-1">MCRPv2 employs content indirection extensively. Content may be
        fetched and/or stored based on URI addressing on systems other than
        the MRCPv2 client or server. Not all of the stored content is
        necessarily sensitive (e.g., XML schemas), but the majority generally
        needs protection, and some indirect content, such as voice recordings
        and voiceprints, is extremely sensitive and must always be protected.
        MRCPv2 clients and servers MUST implement HTTPS for indirect content
        access and SHOULD employ secure access for all sensitive indirect
        content. Other secure URI schemes such as <span>[<a href="#RFC4217" class="xref">Secure FTP (FTPS)</a>] MAY also be used. See </span><a href="#sec.SetCookie" class="xref">Section 6.2.15</a> for the header fields used to transfer
        cookie information between the MRCPv2 client and server if needed for
        authentication.</p>
<p id="section-12.4-2">Access to URIs provided by servers introduces risks that
        need to be considered.  Although <span>[<a href="#RFC6454" class="xref">RFC
        6454</a>] discusses and focuses on a same-origin policy,
        which MRCPv2 does not restrict URIs to, it still provides an
        excellent description of the pitfalls of blindly following
        server-provided URIs in Section 3 of the RFC.  Servers also
        need to be aware that clients could provide URIs to sites
        designed to tie up the server in long or otherwise problematic
        document fetches.  MRCPv2 servers, and the services they
        access, MUST always be prepared for the possibility of such a
        denial-of-service attack.</span></p>
<p id="section-12.4-3">MRCPv2 makes no inherent assumptions about the lifetime and access
        controls associated with a URI. For example, if neither authentication
        nor scheme-specific access controls are used, a leak of the URI is
        equivalent to a leak of the content. Moreover, MRCPv2 makes no
        specific demands on the lifetime of a URI. If a server offers a URI
        and the client takes a long, long time to access that URI, the server
        may have removed the resource in the interim time period. MRCPv2 deals
        with this case by using the URI access scheme's 'resource not found'
        error, such as 404 for HTTPS. How long a server should keep a dynamic
        resource available is highly application and context dependent.
        However, the server SHOULD keep the resource available for a
        reasonable amount of time to make it likely the client will have the
        resource available when the client needs the resource. Conversely, to
        mitigate state exhaustion attacks, MRCPv2 servers are not obligated to
        keep resources and resource state in perpetuity. The server SHOULD
        delete dynamically generated resources associated with an MRCPv2
        session when the session ends.</p>
<p id="section-12.4-4">One method to avoid resource leakage is for the server to use
        difficult-to-guess, one-time resource URIs. In this instance, there can be only a single
        access to the underlying resource using the given URI. A downside to
        this approach is if an attacker uses the URI before the client uses
        the URI, then the client is denied the resource. Other methods would
        be to adopt a mechanism similar to the <span>[<a href="#RFC4467" class="xref">URLAUTH
        IMAP extension</a>], where the server sets cryptographic checks on
        URI usage, as well as capabilities for expiration, revocation, and so
        on. Specifying such a mechanism is beyond the scope of this
        document.</span></p></section><section id="section-12.5"><h3 id="name-protection-of-stored-media">
<a href="#section-12.5" class="section-number selfRef">12.5.Â </a><a href="#name-protection-of-stored-media" class="section-name selfRef">Protection of Stored Media</a>
</h3>
<p id="section-12.5-1">MRCPv2 applications often require the use of stored media. Voice
        recordings are both stored (e.g., for diagnosis and system tuning), and
        fetched (for replaying utterances into multiple MRCPv2 resources).
        Voiceprints are fundamental to the speaker identification and
        verification functions. This data can be extremely sensitive and can
        present substantial privacy and impersonation risks if stolen. Systems
        employing MRCPv2 SHOULD be deployed in ways that minimize these risks.
        The <span>[<a href="#RFC4313" class="xref">SPEECHSC requirements RFC</a>] contains a
        more extensive discussion of these risks and ways they may be
        mitigated.</span></p></section><section id="section-12.6"><h3 id="name-dtmf-and-recognition-buffer">
<a href="#section-12.6" class="section-number selfRef">12.6.Â </a><a href="#name-dtmf-and-recognition-buffer" class="section-name selfRef">DTMF and Recognition Buffers</a>
</h3>
<p id="section-12.6-1">DTMF buffers and recognition buffers may grow large enough to
        exceed the capabilities of a server, and the server MUST be prepared
        to gracefully handle resource consumption. A server MAY respond with
        the appropriate recognition incomplete if the server is in danger of
        running out of resources.</p></section><section id="section-12.7"><h3 id="name-client-set-server-parameter">
<a href="#section-12.7" class="section-number selfRef">12.7.Â </a><a href="#name-client-set-server-parameter" class="section-name selfRef">Client-Set Server Parameters</a>
</h3>
<p id="section-12.7-1">In MRCPv2, there are some tasks, such as URI resource
        fetches, that the server does on behalf of the client.  To
        control this behavior, MRCPv2 has a number of server
        parameters that a client can configure.  With one such
        parameter, <a href="#sec.FetchTimeout" class="xref">Fetch-Timeout</a>, a malicious
        client could set a very large value and then request the
        server to fetch a non-existent document.  It is RECOMMENDED
        that servers be cautious about accepting long timeout
        values or abnormally large values for other client-set parameters.</p></section><section id="section-12.8"><div id="sec.DelVPAuth">
<h3 id="name-delete-voiceprint-and-autho">
<a href="#section-12.8" class="section-number selfRef">12.8.Â </a><a href="#name-delete-voiceprint-and-autho" class="section-name selfRef">DELETE-VOICEPRINT and Authorization</a>
</h3>
<p id="section-12.8-1">Since this specification does not mandate a specific
        mechanism for authentication and authorization when
        requesting <a href="#sec.DeleteVoiceprint" class="xref">DELETE-VOICEPRINT</a>,
        there is a risk that an MRCPv2 server may not do such a check
        for authentication and authorization.  In practice, each
        provider of voice biometric solutions does insist on its own
        authentication and authorization mechanism, outside of this
        specification, so this is not likely to be a major problem.
        If in the future voice biometric providers standardize on such
        a mechanism, then a future version of MRCP can mandate it.</p>
</div></section>
</div></section><section id="section-13"><div id="sec.iana">
<h2 id="name-iana-considerations">
<a href="#section-13" class="section-number selfRef">13.Â </a><a href="#name-iana-considerations" class="section-name selfRef">IANA Considerations</a>
</h2>
<section id="section-13.1"><h3 id="name-new-registries">
<a href="#section-13.1" class="section-number selfRef">13.1.Â </a><a href="#name-new-registries" class="section-name selfRef">New Registries</a>
</h3>
<p id="section-13.1-1">This section describes the name spaces (registries) for MRCPv2 that
        IANA has created and now maintains. Assignment/registration
        policies are described in <span>[<a href="#RFC5226" class="xref">RFC 5226</a>].</span></p>
<section id="section-13.1.1"><div id="sec.registration.resources">
<h4 id="name-mrcpv2-resource-types">
<a href="#section-13.1.1" class="section-number selfRef">13.1.1.Â </a><a href="#name-mrcpv2-resource-types" class="section-name selfRef">MRCPv2 Resource Types</a>
</h4>
<p id="section-13.1.1-1">IANA has created a new name space of "MRCPv2 Resource Types".
          All maintenance within and additions to the contents of this name
          space MUST be according to the "Standards Action" registration
          policy. The initial contents of the registry, defined in <a href="#sec.resourceControl" class="xref">Section 4.2</a>, are given below:</p>
<div id="section-13.1.1-2" class="artwork art-text" text-align="left"><pre>Resource type  Resource description  Reference
-------------  --------------------  ---------
speechrecog    Speech Recognizer     [RFC6787]
dtmfrecog      DTMF Recognizer       [RFC6787]
speechsynth    Speech Synthesizer    [RFC6787]
basicsynth     Basic Synthesizer     [RFC6787]
speakverify    Speaker Verifier      [RFC6787]
recorder       Speech Recorder       [RFC6787]</pre></div>
</div></section><section id="section-13.1.2"><h4 id="name-mrcpv2-methods-and-events">
<a href="#section-13.1.2" class="section-number selfRef">13.1.2.Â </a><a href="#name-mrcpv2-methods-and-events" class="section-name selfRef">MRCPv2 Methods and Events</a>
</h4>
<p id="section-13.1.2-1">IANA has created a new name space of "MRCPv2 Methods and Events". All maintenance within and additions to the contents of
          this name space MUST be according to the "Standards Action"
          registration policy. The initial contents of the registry, defined
          by the "method-name" and "event-name" BNF in <a href="#S.abnf" class="xref">Section 15</a> and explained in Sections <a href="#sec.request" class="xref">5.2</a>
          and <a href="#sec.events" class="xref">5.5</a>,
          are given below.</p>
<div id="section-13.1.2-2" class="artwork art-text" text-align="left"><pre>Name                     Resource type  Method/Event  Reference
----                     -------------  ------------  ---------
SET-PARAMS               Generic        Method        [RFC6787]
GET-PARAMS               Generic        Method        [RFC6787]
SPEAK                    Synthesizer    Method        [RFC6787]
STOP                     Synthesizer    Method        [RFC6787]
PAUSE                    Synthesizer    Method        [RFC6787]
RESUME                   Synthesizer    Method        [RFC6787]
BARGE-IN-OCCURRED        Synthesizer    Method        [RFC6787]
CONTROL                  Synthesizer    Method        [RFC6787]
DEFINE-LEXICON           Synthesizer    Method        [RFC6787]
DEFINE-GRAMMAR           Recognizer     Method        [RFC6787]
RECOGNIZE                Recognizer     Method        [RFC6787]
INTERPRET                Recognizer     Method        [RFC6787]
GET-RESULT               Recognizer     Method        [RFC6787]
START-INPUT-TIMERS       Recognizer     Method        [RFC6787]
STOP                     Recognizer     Method        [RFC6787]
START-PHRASE-ENROLLMENT  Recognizer     Method        [RFC6787]
ENROLLMENT-ROLLBACK      Recognizer     Method        [RFC6787]
END-PHRASE-ENROLLMENT    Recognizer     Method        [RFC6787]
MODIFY-PHRASE            Recognizer     Method        [RFC6787]
DELETE-PHRASE            Recognizer     Method        [RFC6787]
RECORD                   Recorder       Method        [RFC6787]
STOP                     Recorder       Method        [RFC6787]
START-INPUT-TIMERS       Recorder       Method        [RFC6787]
START-SESSION            Verifier       Method        [RFC6787]
END-SESSION              Verifier       Method        [RFC6787]
QUERY-VOICEPRINT         Verifier       Method        [RFC6787]
DELETE-VOICEPRINT        Verifier       Method        [RFC6787]
VERIFY                   Verifier       Method        [RFC6787]
VERIFY-FROM-BUFFER       Verifier       Method        [RFC6787]
VERIFY-ROLLBACK          Verifier       Method        [RFC6787]
STOP                     Verifier       Method        [RFC6787]
START-INPUT-TIMERS       Verifier       Method        [RFC6787]
GET-INTERMEDIATE-RESULT  Verifier       Method        [RFC6787]
SPEECH-MARKER            Synthesizer    Event         [RFC6787]
SPEAK-COMPLETE           Synthesizer    Event         [RFC6787]
START-OF-INPUT           Recognizer     Event         [RFC6787]
RECOGNITION-COMPLETE     Recognizer     Event         [RFC6787]
INTERPRETATION-COMPLETE  Recognizer     Event         [RFC6787]
START-OF-INPUT           Recorder       Event         [RFC6787]
RECORD-COMPLETE          Recorder       Event         [RFC6787]
VERIFICATION-COMPLETE    Verifier       Event         [RFC6787]
START-OF-INPUT           Verifier       Event         [RFC6787]</pre></div></section><section id="section-13.1.3"><h4 id="name-mrcpv2-header-fields">
<a href="#section-13.1.3" class="section-number selfRef">13.1.3.Â </a><a href="#name-mrcpv2-header-fields" class="section-name selfRef">MRCPv2 Header Fields</a>
</h4>
<p id="section-13.1.3-1">IANA has created a new name space of "MRCPv2 Header Fields". All
          maintenance within and additions to the contents of this name space
          MUST be according to the "Standards Action" registration policy. The
          initial contents of the registry, defined by the "message-header"
          BNF in <a href="#S.abnf" class="xref">Section 15</a> and explained in <a href="#sec.common" class="xref">Section 5.1</a>, are given below. Note that the values
          permitted for the "Vendor-Specific-Parameters" parameter are managed
          according to a different policy. See <a href="#sec.vendorSpecificRegistration" class="xref">Section 13.1.6</a>.</p>
<div id="section-13.1.3-2" class="artwork art-text" text-align="left"><pre>
Name                               Resource type    Reference
----                               -------------    ---------
Channel-Identifier                 Generic          [RFC6787]
Accept                             Generic          [RFC2616]
Active-Request-Id-List             Generic          [RFC6787]
Proxy-Sync-Id                      Generic          [RFC6787]
Accept-Charset                     Generic          [RFC2616]
Content-Type                       Generic          [RFC6787]
Content-ID                         Generic 
                          [RFC2392], [RFC2046], and [RFC5322]
Content-Base                       Generic          [RFC6787]
Content-Encoding                   Generic          [RFC6787]
Content-Location                   Generic          [RFC6787]
Content-Length                     Generic          [RFC6787]
Fetch-Timeout                      Generic          [RFC6787]
Cache-Control                      Generic          [RFC6787]
Logging-Tag                        Generic          [RFC6787]
Set-Cookie                         Generic          [RFC6787]
Vendor-Specific                    Generic          [RFC6787]
Jump-Size                          Synthesizer      [RFC6787]
Kill-On-Barge-In                   Synthesizer      [RFC6787]
Speaker-Profile                    Synthesizer      [RFC6787]
Completion-Cause                   Synthesizer      [RFC6787]
Completion-Reason                  Synthesizer      [RFC6787]
Voice-Parameter                    Synthesizer      [RFC6787]
Prosody-Parameter                  Synthesizer      [RFC6787]
Speech-Marker                      Synthesizer      [RFC6787]
Speech-Language                    Synthesizer      [RFC6787]
Fetch-Hint                         Synthesizer      [RFC6787]
Audio-Fetch-Hint                   Synthesizer      [RFC6787]
Failed-URI                         Synthesizer      [RFC6787]
Failed-URI-Cause                   Synthesizer      [RFC6787]
Speak-Restart                      Synthesizer      [RFC6787]
Speak-Length                       Synthesizer      [RFC6787]
Load-Lexicon                       Synthesizer      [RFC6787]
Lexicon-Search-Order               Synthesizer      [RFC6787]
Confidence-Threshold               Recognizer       [RFC6787]
Sensitivity-Level                  Recognizer       [RFC6787]
Speed-Vs-Accuracy                  Recognizer       [RFC6787]
N-Best-List-Length                 Recognizer       [RFC6787]
Input-Type                         Recognizer       [RFC6787]
No-Input-Timeout                   Recognizer       [RFC6787]
Recognition-Timeout                Recognizer       [RFC6787]
Waveform-URI                       Recognizer       [RFC6787]
Input-Waveform-URI                 Recognizer       [RFC6787]
Completion-Cause                   Recognizer       [RFC6787]
Completion-Reason                  Recognizer       [RFC6787]
Recognizer-Context-Block           Recognizer       [RFC6787]
Start-Input-Timers                 Recognizer       [RFC6787]
Speech-Complete-Timeout            Recognizer       [RFC6787]
Speech-Incomplete-Timeout          Recognizer       [RFC6787]
Dtmf-Interdigit-Timeout            Recognizer       [RFC6787]
Dtmf-Term-Timeout                  Recognizer       [RFC6787]
Dtmf-Term-Char                     Recognizer       [RFC6787]
Failed-URI                         Recognizer       [RFC6787]
Failed-URI-Cause                   Recognizer       [RFC6787]
Save-Waveform                      Recognizer       [RFC6787]
Media-Type                         Recognizer       [RFC6787]
New-Audio-Channel                  Recognizer       [RFC6787]
Speech-Language                    Recognizer       [RFC6787]
Ver-Buffer-Utterance               Recognizer       [RFC6787]
Recognition-Mode                   Recognizer       [RFC6787]
Cancel-If-Queue                    Recognizer       [RFC6787]
Hotword-Max-Duration               Recognizer       [RFC6787]
Hotword-Min-Duration               Recognizer       [RFC6787]
Interpret-Text                     Recognizer       [RFC6787]
Dtmf-Buffer-Time                   Recognizer       [RFC6787]
Clear-Dtmf-Buffer                  Recognizer       [RFC6787]
Early-No-Match                     Recognizer       [RFC6787]
Num-Min-Consistent-Pronunciations  Recognizer       [RFC6787]
Consistency-Threshold              Recognizer       [RFC6787]
Clash-Threshold                    Recognizer       [RFC6787]
Personal-Grammar-URI               Recognizer       [RFC6787]
Enroll-Utterance                   Recognizer       [RFC6787]
Phrase-ID                          Recognizer       [RFC6787]
Phrase-NL                          Recognizer       [RFC6787]
Weight                             Recognizer       [RFC6787]
Save-Best-Waveform                 Recognizer       [RFC6787]
New-Phrase-ID                      Recognizer       [RFC6787]
Confusable-Phrases-URI             Recognizer       [RFC6787]
Abort-Phrase-Enrollment            Recognizer       [RFC6787]
Sensitivity-Level                  Recorder         [RFC6787]
No-Input-Timeout                   Recorder         [RFC6787]
Completion-Cause                   Recorder         [RFC6787]
Completion-Reason                  Recorder         [RFC6787]
Failed-URI                         Recorder         [RFC6787]
Failed-URI-Cause                   Recorder         [RFC6787]
Record-URI                         Recorder         [RFC6787]
Media-Type                         Recorder         [RFC6787]
Max-Time                           Recorder         [RFC6787]
Trim-Length                        Recorder         [RFC6787] 
Final-Silence                      Recorder         [RFC6787]
Capture-On-Speech                  Recorder         [RFC6787] 
Ver-Buffer-Utterance               Recorder         [RFC6787] 
Start-Input-Timers                 Recorder         [RFC6787]
New-Audio-Channel                  Recorder         [RFC6787]
Repository-URI                     Verifier         [RFC6787]
Voiceprint-Identifier              Verifier         [RFC6787]
Verification-Mode                  Verifier         [RFC6787]
Adapt-Model                        Verifier         [RFC6787]
Abort-Model                        Verifier         [RFC6787]
Min-Verification-Score             Verifier         [RFC6787]
Num-Min-Verification-Phrases       Verifier         [RFC6787]
Num-Max-Verification-Phrases       Verifier         [RFC6787]
No-Input-Timeout                   Verifier         [RFC6787]
Save-Waveform                      Verifier         [RFC6787]
Media-Type                         Verifier         [RFC6787]
Waveform-URI                       Verifier         [RFC6787]
Voiceprint-Exists                  Verifier         [RFC6787]
Ver-Buffer-Utterance               Verifier         [RFC6787]
Input-Waveform-URI                 Verifier         [RFC6787]
Completion-Cause                   Verifier         [RFC6787]
Completion-Reason                  Verifier         [RFC6787]
Speech-Complete-Timeout            Verifier         [RFC6787]
New-Audio-Channel                  Verifier         [RFC6787]
Abort-Verification                 Verifier         [RFC6787]
Start-Input-Timers                 Verifier         [RFC6787]
Input-Type                         Verifier         [RFC6787]</pre></div></section><section id="section-13.1.4"><h4 id="name-mrcpv2-status-codes">
<a href="#section-13.1.4" class="section-number selfRef">13.1.4.Â </a><a href="#name-mrcpv2-status-codes" class="section-name selfRef">MRCPv2 Status Codes</a>
</h4>
<p id="section-13.1.4-1">IANA has created a new name space of "MRCPv2 Status Codes" with
          the initial values that are defined in <a href="#sec.statusCodes" class="xref">Section 5.4</a>. All maintenance within and
          additions to the contents of this name space MUST be according to
          the "Specification Required with Expert Review" registration
          policy.</p></section><section id="section-13.1.5"><h4 id="name-grammar-reference-list-para">
<a href="#section-13.1.5" class="section-number selfRef">13.1.5.Â </a><a href="#name-grammar-reference-list-para" class="section-name selfRef">Grammar Reference List Parameters</a>
</h4>
<p id="section-13.1.5-1">IANA has created a new name space of "Grammar Reference List
          Parameters". All maintenance within and additions to the contents of
          this name space MUST be according to the "Specification Required
          with Expert Review" registration policy. There is only one initial
          parameter as shown below.</p>
<div id="section-13.1.5-2" class="artwork art-text" text-align="left"><pre>
Name                       Reference
----                       -------------
weight                     [RFC6787]</pre></div></section><section id="section-13.1.6"><div id="sec.vendorSpecificRegistration">
<h4 id="name-mrcpv2-vendor-specific-para">
<a href="#section-13.1.6" class="section-number selfRef">13.1.6.Â </a><a href="#name-mrcpv2-vendor-specific-para" class="section-name selfRef">MRCPv2 Vendor-Specific Parameters</a>
</h4>
<p id="section-13.1.6-1">IANA has created a new name space of "MRCPv2 Vendor-Specific
Parameters". All maintenance within and additions to the contents of 
          this name space MUST be according to the "Hierarchical Allocation"
          registration policy as follows. Each name (corresponding to the
          "vendor-av-pair-name" ABNF production) MUST satisfy the syntax
          requirements of Internet Domain Names as described in Section 2.3.1
          of <span>[<a href="#RFC1035" class="xref">RFC 1035</a>] (and as updated or
          obsoleted by successive RFCs), with one exception, the order of the
          domain names is reversed. For example, a vendor-specific parameter
          "foo" by example.com would have the form "com.example.foo". The
          first, or top-level domain, is restricted to exactly the set of
          Top-Level Internet Domains defined by IANA and will be updated by
          IANA when and only when that set changes. The second-level and all
          subdomains within the parameter name MUST be allocated according to
          the "First Come First Served" policy. It is RECOMMENDED that
          assignment requests adhere to the existing allocations of Internet
          domain names to organizations, institutions, corporations, etc.</span></p>
<p id="section-13.1.6-2">The registry contains a list of vendor-registered parameters,
          where each defined parameter is associated with a contact person and includes an optional
reference to the definition of the parameter, preferably an RFC. The registry is initially empty.</p>
</div></section></section><section id="section-13.2"><h3 id="name-nlsml-related-registrations">
<a href="#section-13.2" class="section-number selfRef">13.2.Â </a><a href="#name-nlsml-related-registrations" class="section-name selfRef">NLSML-Related Registrations</a>
</h3>
<section id="section-13.2.1"><h4 id="name-application-nlsmlxml-media-">
<a href="#section-13.2.1" class="section-number selfRef">13.2.1.Â </a><a href="#name-application-nlsmlxml-media-" class="section-name selfRef">'application/nlsml+xml' Media Type Registration</a>
</h4>
<p id="section-13.2.1-1">IANA has registered the following media type according
          to the process defined in <span>[<a href="#RFC4288" class="xref">RFC 4288</a>].
          </span></p>
<dl id="section-13.2.1-2" class="dlNewline">
<dt id="section-13.2.1-3">To:</dt>
<dd id="section-13.2.1-4">ietf-types@iana.org</dd>
<dt id="section-13.2.1-5">Subject:</dt>
<dd id="section-13.2.1-6">Registration of media type
              application/nlsml+xml</dd>
<dt id="section-13.2.1-7">MIME media type name:</dt>
<dd id="section-13.2.1-8">application</dd>
<dt id="section-13.2.1-9">MIME subtype name:</dt>
<dd id="section-13.2.1-10">nlsml+xml</dd>
<dt id="section-13.2.1-11">Required parameters:</dt>
<dd id="section-13.2.1-12">none</dd>
<dt id="section-13.2.1-13">Optional parameters:</dt>
<dd id="section-13.2.1-14"><dl id="section-13.2.1-15" class="dlParallel">
<dt id="section-13.2.1-16">charset:</dt>
<dd id="section-13.2.1-17">All of the considerations described
                  in <span>[<a href="#RFC3023" class="xref">RFC 3023</a>] also apply to the
                  application/nlsml+xml media type.</span>
</dd>
</dl></dd>
<dt id="section-13.2.1-18">Encoding considerations:</dt>
<dd id="section-13.2.1-19">All of the considerations
              described in RFC 3023 also apply to the 'application/nlsml+xml'
              media type.</dd>
<dt id="section-13.2.1-20">Security considerations:</dt>
<dd id="section-13.2.1-21">As with HTML, NLSML
              documents contain links to other data stores (grammars, verifier
              resources, etc.). Unlike HTML, however, the data stores are not
              treated as media to be rendered. Nevertheless, linked files may
              themselves have security considerations, which would be those of
              the individual registered types. Additionally, this media type
              has all of the security considerations described in RFC
              3023.</dd>
<dt id="section-13.2.1-22">Interoperability considerations:</dt>
<dd id="section-13.2.1-23">Although an NLSML
              document is itself a complete XML document, for a fuller
              interpretation of the content a receiver of an NLSML document
              may wish to access resources linked to by the document. The
              inability of an NLSML processor to access or process such linked
              resources could result in different behavior by the ultimate
              consumer of the data.</dd>
<dt id="section-13.2.1-24">Published specification:</dt>
<dd id="section-13.2.1-25">RFC 6787</dd>
<dt id="section-13.2.1-26">Applications that use this media type:</dt>
<dd id="section-13.2.1-27">MRCPv2
              clients and servers</dd>
<dt id="section-13.2.1-28">Additional information:</dt>
<dd id="section-13.2.1-29">none</dd>
<dt id="section-13.2.1-30">Magic number(s):</dt>
<dd id="section-13.2.1-31">There is no single initial octet
              sequence that is always present for NLSML files.</dd>
<dt id="section-13.2.1-32">Person &amp; email address to contact for further information:</dt>
<dd id="section-13.2.1-33">SarviÂ Shanmugham, sarvi@cisco.com</dd>
<dt id="section-13.2.1-34">Intended usage:</dt>
<dd id="section-13.2.1-35">This media type is expected to be
              used only in conjunction with MRCPv2.</dd>
</dl></section></section><section id="section-13.3"><h3 id="name-nlsml-xml-schema-registrati">
<a href="#section-13.3" class="section-number selfRef">13.3.Â </a><a href="#name-nlsml-xml-schema-registrati" class="section-name selfRef">NLSML XML Schema Registration</a>
</h3>
<p id="section-13.3-1">IANA has registered and now maintains the following XML
        Schema. Information provided follows the template in <span>[<a href="#RFC3688" class="xref">RFC 3688</a>]. </span></p>
<dl id="section-13.3-2" class="dlParallel">
<dt id="section-13.3-3">XML element type:</dt>
<dd id="section-13.3-4">schema</dd>
<dt id="section-13.3-5">URI:</dt>
<dd id="section-13.3-6">urn:ietf:params:xml:schema:nlsml</dd>
<dt id="section-13.3-7">Registrant Contact:</dt>
<dd id="section-13.3-8">IESG</dd>
<dt id="section-13.3-9">XML:</dt>
<dd id="section-13.3-10">See <a href="#sec.schema.NLSML" class="xref">Section 16.1</a>.</dd>
</dl></section><section id="section-13.4"><h3 id="name-mrcpv2-xml-namespace-regist">
<a href="#section-13.4" class="section-number selfRef">13.4.Â </a><a href="#name-mrcpv2-xml-namespace-regist" class="section-name selfRef">MRCPv2 XML Namespace Registration</a>
</h3>
<p id="section-13.4-1">IANA has registered and now maintains the following XML Name
        space. Information provided follows the template in <span>[<a href="#RFC3688" class="xref">RFC 3688</a>]. </span></p>
<dl id="section-13.4-2" class="dlParallel">
<dt id="section-13.4-3">XML element type:</dt>
<dd id="section-13.4-4">ns</dd>
<dt id="section-13.4-5">URI:</dt>
<dd id="section-13.4-6">urn:ietf:params:xml:ns:mrcpv2</dd>
<dt id="section-13.4-7">Registrant Contact:</dt>
<dd id="section-13.4-8">IESG</dd>
<dt id="section-13.4-9">XML:</dt>
<dd id="section-13.4-10">RFC 6787</dd>
</dl></section><section id="section-13.5"><div id="sec.text-media-registrations">
<h3 id="name-text-media-type-registratio">
<a href="#section-13.5" class="section-number selfRef">13.5.Â </a><a href="#name-text-media-type-registratio" class="section-name selfRef">Text Media Type Registrations</a>
</h3>
<p id="section-13.5-1">IANA has registered the following text media type
        according to the process defined in <span>[<a href="#RFC4288" class="xref">RFC
        4288</a>].</span></p>
<section id="section-13.5.1"><div id="sec.grammar-ref-list">
<h4 id="name-text-grammar-ref-list">
<a href="#section-13.5.1" class="section-number selfRef">13.5.1.Â </a><a href="#name-text-grammar-ref-list" class="section-name selfRef">text/grammar-ref-list</a>
</h4>
<dl id="section-13.5.1-1" class="dlParallel">
<dt id="section-13.5.1-2">To:</dt>
<dd id="section-13.5.1-3">ietf-types@iana.org</dd>
<dt id="section-13.5.1-4">Subject:</dt>
<dd id="section-13.5.1-5">Registration of media type
              text/grammar-ref-list</dd>
<dt id="section-13.5.1-6">MIME media type name:</dt>
<dd id="section-13.5.1-7">text</dd>
<dt id="section-13.5.1-8">MIME subtype name:</dt>
<dd id="section-13.5.1-9">text/grammar-ref-list</dd>
<dt id="section-13.5.1-10">Required parameters:</dt>
<dd id="section-13.5.1-11">none</dd>
<dt id="section-13.5.1-12">Optional parameters:</dt>
<dd id="section-13.5.1-13">none</dd>
<dt id="section-13.5.1-14">Encoding considerations:</dt>
<dd id="section-13.5.1-15">Depending on the transfer
              protocol, a transfer encoding may be necessary to deal with very
              long lines.</dd>
<dt id="section-13.5.1-16">Security considerations:</dt>
<dd id="section-13.5.1-17">This media type contains
              URIs that may represent references to external resources. As
              these resources are assumed to be speech recognition grammars,
              similar considerations as for the media types 'application/srgs'
              and 'application/srgs+xml' apply.</dd>
<dt id="section-13.5.1-18">Interoperability considerations:</dt>
<dd id="section-13.5.1-19">'&gt;' must be
              percent encoded in URIs according to <span>[<a href="#RFC3986" class="xref">RFC
              3986</a>].</span>
</dd>
<dt id="section-13.5.1-20">Published specification:</dt>
<dd id="section-13.5.1-21">
<p id="section-13.5.1-22">The RECOGNIZE method of
              the MRCP protocol performs a recognition operation that matches
              input against a set of grammars. When matching against more than
              one grammar, it is sometimes necessary to use different weights
              for the individual grammars. These weights are not a property of
              the grammar resource itself but qualify the reference to that
              grammar for the particular recognition operation initiated by
              the RECOGNIZE method. The format of the proposed
              'text/grammar-ref-list' media type is as follows: 
</p>
<div id="section-13.5.1-23" class="artwork art-text art-abnf" text-align="left"><pre>
   body       = *reference
   reference  = "&lt;" uri "&gt;" [parameters] CRLF
   parameters = ";" parameter *(";" parameter)
   parameter  = attribute "=" value
</pre></div>
<p id="section-13.5.1-24">
This specification currently only defines a
              'weight' parameter, but new parameters MAY be added through the
              "Grammar Reference List Parameters" IANA registry established
              through this specification. Example:
</p>
<div id="section-13.5.1-25" class="artwork art-text" text-align="left"><pre>
         &lt;http://example.com/grammars/field1.gram&gt;
         &lt;http://example.com/grammars/field2.gram&gt;;weight="0.85"
         &lt;session:field3@form-level.store&gt;;weight="0.9"
         &lt;http://example.com/grammars/universals.gram&gt;;weight="0.75"
</pre></div>
</dd>
<dt id="section-13.5.1-26">Applications that use this media type:</dt>
<dd id="section-13.5.1-27">MRCPv2
              clients and servers</dd>
<dt id="section-13.5.1-28">Additional information:</dt>
<dd id="section-13.5.1-29">none</dd>
<dt id="section-13.5.1-30">Magic number(s):</dt>
<dd id="section-13.5.1-31">none</dd>
<dt id="section-13.5.1-32">Person &amp; email address to contact for further information:</dt>
<dd id="section-13.5.1-33">SarviÂ Shanmugham, sarvi@cisco.com</dd>
<dt id="section-13.5.1-34">Intended usage:</dt>
<dd id="section-13.5.1-35">This media type is expected to be
              used only in conjunction with MRCPv2.</dd>
</dl>
</div></section>
</div></section><section id="section-13.6"><div id="sec.sessionURIScheme">
<h3 id="name-session-uri-scheme-registra">
<a href="#section-13.6" class="section-number selfRef">13.6.Â </a><a href="#name-session-uri-scheme-registra" class="section-name selfRef">'session' URI Scheme Registration</a>
</h3>
<p id="section-13.6-1">IANA has registered the following new URI scheme. The
        information below follows the template given in <span>[<a href="#RFC4395" class="xref">RFC 4395</a>]. </span></p>
<dl id="section-13.6-2" class="dlParallel">
<dt id="section-13.6-3">URI scheme name:</dt>
<dd id="section-13.6-4">session</dd>
<dt id="section-13.6-5">Status:</dt>
<dd id="section-13.6-6">Permanent</dd>
<dt id="section-13.6-7">URI scheme syntax:</dt>
<dd id="section-13.6-8">The syntax of this scheme is
            identical to that defined for the "cid" scheme in Section 2 of
            <span>[<a href="#RFC2392" class="xref">RFC 2392</a>].</span>
</dd>
<dt id="section-13.6-9">URI scheme semantics:</dt>
<dd id="section-13.6-10">The URI is intended to
            identify a data resource previously given to the network computing
            resource. The purpose of this scheme is to permit access to the
            specific resource for the lifetime of the session with the entity
            storing the resource. The media type of the resource CAN vary.
            There is no explicit mechanism for communication of the media
            type. This scheme is currently widely used internally by existing
            implementations, and the registration is intended to provide
            information in the rare (and unfortunate) case that the scheme is
            used elsewhere. The scheme SHOULD NOT be used for open Internet
            protocols.</dd>
<dt id="section-13.6-11">Encoding considerations:</dt>
<dd id="section-13.6-12">There are no other encoding
            considerations for the 'session' URIs not described in <span>[<a href="#RFC3986" class="xref">RFC 3986</a>]</span>
</dd>
<dt id="section-13.6-13">Applications/protocols that use this URI scheme name:</dt>
<dd id="section-13.6-14">This
            scheme name is used by MRCPv2 clients and servers.</dd>
<dt id="section-13.6-15">Interoperability considerations:</dt>
<dd id="section-13.6-16">Note that none of
            the resources are accessible after the MCRPv2 session ends, hence
            the name of the scheme. For clients who establish one MRCPv2
            session only for the entire speech application being implemented,
            this is sufficient, but clients who create, terminate, and
            recreate MRCP sessions for performance or scalability reasons will
            lose access to resources established in the earlier
            session(s).</dd>
<dt id="section-13.6-17">Security considerations:</dt>
<dd id="section-13.6-18">Generic security
            considerations for URIs described in <span>[<a href="#RFC3986" class="xref">RFC
            3986</a>] apply to this scheme as well. The URIs defined here
            provide an identification mechanism only. Given that the
            communication channel between client and server is secure, that
            the server correctly accesses the resource associated with the
            URI, and that the server ensures session-only lifetime and access
            for each URI, the only additional security issues are those of the
            types of media referred to by the URI.</span>
</dd>
<dt id="section-13.6-19">Contact:</dt>
<dd id="section-13.6-20">Sarvi Shanmugham, sarvi@cisco.com</dd>
<dt id="section-13.6-21">Author/Change controller:</dt>
<dd id="section-13.6-22">IESG, iesg@ietf.org</dd>
<dt id="section-13.6-23">References:</dt>
<dd id="section-13.6-24">This specification, particularly
            Sections <a href="#sec.Content-ID" class="xref">6.2.7</a>, <a href="#sec.lexiconData" class="xref">8.5.2</a>, <a href="#sec.grammarData" class="xref">9.5.1</a>, and <a href="#sec.methodRecognize" class="xref">9.9</a>.</dd>
</dl>
</div></section><section id="section-13.7"><h3 id="name-sdp-parameter-registrations">
<a href="#section-13.7" class="section-number selfRef">13.7.Â </a><a href="#name-sdp-parameter-registrations" class="section-name selfRef">SDP Parameter Registrations</a>
</h3>
<p id="section-13.7-1">IANA has registered the following SDP parameter values.
        The information for each follows the template given in <span>[<a href="#RFC4566" class="xref">RFC 4566</a>], Appendix B.</span></p>
<section id="section-13.7.1"><h4 id="name-sub-registry-proto">
<a href="#section-13.7.1" class="section-number selfRef">13.7.1.Â </a><a href="#name-sub-registry-proto" class="section-name selfRef">Sub-Registry "proto"</a>
</h4>
<p id="section-13.7.1-1">"TCP/MRCPv2" value of the "proto" parameter</p>
<dl id="section-13.7.1-2" class="dlParallel">
<dt id="section-13.7.1-3">Contact name, email address, and telephone number:</dt>
<dd id="section-13.7.1-4">Sarvi
              Shanmugham, sarvi@cisco.com, +1.408.902.3875</dd>
<dt id="section-13.7.1-5">Name being registered (as it will appear in SDP):</dt>
<dd id="section-13.7.1-6">TCP/MRCPv2</dd>
<dt id="section-13.7.1-7">Long-form name in English:</dt>
<dd id="section-13.7.1-8">MCRPv2 over TCP</dd>
<dt id="section-13.7.1-9">Type of name:</dt>
<dd id="section-13.7.1-10">proto</dd>
<dt id="section-13.7.1-11">Explanation of name:</dt>
<dd id="section-13.7.1-12">This name represents the
              MCRPv2 protocol carried over TCP.</dd>
<dt id="section-13.7.1-13">Reference to specification of name:</dt>
<dd id="section-13.7.1-14">RFC 6787</dd>
</dl>
<p id="section-13.7.1-15"></p>
<p id="section-13.7.1-16">"TCP/TLS/MRCPv2" value of the "proto" parameter</p>
<dl id="section-13.7.1-17" class="dlParallel">
<dt id="section-13.7.1-18">Contact name, email address, and telephone number:</dt>
<dd id="section-13.7.1-19">Sarvi
              Shanmugham, sarvi@cisco.com, +1.408.902.3875</dd>
<dt id="section-13.7.1-20">Name being registered (as it will appear in SDP):</dt>
<dd id="section-13.7.1-21">TCP/TLS/MRCPv2</dd>
<dt id="section-13.7.1-22">Long-form name in English:</dt>
<dd id="section-13.7.1-23">MCRPv2 over TLS over
              TCP</dd>
<dt id="section-13.7.1-24">Type of name:</dt>
<dd id="section-13.7.1-25">proto</dd>
<dt id="section-13.7.1-26">Explanation of name:</dt>
<dd id="section-13.7.1-27">This name represents the
              MCRPv2 protocol carried over TLS over TCP.</dd>
<dt id="section-13.7.1-28">Reference to specification of name:</dt>
<dd id="section-13.7.1-29">RFC 6787</dd>
</dl></section><section id="section-13.7.2"><h4 id="name-sub-registry-att-field-medi">
<a href="#section-13.7.2" class="section-number selfRef">13.7.2.Â </a><a href="#name-sub-registry-att-field-medi" class="section-name selfRef">Sub-Registry "att-field (media-level)"</a>
</h4>
<p id="section-13.7.2-1">"resource" value of the "att-field" parameter </p>
<dl id="section-13.7.2-2" class="dlParallel">
<dt id="section-13.7.2-3">Contact name, email address, and telephone number:</dt>
<dd id="section-13.7.2-4">Sarvi
              Shanmugham, sarvi@cisco.com, +1.408.902.3875</dd>
<dt id="section-13.7.2-5">Attribute name (as it will appear in SDP):</dt>
<dd id="section-13.7.2-6">resource</dd>
<dt id="section-13.7.2-7">Long-form attribute name in English:</dt>
<dd id="section-13.7.2-8">MRCPv2
              resource type</dd>
<dt id="section-13.7.2-9">Type of attribute:</dt>
<dd id="section-13.7.2-10">media-level</dd>
<dt id="section-13.7.2-11">Subject to charset attribute?</dt>
<dd id="section-13.7.2-12">no</dd>
<dt id="section-13.7.2-13">Explanation of attribute:</dt>
<dd id="section-13.7.2-14">See <a href="#sec.resourceControl" class="xref">Section 4.2</a> of RFC 6787 for description
              and examples.</dd>
<dt id="section-13.7.2-15">Specification of appropriate attribute values:</dt>
<dd id="section-13.7.2-16">See
              section <a href="#sec.registration.resources" class="xref">Section 13.1.1</a> of
              RFC 6787.</dd>
</dl>
<p id="section-13.7.2-17"></p>
<p id="section-13.7.2-18">"channel" value of the "att-field" parameter </p>
<dl id="section-13.7.2-19" class="dlParallel">
<dt id="section-13.7.2-20">Contact name, email address, and telephone number:</dt>
<dd id="section-13.7.2-21">Sarvi
              Shanmugham, sarvi@cisco.com, +1.408.902.3875</dd>
<dt id="section-13.7.2-22">Attribute name (as it will appear in SDP):</dt>
<dd id="section-13.7.2-23">channel</dd>
<dt id="section-13.7.2-24">Long-form attribute name in English:</dt>
<dd id="section-13.7.2-25">MRCPv2
              resource channel identifier</dd>
<dt id="section-13.7.2-26">Type of attribute:</dt>
<dd id="section-13.7.2-27">media-level</dd>
<dt id="section-13.7.2-28">Subject to charset attribute?</dt>
<dd id="section-13.7.2-29">no</dd>
<dt id="section-13.7.2-30">Explanation of attribute:</dt>
<dd id="section-13.7.2-31">See <a href="#sec.resourceControl" class="xref">Section 4.2</a> of RFC 6787 for description
              and examples.</dd>
<dt id="section-13.7.2-32">Specification of appropriate attribute values:</dt>
<dd id="section-13.7.2-33">See
              <a href="#sec.resourceControl" class="xref">Section 4.2</a> and the "channel-id"
              ABNF production rules of RFC 6787.</dd>
</dl>
<p id="section-13.7.2-34"></p>
<p id="section-13.7.2-35">"cmid" value of the "att-field" parameter</p>
<dl id="section-13.7.2-36" class="dlParallel">
<dt id="section-13.7.2-37">Contact name, email address, and telephone number:</dt>
<dd id="section-13.7.2-38">Sarvi
              Shanmugham, sarvi@cisco.com, +1.408.902.3875</dd>
<dt id="section-13.7.2-39">Attribute name (as it will appear in SDP):</dt>
<dd id="section-13.7.2-40">cmid</dd>
<dt id="section-13.7.2-41">Long-form attribute name in English:</dt>
<dd id="section-13.7.2-42">MRCPv2
              resource channel media identifier</dd>
<dt id="section-13.7.2-43">Type of attribute:</dt>
<dd id="section-13.7.2-44">media-level</dd>
<dt id="section-13.7.2-45">Subject to charset attribute?</dt>
<dd id="section-13.7.2-46">no</dd>
<dt id="section-13.7.2-47">Explanation of attribute:</dt>
<dd id="section-13.7.2-48">See <a href="#sec.mediaStreams" class="xref">Section 4.4</a> of RFC 6787 for description and
              examples.</dd>
<dt id="section-13.7.2-49">Specification of appropriate attribute values:</dt>
<dd id="section-13.7.2-50">See
              <a href="#sec.mediaStreams" class="xref">Section 4.4</a> and the "cmid-attribute"
              ABNF production rules of RFC 6787.</dd>
</dl>
<p id="section-13.7.2-51"></p></section></section>
</div></section><section id="section-14"><h2 id="name-examples">
<a href="#section-14" class="section-number selfRef">14.Â </a><a href="#name-examples" class="section-name selfRef">Examples</a>
</h2>
<section id="section-14.1"><h3 id="name-message-flow">
<a href="#section-14.1" class="section-number selfRef">14.1.Â </a><a href="#name-message-flow" class="section-name selfRef">Message Flow</a>
</h3>
<p id="section-14.1-1">The following is an example of a typical MRCPv2 session of speech
        synthesis and recognition between a client and a server. Although the
        SDP "s=" attribute in these examples has a text description value to
        assist in understanding the examples, please keep in mind that <span>[<a href="#RFC3264" class="xref">RFC 3264</a>] recommends that messages actually put
        on the wire use a space or a dash.</span></p>
<p id="section-14.1-2">The figure below illustrates opening a session to the MRCPv2
        server. This exchange does not allocate a resource or setup media. It
        simply establishes a SIP session with the MRCPv2 server.</p>
<div id="section-14.1-3" class="artwork art-text" text-align="left"><pre>
C-&gt;S:
       INVITE sip:mresources@example.com SIP/2.0
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg1
       Max-Forwards:6
       To:MediaServer &lt;sip:mresources@example.com&gt;
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       Call-ID:a84b4c76e66710
       CSeq:323123 INVITE
       Contact:&lt;sip:sarvi@client.example.com&gt;
       Content-Type:application/sdp
       Content-Length:...
       
       v=0
       o=sarvi 2614933546 2614933546 IN IP4 192.0.2.12
       s=Set up MRCPv2 control and audio
       i=Initial contact
       c=IN IP4 192.0.2.12


S-&gt;C:
       SIP/2.0 200 OK
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg1;received=192.0.32.10
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       Call-ID:a84b4c76e66710
       CSeq:323123 INVITE
       Contact:&lt;sip:mresources@server.example.com&gt;
       Content-Type:application/sdp
       Content-Length:...

       v=0
       o=- 3000000001 3000000001 IN IP4 192.0.2.11
       s=Set up MRCPv2 control and audio
       i=Initial contact
       c=IN IP4 192.0.2.11


C-&gt;S:
       ACK sip:mresources@server.example.com SIP/2.0
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg2
       Max-Forwards:6
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:Sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       Call-ID:a84b4c76e66710
       CSeq:323123 ACK
       Content-Length:0
</pre></div>
<p id="section-14.1-4">The client requests the server to create a synthesizer resource
        control channel to do speech synthesis. This also adds a media stream
        to send the generated speech. Note that, in this example, the client
        requests a new MRCPv2 TCP stream between the client and the server. In
        the following requests, the client will ask to use the existing
        connection.</p>
<div id="section-14.1-5" class="artwork art-text" text-align="left"><pre>
C-&gt;S:
       INVITE sip:mresources@server.example.com SIP/2.0
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg3
       Max-Forwards:6
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       Call-ID:a84b4c76e66710
       CSeq:323124 INVITE
       Contact:&lt;sip:sarvi@client.example.com&gt;
       Content-Type:application/sdp
       Content-Length:...
       
       v=0
       o=sarvi 2614933546 2614933547 IN IP4 192.0.2.12
       s=Set up MRCPv2 control and audio
       i=Add TCP channel, synthesizer and one-way audio
       c=IN IP4 192.0.2.12
       t=0 0
       m=application 9  TCP/MRCPv2 1 
       a=setup:active
       a=connection:new
       a=resource:speechsynth 
       a=cmid:1
       m=audio 49170 RTP/AVP 0 96
       a=rtpmap:0 pcmu/8000
       a=rtpmap:96 telephone-event/8000 
       a=fmtp:96 0-15 
       a=recvonly 
       a=mid:1


S-&gt;C:
       SIP/2.0 200 OK
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg3;received=192.0.32.10
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       Call-ID:a84b4c76e66710
       CSeq:323124 INVITE
       Contact:&lt;sip:mresources@server.example.com&gt;
       Content-Type:application/sdp
       Content-Length:...
       
       v=0
       o=- 3000000001 3000000002 IN IP4 192.0.2.11
       s=Set up MRCPv2 control and audio
       i=Add TCP channel, synthesizer and one-way audio
       c=IN IP4 192.0.2.11
       t=0 0
       m=application 32416  TCP/MRCPv2 1 
       a=setup:passive
       a=connection:new
       a=channel:32AECB23433801@speechsynth 
       a=cmid:1
       m=audio 48260 RTP/AVP 0
       a=rtpmap:0 pcmu/8000
       a=sendonly 
       a=mid:1


C-&gt;S:
       ACK sip:mresources@server.example.com SIP/2.0
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg4
       Max-Forwards:6
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:Sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       Call-ID:a84b4c76e66710
       CSeq:323124 ACK
       Content-Length:0
</pre></div>
<p id="section-14.1-6">This exchange allocates an additional resource control channel for
        a recognizer. Since a recognizer would need to receive an audio stream
        for recognition, this interaction also updates the audio stream to
        sendrecv, making it a two-way audio stream.</p>
<div id="section-14.1-7" class="artwork art-text" text-align="left"><pre>
C-&gt;S:
       INVITE sip:mresources@server.example.com SIP/2.0
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg5
       Max-Forwards:6
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       Call-ID:a84b4c76e66710
       CSeq:323125 INVITE
       Contact:&lt;sip:sarvi@client.example.com&gt;
       Content-Type:application/sdp
       Content-Length:...
       
       v=0
       o=sarvi 2614933546 2614933548 IN IP4 192.0.2.12
       s=Set up MRCPv2 control and audio
       i=Add recognizer and duplex the audio
       c=IN IP4 192.0.2.12
       t=0 0
       m=application 9  TCP/MRCPv2 1 
       a=setup:active
       a=connection:existing
       a=resource:speechsynth 
       a=cmid:1
       m=audio 49170 RTP/AVP 0 96
       a=rtpmap:0 pcmu/8000
       a=rtpmap:96 telephone-event/8000 
       a=fmtp:96 0-15 
       a=recvonly 
       a=mid:1
       m=application 9  TCP/MRCPv2 1 
       a=setup:active
       a=connection:existing
       a=resource:speechrecog 
       a=cmid:2
       m=audio 49180 RTP/AVP 0 96
       a=rtpmap:0 pcmu/8000
       a=rtpmap:96 telephone-event/8000
       a=fmtp:96 0-15
       a=sendonly 
       a=mid:2


S-&gt;C:
       SIP/2.0 200 OK
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg5;received=192.0.32.10
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       Call-ID:a84b4c76e66710
       CSeq:323125 INVITE
       Contact:&lt;sip:mresources@server.example.com&gt;
       Content-Type:application/sdp
       Content-Length:...
       
       v=0
       o=- 3000000001 3000000003 IN IP4 192.0.2.11
       s=Set up MRCPv2 control and audio
       i=Add recognizer and duplex the audio
       c=IN IP4 192.0.2.11
       t=0 0
       m=application 32416  TCP/MRCPv2 1 
       a=channel:32AECB23433801@speechsynth 
       a=cmid:1
       m=audio 48260 RTP/AVP 0
       a=rtpmap:0 pcmu/8000
       a=sendonly 
       a=mid:1
       m=application 32416  TCP/MRCPv2 1 
       a=channel:32AECB23433801@speechrecog 
       a=cmid:2
       m=audio 48260 RTP/AVP 0
       a=rtpmap:0 pcmu/8000
       a=rtpmap:96 telephone-event/8000
       a=fmtp:96 0-15
       a=recvonly 
       a=mid:2


C-&gt;S:
       ACK sip:mresources@server.example.com SIP/2.0
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg6
       Max-Forwards:6
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       From:Sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       Call-ID:a84b4c76e66710
       CSeq:323125 ACK
       Content-Length:0
</pre></div>
<p id="section-14.1-8">A MRCPv2 SPEAK request initiates speech.</p>
<div id="section-14.1-9" class="artwork art-text" text-align="left"><pre>
C-&gt;S:
       MRCP/2.0 ... SPEAK 543257
       Channel-Identifier:32AECB23433801@speechsynth
       Kill-On-Barge-In:false
       Voice-gender:neutral
       Voice-age:25
       Prosody-volume:medium
       Content-Type:application/ssml+xml
       Content-Length:...
       
       &lt;?xml version="1.0"?&gt;
       &lt;speak version="1.0"                
              xmlns="http://www.w3.org/2001/10/synthesis"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
              http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
              xml:lang="en-US"&gt;
         &lt;p&gt;
           &lt;s&gt;You have 4 new messages.&lt;/s&gt;
           &lt;s&gt;The first is from Stephanie Williams 
             &lt;mark name="Stephanie"/&gt;
             and arrived at &lt;break/&gt;
             &lt;say-as interpret-as="vxml:time"&gt;0345p&lt;/say-as&gt;.&lt;/s&gt;
           &lt;s&gt;The subject is &lt;prosody
              rate="-20%"&gt;ski trip&lt;/prosody&gt;&lt;/s&gt;
         &lt;/p&gt;
       &lt;/speak&gt;

S-&gt;C:
       MRCP/2.0 ... 543257 200 IN-PROGRESS 
       Channel-Identifier:32AECB23433801@speechsynth
       Speech-Marker:timestamp=857205015059

</pre></div>
<p id="section-14.1-10">The synthesizer hits the special marker in the message to be spoken
        and faithfully informs the client of the event.</p>
<div id="section-14.1-11" class="artwork art-text" text-align="left"><pre>
S-&gt;C:  MRCP/2.0 ... SPEECH-MARKER 543257 IN-PROGRESS 
       Channel-Identifier:32AECB23433801@speechsynth
       Speech-Marker:timestamp=857206027059;Stephanie
</pre></div>
<p id="section-14.1-12">The synthesizer finishes with the SPEAK request.</p>
<div id="section-14.1-13" class="artwork art-text" text-align="left"><pre>
S-&gt;C:  MRCP/2.0 ... SPEAK-COMPLETE 543257 COMPLETE
       Channel-Identifier:32AECB23433801@speechsynth
       Speech-Marker:timestamp=857207685213;Stephanie

</pre></div>
<p id="section-14.1-14">The recognizer is issued a request to listen for the customer
        choices.</p>
<div id="section-14.1-15" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... RECOGNIZE 543258
       Channel-Identifier:32AECB23433801@speechrecog
       Content-Type:application/srgs+xml
       Content-Length:...
       
       &lt;?xml version="1.0"?&gt;
       &lt;!-- the default grammar language is US English --&gt;
       &lt;grammar xmlns="http://www.w3.org/2001/06/grammar"
                xml:lang="en-US" version="1.0" root="request"&gt;
       &lt;!-- single language attachment to a rule expansion --&gt;
         &lt;rule id="request"&gt;
           Can I speak to
           &lt;one-of xml:lang="fr-CA"&gt;
             &lt;item&gt;Michel Tremblay&lt;/item&gt;
             &lt;item&gt;Andre Roy&lt;/item&gt;
           &lt;/one-of&gt;
         &lt;/rule&gt;
       &lt;/grammar&gt;


S-&gt;C:  MRCP/2.0 ... 543258 200 IN-PROGRESS
       Channel-Identifier:32AECB23433801@speechrecog
</pre></div>
<p id="section-14.1-16">The client issues the next MRCPv2 SPEAK method.</p>
<div id="section-14.1-17" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  MRCP/2.0 ... SPEAK 543259
       Channel-Identifier:32AECB23433801@speechsynth
       Kill-On-Barge-In:true
       Content-Type:application/ssml+xml
       Content-Length:...
       
       &lt;?xml version="1.0"?&gt;
       &lt;speak version="1.0"                
              xmlns="http://www.w3.org/2001/10/synthesis"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
              http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
              xml:lang="en-US"&gt;
         &lt;p&gt;
           &lt;s&gt;Welcome to ABC corporation.&lt;/s&gt;
           &lt;s&gt;Who would you like to talk to?&lt;/s&gt;
         &lt;/p&gt;
       &lt;/speak&gt;

S-&gt;C:  MRCP/2.0 ... 543259 200 IN-PROGRESS
       Channel-Identifier:32AECB23433801@speechsynth
       Speech-Marker:timestamp=857207696314
</pre></div>
<p id="section-14.1-18">This next section of this ongoing example demonstrates how
        kill-on-barge-in support works. Since this last SPEAK request had
        Kill-On-Barge-In set to "true", when the recognizer (the server)
        generated the START-OF-INPUT event while a SPEAK was active, the client
        immediately issued a BARGE-IN-OCCURRED method to the synthesizer
        resource. The speech synthesizer then terminated playback and notified
        the client. The completion-cause code provided the indication that
        this was a kill-on-barge-in interruption rather than a normal
        completion.</p>
<p id="section-14.1-19">Note that, since the recognition and synthesizer resources are in
        the same session on the same server, to obtain a faster response the
        server might have internally relayed the start-of-input condition to
        the synthesizer directly, before receiving the expected
        BARGE-IN-OCCURRED event. However, any such communication is outside
        the scope of MRCPv2.</p>
<div id="section-14.1-20" class="artwork art-text" text-align="left"><pre>
S-&gt;C:  MRCP/2.0 ... START-OF-INPUT 543258 IN-PROGRESS
       Channel-Identifier:32AECB23433801@speechrecog
       Proxy-Sync-Id:987654321


C-&gt;S:  MRCP/2.0 ... BARGE-IN-OCCURRED 543259
       Channel-Identifier:32AECB23433801@speechsynth
       Proxy-Sync-Id:987654321


S-&gt;C:  MRCP/2.0 ... 543259 200 COMPLETE
       Channel-Identifier:32AECB23433801@speechsynth
       Active-Request-Id-List:543258
       Speech-Marker:timestamp=857206096314

S-&gt;C:  MRCP/2.0 ... SPEAK-COMPLETE 543259 COMPLETE
       Channel-Identifier:32AECB23433801@speechsynth
       Completion-Cause:001 barge-in
       Speech-Marker:timestamp=857207685213

</pre></div>
<p id="section-14.1-21">The recognizer resource matched the spoken stream to a grammar and
        generated results. The result of the recognition is returned by the
        server as part of the RECOGNITION-COMPLETE event.</p>
<div id="section-14.1-22" class="artwork art-text" text-align="left"><pre>
S-&gt;C:  MRCP/2.0 ... RECOGNITION-COMPLETE 543258 COMPLETE
       Channel-Identifier:32AECB23433801@speechrecog
       Completion-Cause:000 success    
       Waveform-URI:&lt;http://web.media.com/session123/audio.wav&gt;;
                    size=423523;duration=25432
       Content-Type:application/nlsml+xml
       Content-Length:...
       
       &lt;?xml version="1.0"?&gt;
       &lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
               xmlns:ex="http://www.example.com/example"
               grammar="session:request1@form-level.store"&gt;
           &lt;interpretation&gt;
               &lt;instance name="Person"&gt;
                   &lt;ex:Person&gt;
                       &lt;ex:Name&gt; Andre Roy &lt;/ex:Name&gt;
                   &lt;/ex:Person&gt;
               &lt;/instance&gt;
               &lt;input&gt;   may I speak to Andre Roy &lt;/input&gt;
           &lt;/interpretation&gt;
       &lt;/result&gt;
</pre></div>
<p id="section-14.1-23">Since the client was now finished with the session, including all
        resources, it issued a SIP BYE request to close the SIP session. This
        caused all control channels and resources allocated under the session
        to be deallocated.</p>
<div id="section-14.1-24" class="artwork art-text" text-align="left"><pre>
C-&gt;S:  BYE sip:mresources@server.example.com SIP/2.0
       Via:SIP/2.0/TCP client.atlanta.example.com:5060;
        branch=z9hG4bK74bg7
       Max-Forwards:6
       From:Sarvi &lt;sip:sarvi@example.com&gt;;tag=1928301774
       To:MediaServer &lt;sip:mresources@example.com&gt;;tag=62784
       Call-ID:a84b4c76e66710
       CSeq:323126 BYE
       Content-Length:0
</pre></div></section><section id="section-14.2"><h3 id="name-recognition-result-examples">
<a href="#section-14.2" class="section-number selfRef">14.2.Â </a><a href="#name-recognition-result-examples" class="section-name selfRef">Recognition Result Examples</a>
</h3>
<section id="section-14.2.1"><h4 id="name-simple-asr-ambiguity">
<a href="#section-14.2.1" class="section-number selfRef">14.2.1.Â </a><a href="#name-simple-asr-ambiguity" class="section-name selfRef">Simple ASR Ambiguity</a>
</h4>
<div id="section-14.2.1-1" class="artwork art-text" text-align="left"><pre>
System: To which city will you be traveling?
User:   I want to go to Pittsburgh.

&lt;?xml version="1.0"?&gt;  
&lt;result xmlns="urn:ietf:params:xml:ns:mrcpv2"
        xmlns:ex="http://www.example.com/example"
        grammar="http://www.example.com/flight"&gt;
  &lt;interpretation confidence="0.6"&gt;
     &lt;instance&gt;
        &lt;ex:airline&gt;
           &lt;ex:to_city&gt;Pittsburgh&lt;/ex:to_city&gt;
        &lt;ex:airline&gt;
     &lt;instance&gt;
     &lt;input mode="speech"&gt;
        I want to go to Pittsburgh
     &lt;/input&gt;
  &lt;/interpretation&gt;
  &lt;interpretation confidence="0.4"
     &lt;instance&gt;
        &lt;ex:airline&gt;
           &lt;ex:to_city&gt;Stockholm&lt;/ex:to_city&gt;
        &lt;/ex:airline&gt;
     &lt;/instance&gt;
     &lt;input&gt;I want to go to Stockholm&lt;/input&gt;
  &lt;/interpretation&gt;
&lt;/result&gt;
</pre></div></section><section id="section-14.2.2"><h4 id="name-mixed-initiative">
<a href="#section-14.2.2" class="section-number selfRef">14.2.2.Â </a><a href="#name-mixed-initiative" class="section-name selfRef">Mixed Initiative</a>
</h4>
<div id="section-14.2.2-1" class="artwork art-text" text-align="left"><pre>
System: What would you like?
User:   I would like 2 pizzas, one with pepperoni and cheese, 
        one with sausage and a bottle of coke, to go.
</pre></div>
<p id="section-14.2.2-2">This example includes an order object which in turn contains
          objects named "food_item", "drink_item", and "delivery_method". The
          representation assumes there are no ambiguities in the speech or
          natural language processing. Note that this representation also
          assumes some level of intra-sentential anaphora resolution, i.e., to
          resolve the two "one"s as "pizza".</p>
<div id="section-14.2.2-3" class="artwork art-text" text-align="left"><pre>
&lt;?xml version="1.0"?&gt;  
&lt;nl:result xmlns:nl="urn:ietf:params:xml:ns:mrcpv2"
           xmlns="http://www.example.com/example"
           grammar="http://www.example.com/foodorder"&gt;
  &lt;nl:interpretation confidence="1.0" &gt;
     &lt;nl:instance&gt;
      &lt;order&gt;
        &lt;food_item confidence="1.0"&gt;
          &lt;pizza&gt;
            &lt;ingredients confidence="1.0"&gt;
              pepperoni
            &lt;/ingredients&gt;
            &lt;ingredients confidence="1.0"&gt;
              cheese
            &lt;/ingredients&gt;
          &lt;/pizza&gt;
          &lt;pizza&gt;
            &lt;ingredients&gt;sausage&lt;/ingredients&gt;
          &lt;/pizza&gt;
        &lt;/food_item&gt;
        &lt;drink_item confidence="1.0"&gt;
          &lt;size&gt;2-liter&lt;/size&gt;
        &lt;/drink_item&gt;
        &lt;delivery_method&gt;to go&lt;/delivery_method&gt;
      &lt;/order&gt;
    &lt;/nl:instance&gt;
    &lt;nl:input mode="speech"&gt;I would like 2 pizzas,
         one with pepperoni and cheese, one with sausage
         and a bottle of coke, to go.
    &lt;/nl:input&gt;
  &lt;/nl:interpretation&gt;
&lt;/nl:result&gt;
</pre></div></section><section id="section-14.2.3"><h4 id="name-dtmf-input">
<a href="#section-14.2.3" class="section-number selfRef">14.2.3.Â </a><a href="#name-dtmf-input" class="section-name selfRef">DTMF Input</a>
</h4>
<p id="section-14.2.3-1">A combination of DTMF input and speech is represented using
          nested input elements. For example:</p>
<div id="section-14.2.3-2" class="artwork art-text" text-align="left"><pre>User: My pin is (dtmf 1 2 3 4)</pre></div>
<div id="section-14.2.3-3" class="artwork art-text" text-align="left"><pre>
&lt;input&gt;
  &lt;input mode="speech" confidence ="1.0"
     timestamp-start="2000-04-03T0:00:00" 
     timestamp-end="2000-04-03T0:00:01.5"&gt;My pin is
  &lt;/input&gt;
  &lt;input mode="dtmf" confidence ="1.0"
     timestamp-start="2000-04-03T0:00:01.5" 
     timestamp-end="2000-04-03T0:00:02.0"&gt;1 2 3 4
  &lt;/input&gt;
&lt;/input&gt;
</pre></div>
<p id="section-14.2.3-4">Note that grammars that recognize mixtures of speech and DTMF are
          not currently possible in SRGS; however, this representation might
          be needed for other applications of NLSML, and this mixture
          capability might be introduced in future versions of SRGS.</p></section><section id="section-14.2.4"><h4 id="name-interpreting-meta-dialog-an">
<a href="#section-14.2.4" class="section-number selfRef">14.2.4.Â </a><a href="#name-interpreting-meta-dialog-an" class="section-name selfRef">Interpreting Meta-Dialog and Meta-Task Utterances</a>
</h4>
<p id="section-14.2.4-1">Natural language communication makes use of meta-dialog and
          meta-task utterances. This specification is flexible enough so that
          meta-utterances can be represented on an application-specific basis
          without requiring other standard markup.</p>
<p id="section-14.2.4-2">Here are two examples of how meta-task and meta-dialog utterances
          might be represented.</p>
<div id="section-14.2.4-3" class="artwork art-text" text-align="left"><pre>
System: What toppings do you want on your pizza?
User:   What toppings do you have?

&lt;interpretation grammar="http://www.example.com/toppings"&gt;
   &lt;instance&gt;
      &lt;question&gt;
         &lt;questioned_item&gt;toppings&lt;questioned_item&gt;
         &lt;questioned_property&gt;
          availability
         &lt;/questioned_property&gt;
      &lt;/question&gt;
   &lt;/instance&gt;
   &lt;input mode="speech"&gt;
     what toppings do you have?
   &lt;/input&gt;
&lt;/interpretation&gt;


User:   slow down.

&lt;interpretation
   grammar="http://www.example.com/generalCommandsGrammar"&gt;
   &lt;instance&gt;
    &lt;command&gt;
       &lt;action&gt;reduce speech rate&lt;/action&gt;
       &lt;doer&gt;system&lt;/doer&gt;
    &lt;/command&gt;
   &lt;/instance&gt;
  &lt;input mode="speech"&gt;slow down&lt;/input&gt;
&lt;/interpretation&gt;
</pre></div></section><section id="section-14.2.5"><h4 id="name-anaphora-and-deixis">
<a href="#section-14.2.5" class="section-number selfRef">14.2.5.Â </a><a href="#name-anaphora-and-deixis" class="section-name selfRef">Anaphora and Deixis</a>
</h4>
<p id="section-14.2.5-1">This specification can be used on an application-specific basis
          to represent utterances that contain unresolved anaphoric and
          deictic references. Anaphoric references, which include pronouns and
          definite noun phrases that refer to something that was mentioned in
          the preceding linguistic context, and deictic references, which
          refer to something that is present in the non-linguistic context,
          present similar problems in that there may not be sufficient
          unambiguous linguistic context to determine what their exact role in
          the interpretation should be. In order to represent unresolved
          anaphora and deixis using this specification, one strategy would be
          for the developer to define a more surface-oriented representation
          that leaves the specific details of the interpretation of the
          reference open. (This assumes that a later component is responsible
          for actually resolving the reference).</p>
<div id="section-14.2.5-2" class="artwork art-text" text-align="left"><pre>
Example: (ignoring the issue of representing the input from the 
          pointing gesture.)

System: What do you want to drink?
User:   I want this. (clicks on picture of large root beer.)

&lt;?xml version="1.0"?&gt;  
&lt;nl:result xmlns:nl="urn:ietf:params:xml:ns:mrcpv2"
        xmlns="http://www.example.com/example"
        grammar="http://www.example.com/beverages.grxml"&gt;  
   &lt;nl:interpretation&gt;
      &lt;nl:instance&gt; 
       &lt;doer&gt;I&lt;/doer&gt;
       &lt;action&gt;want&lt;/action&gt;
       &lt;object&gt;this&lt;/object&gt;
      &lt;/nl:instance&gt;
      &lt;nl:input mode="speech"&gt;I want this&lt;/nl:input&gt;
   &lt;/nl:interpretation&gt;
&lt;/nl:result&gt;
</pre></div></section><section id="section-14.2.6"><h4 id="name-distinguishing-individual-i">
<a href="#section-14.2.6" class="section-number selfRef">14.2.6.Â </a><a href="#name-distinguishing-individual-i" class="section-name selfRef">Distinguishing Individual Items from Sets with One Member</a>
</h4>
<p id="section-14.2.6-1">For programming convenience, it is useful to be able to
          distinguish between individual items and sets containing one item in
          the XML representation of semantic results. For example, a pizza
          order might consist of exactly one pizza, but a pizza might contain
          zero or more toppings. Since there is no standard way of marking
          this distinction directly in XML, in the current framework, the
          developer is free to adopt any conventions that would convey this
          information in the XML markup. One strategy would be for the
          developer to wrap the set of items in a grouping element, as in the
          following example.</p>
<div id="section-14.2.6-2" class="artwork art-text" text-align="left"><pre>
&lt;order&gt;
   &lt;pizza&gt;
      &lt;topping-group&gt;
         &lt;topping&gt;mushrooms&lt;/topping&gt;
      &lt;/topping-group&gt;
   &lt;/pizza&gt;
   &lt;drink&gt;coke&lt;/drink&gt;
&lt;/order&gt;
</pre></div>
<p id="section-14.2.6-3">In this example, the programmer can assume that there is supposed
          to be exactly one pizza and one drink in the order, but the fact
          that there is only one topping is an accident of this particular
          pizza order.</p>
<p id="section-14.2.6-4">Note that the client controls both the grammar and the semantics
          to be returned upon grammar matches, so the user of MRCPv2
           is fully empowered to cause results to be returned in NLSML
          in such a way that the interpretation is clear to that user.</p></section><section id="section-14.2.7"><h4 id="name-extensibility">
<a href="#section-14.2.7" class="section-number selfRef">14.2.7.Â </a><a href="#name-extensibility" class="section-name selfRef">Extensibility</a>
</h4>
<p id="section-14.2.7-1">Extensibility in NLSML is provided via result content
          flexibility, as described in the discussions of meta-utterances and
          anaphora. NLSML can easily be used in sophisticated systems to
          convey application-specific information that more basic systems
          would not make use of, for example, defining speech acts.</p></section></section></section><section id="section-15"><div id="S.abnf">
<h2 id="name-abnf-normative-definition">
<a href="#section-15" class="section-number selfRef">15.Â </a><a href="#name-abnf-normative-definition" class="section-name selfRef">ABNF Normative Definition</a>
</h2>
<p id="section-15-1">The following productions make use of the core rules defined in
      Section B.1 of <span>[<a href="#RFC5234" class="xref">RFC 5234</a>].</span></p>
<div id="section-15-2" class="artwork art-text" text-align="left"><pre>
LWS    =    [*WSP CRLF] 1*WSP ; linear whitespace

SWS    =    [LWS] ; sep whitespace

UTF8-NONASCII    =    %xC0-DF 1UTF8-CONT 
                 /    %xE0-EF 2UTF8-CONT
                 /    %xF0-F7 3UTF8-CONT
                 /    %xF8-FB 4UTF8-CONT
                 /    %xFC-FD 5UTF8-CONT

UTF8-CONT        =    %x80-BF
UTFCHAR          =    %x21-7E
                 /    UTF8-NONASCII
param            =    *pchar

quoted-string    =    SWS DQUOTE *(qdtext / quoted-pair ) 
                      DQUOTE

qdtext           =    LWS / %x21 / %x23-5B / %x5D-7E
                 /    UTF8-NONASCII

quoted-pair      =    "\" (%x00-09 / %x0B-0C / %x0E-7F)

token            =    1*(alphanum / "-" / "." / "!" / "%" / "*"
                      / "_" / "+" / "`" / "'" / "~" )

reserved         =    ";" / "/" / "?" / ":" / "@" / "&amp;" / "=" 
                      / "+" / "$" / ","

mark             =    "-" / "_" / "." / "!" / "~" / "*" / "'"
                 /    "(" / ")"

unreserved       =    alphanum / mark

pchar            =    unreserved / escaped
                 /    ":" / "@" / "&amp;" / "=" / "+" / "$" / ","

alphanum         =    ALPHA / DIGIT

BOOLEAN          =    "true" / "false" 

FLOAT            =    *DIGIT ["." *DIGIT]

escaped          =    "%" HEXDIG HEXDIG

fragment         =    *uric

uri              =    [ absoluteURI / relativeURI ] 
                      [ "#" fragment ]

absoluteURI      =    scheme ":" ( hier-part / opaque-part )

relativeURI      =    ( net-path / abs-path / rel-path ) 
                      [ "?" query ]

hier-part        =    ( net-path / abs-path ) [ "?" query ]

net-path         =    "//" authority [ abs-path ]

abs-path         =    "/" path-segments

rel-path         =    rel-segment [ abs-path ]

rel-segment      =    1*( unreserved / escaped / ";" / "@" 
                 /    "&amp;" / "=" / "+" / "$" / "," )    

opaque-part      =    uric-no-slash *uric

uric             =    reserved / unreserved / escaped

uric-no-slash    =    unreserved / escaped / ";" / "?" / ":" 
                      / "@" / "&amp;" / "=" / "+" / "$" / ","

path-segments    =    segment *( "/" segment )

segment          =    *pchar *( ";" param )

scheme           =    ALPHA *( ALPHA / DIGIT / "+" / "-" / "." )

authority        =    srvr / reg-name

srvr             =    [ [ userinfo "@" ] hostport ]

reg-name         =    1*( unreserved / escaped / "$" / ","
                 /     ";" / ":" / "@" / "&amp;" / "=" / "+" )

query            =    *uric

userinfo         =    ( user ) [ ":" password ] "@"

user             =    1*( unreserved / escaped 
                 /    user-unreserved )

user-unreserved  =    "&amp;" / "=" / "+" / "$" / "," / ";" 
                 /    "?" / "/"

password         =    *( unreserved / escaped 
                 /    "&amp;" / "=" / "+" / "$" / "," )

hostport         =    host [ ":" port ]

host             =    hostname / IPv4address / IPv6reference

hostname         =    *( domainlabel "." ) toplabel [ "." ]

domainlabel      =    alphanum / alphanum *( alphanum / "-" )
                      alphanum

toplabel         =    ALPHA / ALPHA *( alphanum / "-" )
                      alphanum

IPv4address      =    1*3DIGIT "." 1*3DIGIT "." 1*3DIGIT "." 
                      1*3DIGIT

IPv6reference    =    "[" IPv6address "]"

IPv6address      =    hexpart [ ":" IPv4address ]

hexpart          =    hexseq / hexseq "::" [ hexseq ] / "::" 
                      [ hexseq ]

hexseq           =    hex4 *( ":" hex4)

hex4             =    1*4HEXDIG

port             =    1*19DIGIT


; generic-message is the top-level rule
generic-message  =    start-line message-header CRLF 
                      [ message-body ] 

message-body     =    *OCTET
         
start-line       =    request-line / response-line / event-line 

request-line     =    mrcp-version SP message-length SP method-name
                      SP request-id CRLF 

response-line    =    mrcp-version SP message-length SP request-id 
                      SP status-code SP request-state CRLF 

event-line       =    mrcp-version SP message-length SP event-name
                      SP request-id SP request-state CRLF 

method-name      =    generic-method    
                 /    synthesizer-method
                 /    recognizer-method
                 /    recorder-method
                 /    verifier-method

generic-method   =    "SET-PARAMS"
                 /    "GET-PARAMS"

request-state    =    "COMPLETE" 
                 /    "IN-PROGRESS"        
                 /    "PENDING" 

event-name       =    synthesizer-event
                 /    recognizer-event
                 /    recorder-event
                 /    verifier-event
      
message-header   =  1*(generic-header / resource-header /
                       generic-field)

generic-field    =    field-name ":" [ field-value ]
field-name       =    token
field-value      =    *LWS field-content *( CRLF 1*LWS field-content)
field-content    =    &lt;the OCTETs making up the field-value
                      and consisting of either *TEXT or combinations
                      of token, separators, and quoted-string&gt;

resource-header  =    synthesizer-header
                 /    recognizer-header
                 /    recorder-header
                 /    verifier-header    

generic-header   =    channel-identifier
                 /    accept
                 /    active-request-id-list
                 /    proxy-sync-id
                 /    accept-charset
                 /    content-type
                 /    content-id
                 /    content-base
                 /    content-encoding
                 /    content-location
                 /    content-length
                 /    fetch-timeout
                 /    cache-control
                 /    logging-tag 
                 /    set-cookie
                 /    vendor-specific
          
; -- content-id is as defined in RFC 2392, RFC 2046 and RFC 5322
; -- accept and accept-charset are as defined in RFC 2616

mrcp-version     =    "MRCP" "/" 1*2DIGIT "." 1*2DIGIT 

message-length   =    1*19DIGIT

request-id       =    1*10DIGIT 

status-code      =    3DIGIT

channel-identifier =  "Channel-Identifier" ":" 
                      channel-id CRLF

channel-id       =    1*alphanum "@" 1*alphanum

active-request-id-list = "Active-Request-Id-List" ":"  
                         request-id *("," request-id) CRLF 

proxy-sync-id    =    "Proxy-Sync-Id" ":" 1*VCHAR CRLF    

content-base     =    "Content-Base" ":" absoluteURI CRLF

content-length   =    "Content-Length" ":" 1*19DIGIT CRLF

content-type     =    "Content-Type" ":" media-type-value CRLF

media-type-value =    type "/" subtype *( ";" parameter )

type             =    token

subtype          =    token

parameter        =    attribute "=" value

attribute        =    token

value            =    token / quoted-string
         
content-encoding =    "Content-Encoding" ":" 
                      *WSP content-coding
                      *(*WSP "," *WSP content-coding *WSP )
                      CRLF

content-coding   =    token


content-location =    "Content-Location" ":" 
                      ( absoluteURI / relativeURI )  CRLF

cache-control    =    "Cache-Control" ":" 
                      [*WSP cache-directive
                      *( *WSP "," *WSP cache-directive *WSP )]
                      CRLF

fetch-timeout    =    "Fetch-Timeout" ":" 1*19DIGIT CRLF 

cache-directive  =    "max-age" "=" delta-seconds     
                 /    "max-stale" ["=" delta-seconds ] 
                 /    "min-fresh" "=" delta-seconds  

delta-seconds         =    1*19DIGIT     

logging-tag      =    "Logging-Tag" ":" 1*UTFCHAR CRLF 

vendor-specific  =    "Vendor-Specific-Parameters" ":" 
                      [vendor-specific-av-pair  
                      *(";" vendor-specific-av-pair)] CRLF  

vendor-specific-av-pair = vendor-av-pair-name "="  
                          value 

vendor-av-pair-name     = 1*UTFCHAR

set-cookie        = "Set-Cookie:" SP set-cookie-string
set-cookie-string = cookie-pair *( ";" SP cookie-av )
cookie-pair       = cookie-name "=" cookie-value
cookie-name       = token
cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )
cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E
token             = &lt;token, defined in [RFC2616], Section 2.2&gt;

cookie-av         = expires-av / max-age-av / domain-av /
                     path-av / secure-av / httponly-av /
                     extension-av / age-av
expires-av        = "Expires=" sane-cookie-date
sane-cookie-date  = &lt;rfc1123-date, from [RFC2616], Section 3.3.1&gt;
max-age-av        = "Max-Age=" non-zero-digit *DIGIT
non-zero-digit    = %x31-39
domain-av         = "Domain=" domain-value
domain-value      = &lt;subdomain&gt;
path-av           = "Path=" path-value
path-value        = &lt;any CHAR except CTLs or ";"&gt;
secure-av         = "Secure"
httponly-av       = "HttpOnly"
extension-av      = &lt;any CHAR except CTLs or ";"&gt;
age-av            = "Age=" delta-seconds
                          
; Synthesizer ABNF

synthesizer-method    =    "SPEAK" 
                      /    "STOP" 
                      /    "PAUSE" 
                      /    "RESUME" 
                      /    "BARGE-IN-OCCURRED" 
                      /    "CONTROL"
                      /    "DEFINE-LEXICON" 

synthesizer-event     =    "SPEECH-MARKER" 
                      /    "SPEAK-COMPLETE" 

synthesizer-header    =    jump-size       
                      /    kill-on-barge-in  
                      /    speaker-profile   
                      /    completion-cause
                      /    completion-reason  
                      /    voice-parameter   
                      /    prosody-parameter   
                      /    speech-marker     
                      /    speech-language   
                      /    fetch-hint        
                      /    audio-fetch-hint  
                      /    failed-uri        
                      /    failed-uri-cause  
                      /    speak-restart     
                      /    speak-length
                      /    load-lexicon
                      /    lexicon-search-order      


jump-size             =    "Jump-Size" ":" speech-length-value CRLF 

speech-length-value   =    numeric-speech-length 
                      /    text-speech-length 

text-speech-length    =    1*UTFCHAR SP "Tag" 
                               
numeric-speech-length =    ("+" / "-") positive-speech-length

positive-speech-length =   1*19DIGIT SP numeric-speech-unit
 
numeric-speech-unit   =    "Second" 
                      /    "Word" 
                      /    "Sentence" 
                      /    "Paragraph" 

kill-on-barge-in      =    "Kill-On-Barge-In" ":" BOOLEAN 
                           CRLF 

speaker-profile       =    "Speaker-Profile" ":" uri CRLF 

completion-cause         =  "Completion-Cause" ":" cause-code SP
                            cause-name CRLF
cause-code               =  3DIGIT
cause-name               =  *VCHAR

completion-reason     =    "Completion-Reason" ":" 
                           quoted-string CRLF

voice-parameter       =    voice-gender
                      /    voice-age
                      /    voice-variant
                      /    voice-name

voice-gender          =    "Voice-Gender:" voice-gender-value CRLF

voice-gender-value    =    "male"
                      /    "female"
                      /    "neutral"

voice-age             =    "Voice-Age:" 1*3DIGIT CRLF

voice-variant         =    "Voice-Variant:" 1*19DIGIT CRLF

voice-name            =    "Voice-Name:"
                           1*UTFCHAR *(1*WSP 1*UTFCHAR) CRLF

prosody-parameter     =    "Prosody-" prosody-param-name ":" 
                           prosody-param-value CRLF 

prosody-param-name    =    1*VCHAR

prosody-param-value   =    1*VCHAR

timestamp             =    "timestamp" "=" time-stamp-value

time-stamp-value      =    1*20DIGIT

speech-marker         =    "Speech-Marker" ":"
                           timestamp
                           [";" 1*(UTFCHAR / %x20)] CRLF

speech-language       =    "Speech-Language" ":"
                           1*VCHAR CRLF 

fetch-hint            =    "Fetch-Hint" ":"
                           ("prefetch" / "safe") CRLF 

audio-fetch-hint      =    "Audio-Fetch-Hint" ":" 
                          ("prefetch" / "safe" / "stream") CRLF 

failed-uri            =    "Failed-URI" ":" absoluteURI CRLF 

failed-uri-cause      =    "Failed-URI-Cause" ":" 1*UTFCHAR CRLF 

speak-restart         =    "Speak-Restart" ":" BOOLEAN CRLF 

speak-length          =    "Speak-Length" ":" positive-length-value 
                           CRLF 

positive-length-value   =  positive-speech-length 
                        /  text-speech-length 

load-lexicon          =    "Load-Lexicon" ":" BOOLEAN CRLF

lexicon-search-order  =    "Lexicon-Search-Order" ":" 
          "&lt;" absoluteURI "&gt;" *(" " "&lt;" absoluteURI "&gt;") CRLF

; Recognizer ABNF 

recognizer-method     =    recog-only-method
                      /    enrollment-method

recog-only-method     =    "DEFINE-GRAMMAR" 
                      /    "RECOGNIZE" 
                      /    "INTERPRET"
                      /    "GET-RESULT" 
                      /    "START-INPUT-TIMERS" 
                      /    "STOP"

enrollment-method     =    "START-PHRASE-ENROLLMENT" 
                      /    "ENROLLMENT-ROLLBACK"
                      /    "END-PHRASE-ENROLLMENT"
                      /    "MODIFY-PHRASE"
                      /    "DELETE-PHRASE"

recognizer-event      =    "START-OF-INPUT"
                      /    "RECOGNITION-COMPLETE"
                      /    "INTERPRETATION-COMPLETE"

recognizer-header     =    recog-only-header
                      /    enrollment-header


recog-only-header     =    confidence-threshold     
                      /    sensitivity-level        
                      /    speed-vs-accuracy        
                      /    n-best-list-length  
                      /    input-type     
                      /    no-input-timeout         
                      /    recognition-timeout      
                      /    waveform-uri  
                      /    input-waveform-uri           
                      /    completion-cause         
                      /    completion-reason
                      /    recognizer-context-block 
                      /    start-input-timers 
                      /    speech-complete-timeout  
                      /    speech-incomplete-timeout 
                      /    dtmf-interdigit-timeout  
                      /    dtmf-term-timeout        
                      /    dtmf-term-char           
                      /    failed-uri               
                      /    failed-uri-cause         
                      /    save-waveform            
                      /    media-type
                      /    new-audio-channel
                      /    speech-language        
                      /    ver-buffer-utterance
                      /    recognition-mode
                      /    cancel-if-queue
                      /    hotword-max-duration
                      /    hotword-min-duration
                      /    interpret-text
                      /    dtmf-buffer-time
                      /    clear-dtmf-buffer
                      /    early-no-match


enrollment-header     =    num-min-consistent-pronunciations
                      /    consistency-threshold  
                      /    clash-threshold        
                      /    personal-grammar-uri 
                      /    enroll-utterance
                      /    phrase-id              
                      /    phrase-nl              
                      /    weight                 
                      /    save-best-waveform     
                      /    new-phrase-id          
                      /    confusable-phrases-uri 
                      /    abort-phrase-enrollment

confidence-threshold  =    "Confidence-Threshold" ":" 
                           FLOAT CRLF 

sensitivity-level     =    "Sensitivity-Level" ":" FLOAT
                           CRLF 

speed-vs-accuracy     =    "Speed-Vs-Accuracy" ":" FLOAT 
                           CRLF 

n-best-list-length    =    "N-Best-List-Length" ":" 1*19DIGIT 
                           CRLF 

input-type            =    "Input-Type" ":"  inputs CRLF
inputs                =    "speech" / "dtmf"

no-input-timeout      =    "No-Input-Timeout" ":" 1*19DIGIT 
                           CRLF 

recognition-timeout   =    "Recognition-Timeout" ":" 1*19DIGIT
                           CRLF 

waveform-uri          =    "Waveform-URI" ":" ["&lt;" uri "&gt;" 
                           ";" "size" "=" 1*19DIGIT 
                           ";" "duration" "=" 1*19DIGIT] CRLF 

recognizer-context-block = "Recognizer-Context-Block" ":" 
                           [1*VCHAR] CRLF 

start-input-timers    =    "Start-Input-Timers" ":"  
                           BOOLEAN CRLF 
 
speech-complete-timeout =  "Speech-Complete-Timeout" ":"  
                           1*19DIGIT CRLF 

speech-incomplete-timeout = "Speech-Incomplete-Timeout" ":"  
                            1*19DIGIT CRLF 

dtmf-interdigit-timeout = "DTMF-Interdigit-Timeout" ":"  
                          1*19DIGIT CRLF 

dtmf-term-timeout     =    "DTMF-Term-Timeout" ":" 1*19DIGIT 
                           CRLF 

dtmf-term-char        =    "DTMF-Term-Char" ":" VCHAR CRLF 

save-waveform         =    "Save-Waveform" ":" BOOLEAN CRLF 

new-audio-channel     =    "New-Audio-Channel" ":" 
                           BOOLEAN CRLF

recognition-mode      =    "Recognition-Mode" ":"
                           "normal" / "hotword" CRLF

cancel-if-queue       =    "Cancel-If-Queue" ":" BOOLEAN CRLF

hotword-max-duration  =    "Hotword-Max-Duration" ":" 
                           1*19DIGIT CRLF

hotword-min-duration  =    "Hotword-Min-Duration" ":" 
                           1*19DIGIT CRLF

interpret-text        =    "Interpret-Text" ":" 1*VCHAR CRLF          

dtmf-buffer-time      =    "DTMF-Buffer-Time" ":" 1*19DIGIT CRLF

clear-dtmf-buffer     =    "Clear-DTMF-Buffer" ":" BOOLEAN CRLF

early-no-match        =    "Early-No-Match" ":" BOOLEAN CRLF

num-min-consistent-pronunciations    = 
    "Num-Min-Consistent-Pronunciations" ":" 1*19DIGIT CRLF 


consistency-threshold =    "Consistency-Threshold" ":" FLOAT 
                           CRLF
 
clash-threshold       =    "Clash-Threshold" ":" FLOAT CRLF

personal-grammar-uri  =    "Personal-Grammar-URI" ":" uri CRLF

enroll-utterance      =    "Enroll-Utterance" ":" BOOLEAN CRLF

phrase-id             =    "Phrase-ID" ":" 1*VCHAR CRLF

phrase-nl             =    "Phrase-NL" ":" 1*UTFCHAR CRLF

weight                =    "Weight" ":" FLOAT CRLF

save-best-waveform    =    "Save-Best-Waveform" ":" 
                           BOOLEAN CRLF

new-phrase-id         =    "New-Phrase-ID" ":" 1*VCHAR CRLF

confusable-phrases-uri =   "Confusable-Phrases-URI" ":" 
                           uri CRLF

abort-phrase-enrollment =  "Abort-Phrase-Enrollment" ":" 
                           BOOLEAN CRLF


; Recorder ABNF

recorder-method       =    "RECORD"
                      /    "STOP"
                      /    "START-INPUT-TIMERS"

recorder-event        =    "START-OF-INPUT"
                      /    "RECORD-COMPLETE"

recorder-header       =    sensitivity-level
                      /    no-input-timeout
                      /    completion-cause
                      /    completion-reason
                      /    failed-uri
                      /    failed-uri-cause
                      /    record-uri
                      /    media-type
                      /    max-time
                      /    trim-length
                      /    final-silence
                      /    capture-on-speech
                      /    ver-buffer-utterance
                      /    start-input-timers 
                      /    new-audio-channel

record-uri            =    "Record-URI" ":" [ "&lt;" uri "&gt;" 
                           ";" "size" "=" 1*19DIGIT 
                           ";" "duration" "=" 1*19DIGIT] CRLF

media-type            =    "Media-Type" ":" media-type-value CRLF

max-time              =    "Max-Time" ":" 1*19DIGIT CRLF

trim-length           =    "Trim-Length" ":" 1*19DIGIT CRLF

final-silence         =    "Final-Silence" ":" 1*19DIGIT CRLF

capture-on-speech     =    "Capture-On-Speech " ":" 
                           BOOLEAN CRLF


; Verifier ABNF

verifier-method       =    "START-SESSION"
                      /    "END-SESSION"
                      /    "QUERY-VOICEPRINT"
                      /    "DELETE-VOICEPRINT"
                      /    "VERIFY"
                      /    "VERIFY-FROM-BUFFER"
                      /    "VERIFY-ROLLBACK"
                      /    "STOP"
                      /    "CLEAR-BUFFER"
                      /    "START-INPUT-TIMERS"
                      /    "GET-INTERMEDIATE-RESULT"


verifier-event        =    "VERIFICATION-COMPLETE"
                      /    "START-OF-INPUT"


verifier-header       =    repository-uri 
                      /    voiceprint-identifier
                      /    verification-mode 
                      /    adapt-model 
                      /    abort-model 
                      /    min-verification-score         
                      /    num-min-verification-phrases
                      /    num-max-verification-phrases
                      /    no-input-timeout           
                      /    save-waveform              
                      /    media-type
                      /    waveform-uri               
                      /    voiceprint-exists          
                      /    ver-buffer-utterance    
                      /    input-waveform-uri        
                      /    completion-cause           
                      /    completion-reason
                      /    speech-complete-timeout          
                      /    new-audio-channel
                      /    abort-verification
                      /    start-input-timers 
                      /    input-type



repository-uri        =    "Repository-URI" ":" uri CRLF

voiceprint-identifier        =  "Voiceprint-Identifier" ":" 
                                vid *[";" vid] CRLF
vid                          =  1*VCHAR ["." 1*VCHAR]

verification-mode     =    "Verification-Mode" ":" 
                           verification-mode-string

verification-mode-string = "train" / "verify"

adapt-model           =    "Adapt-Model" ":" BOOLEAN CRLF

abort-model           =    "Abort-Model" ":" BOOLEAN CRLF

min-verification-score  =  "Min-Verification-Score" ":" 
                           [ %x2D ] FLOAT CRLF

num-min-verification-phrases = "Num-Min-Verification-Phrases" 
                               ":" 1*19DIGIT CRLF

num-max-verification-phrases = "Num-Max-Verification-Phrases" 
                               ":" 1*19DIGIT CRLF
     
voiceprint-exists     =    "Voiceprint-Exists" ":" 
                           BOOLEAN CRLF

ver-buffer-utterance  =    "Ver-Buffer-Utterance" ":" 
                           BOOLEAN CRLF 

input-waveform-uri    =    "Input-Waveform-URI" ":" uri CRLF

abort-verification    =    "Abort-Verification " ":" 
                           BOOLEAN CRLF </pre></div>
<p id="section-15-3">The following productions add a new SDP session-level attribute. See
      <a href="#cmid" class="xref">Section 13.7.2</a>.</p>
<div id="section-15-4" class="artwork art-text" text-align="left"><pre>
cmid-attribute     =    "a=cmid:" identification-tag

identification-tag =    token
</pre></div>
</div></section><section id="section-16"><h2 id="name-xml-schemas">
<a href="#section-16" class="section-number selfRef">16.Â </a><a href="#name-xml-schemas" class="section-name selfRef">XML Schemas</a>
</h2>
<section id="section-16.1"><div id="sec.schema.NLSML">
<h3 id="name-nlsml-schema-definition">
<a href="#section-16.1" class="section-number selfRef">16.1.Â </a><a href="#name-nlsml-schema-definition" class="section-name selfRef">NLSML Schema Definition</a>
</h3>
<div id="section-16.1-1" class="artwork art-text" text-align="left"><pre>
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema" 
            targetNamespace="urn:ietf:params:xml:ns:mrcpv2"
            xmlns="urn:ietf:params:xml:ns:mrcpv2"
            elementFormDefault="qualified" 
            attributeFormDefault="unqualified" &gt;
  &lt;xs:annotation&gt;
    &lt;xs:documentation&gt; Natural Language Semantic Markup Schema 
    &lt;/xs:documentation&gt;
  &lt;/xs:annotation&gt;
  &lt;xs:include schemaLocation="enrollment-schema.rng"/&gt;
  &lt;xs:include schemaLocation="verification-schema.rng"/&gt;
  &lt;xs:element name="result"&gt;
    &lt;xs:complexType&gt;
      &lt;xs:sequence&gt;
        &lt;xs:element name="interpretation" maxOccurs="unbounded"&gt;
          &lt;xs:complexType&gt;
            &lt;xs:sequence&gt;
              &lt;xs:element name="instance"&gt;
                &lt;xs:complexType mixed="true"&gt;
                  &lt;xs:sequence minOccurs="0"&gt;
                    &lt;xs:any namespace="##other"
                            processContents="lax"/&gt;
                  &lt;/xs:sequence&gt;
                &lt;/xs:complexType&gt;
              &lt;/xs:element&gt;
              &lt;xs:element name="input" minOccurs="0"&gt;
                &lt;xs:complexType mixed="true"&gt;
                  &lt;xs:choice&gt;
                    &lt;xs:element name="noinput" minOccurs="0"/&gt;
                    &lt;xs:element name="nomatch" minOccurs="0"/&gt;
                    &lt;xs:element name="input" minOccurs="0"/&gt;
                  &lt;/xs:choice&gt;
                  &lt;xs:attribute name="mode"
                                type="xs:string"
                                default="speech"/&gt;
                  &lt;xs:attribute name="confidence" 
                                type="confidenceinfo" 
                                default="1.0"/&gt;
                  &lt;xs:attribute name="timestamp-start" 
                                type="xs:string"/&gt;
                  &lt;xs:attribute name="timestamp-end" 
                                type="xs:string"/&gt;
                &lt;/xs:complexType&gt;
              &lt;/xs:element&gt;
            &lt;/xs:sequence&gt;
            &lt;xs:attribute name="confidence" type="confidenceinfo"
                          default="1.0"/&gt;
            &lt;xs:attribute name="grammar" type="xs:anyURI"
                          use="optional"/&gt;
          &lt;/xs:complexType&gt;
        &lt;/xs:element&gt;
        &lt;xs:element name="enrollment-result"
                    type="enrollment-contents"/&gt;
        &lt;xs:element name="verification-result"
                    type="verification-contents"/&gt;
      &lt;/xs:sequence&gt;
      &lt;xs:attribute name="grammar" type="xs:anyURI" 
                    use="optional"/&gt;
    &lt;/xs:complexType&gt;
  &lt;/xs:element&gt;

  &lt;xs:simpleType name="confidenceinfo"&gt;
    &lt;xs:restriction base="xs:float"&gt;
       &lt;xs:minInclusive value="0.0"/&gt;
       &lt;xs:maxInclusive value="1.0"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;
&lt;/xs:schema&gt;
</pre></div>
</div></section><section id="section-16.2"><div id="sec.enrollmentResultsSchema">
<h3 id="name-enrollment-results-schema-d">
<a href="#section-16.2" class="section-number selfRef">16.2.Â </a><a href="#name-enrollment-results-schema-d" class="section-name selfRef">Enrollment Results Schema Definition</a>
</h3>
<div id="section-16.2-1" class="artwork art-text" text-align="left"><pre>&lt;?xml version="1.0" encoding="UTF-8"?&gt;

&lt;!-- MRCP Enrollment Schema
(See http://www.oasis-open.org/committees/relax-ng/spec.html)
--&gt;

&lt;grammar datatypeLibrary="http://www.w3.org/2001/XMLSchema-datatypes"
         ns="urn:ietf:params:xml:ns:mrcpv2"
         xmlns="http://relaxng.org/ns/structure/1.0"&gt;

  &lt;start&gt;
    &lt;element name="enrollment-result"&gt;
      &lt;ref name="enrollment-content"/&gt;
    &lt;/element&gt;
  &lt;/start&gt;

  &lt;define name="enrollment-content"&gt;
    &lt;interleave&gt;
      &lt;element name="num-clashes"&gt;
        &lt;data type="nonNegativeInteger"/&gt;
      &lt;/element&gt;
      &lt;element name="num-good-repetitions"&gt;
        &lt;data type="nonNegativeInteger"/&gt;
      &lt;/element&gt;
      &lt;element name="num-repetitions-still-needed"&gt;
        &lt;data type="nonNegativeInteger"/&gt;
      &lt;/element&gt;
      &lt;element name="consistency-status"&gt;
        &lt;choice&gt;
          &lt;value&gt;consistent&lt;/value&gt;
          &lt;value&gt;inconsistent&lt;/value&gt;
          &lt;value&gt;undecided&lt;/value&gt;
        &lt;/choice&gt;
      &lt;/element&gt;
      &lt;optional&gt;
        &lt;element name="clash-phrase-ids"&gt;
          &lt;oneOrMore&gt;
            &lt;element name="item"&gt;
              &lt;data type="token"/&gt;
            &lt;/element&gt;
          &lt;/oneOrMore&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;optional&gt;
        &lt;element name="transcriptions"&gt;
          &lt;oneOrMore&gt;
            &lt;element name="item"&gt;
              &lt;text/&gt;
            &lt;/element&gt;
          &lt;/oneOrMore&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;optional&gt;
        &lt;element name="confusable-phrases"&gt;
          &lt;oneOrMore&gt;
            &lt;element name="item"&gt;
              &lt;text/&gt;
            &lt;/element&gt;
          &lt;/oneOrMore&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
    &lt;/interleave&gt;
  &lt;/define&gt;

&lt;/grammar&gt;
</pre></div>
</div></section><section id="section-16.3"><div id="sec.verificationResultsSchema">
<h3 id="name-verification-results-schema">
<a href="#section-16.3" class="section-number selfRef">16.3.Â </a><a href="#name-verification-results-schema" class="section-name selfRef">Verification Results Schema Definition</a>
</h3>
<div id="section-16.3-1" class="artwork art-text" text-align="left"><pre>&lt;?xml version="1.0" encoding="UTF-8"?&gt;

&lt;!--    MRCP Verification Results Schema 
        (See http://www.oasis-open.org/committees/relax-ng/spec.html)
   --&gt;

&lt;grammar datatypeLibrary="http://www.w3.org/2001/XMLSchema-datatypes"
         ns="urn:ietf:params:xml:ns:mrcpv2"
         xmlns="http://relaxng.org/ns/structure/1.0"&gt;

  &lt;start&gt;
    &lt;element name="verification-result"&gt;
      &lt;ref name="verification-contents"/&gt;
    &lt;/element&gt;
  &lt;/start&gt;

  &lt;define name="verification-contents"&gt;
    &lt;element name="voiceprint"&gt;
      &lt;ref name="firstVoiceprintContent"/&gt;
    &lt;/element&gt;
    &lt;zeroOrMore&gt;
      &lt;element name="voiceprint"&gt;
        &lt;ref name="restVoiceprintContent"/&gt;
      &lt;/element&gt;
    &lt;/zeroOrMore&gt;
  &lt;/define&gt;

  &lt;define name="firstVoiceprintContent"&gt;
    &lt;attribute name="id"&gt;
      &lt;data type="string"/&gt;
    &lt;/attribute&gt;
    &lt;interleave&gt;
      &lt;optional&gt;
        &lt;element name="adapted"&gt;
          &lt;data type="boolean"/&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;optional&gt;
        &lt;element name="needmoredata"&gt;
          &lt;ref name="needmoredataContent"/&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;optional&gt;
        &lt;element name="incremental"&gt;
          &lt;ref name="firstCommonContent"/&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;element name="cumulative"&gt;
        &lt;ref name="firstCommonContent"/&gt;
      &lt;/element&gt;
    &lt;/interleave&gt;
  &lt;/define&gt;

  &lt;define name="restVoiceprintContent"&gt;
    &lt;attribute name="id"&gt;
      &lt;data type="string"/&gt;
    &lt;/attribute&gt;
    &lt;element name="cumulative"&gt;
      &lt;ref name="restCommonContent"/&gt;
    &lt;/element&gt;
  &lt;/define&gt;

  &lt;define name="firstCommonContent"&gt;
    &lt;interleave&gt;
      &lt;element name="decision"&gt;
        &lt;ref name="decisionContent"/&gt;
      &lt;/element&gt;
      &lt;optional&gt;
        &lt;element name="utterance-length"&gt;
          &lt;ref name="utterance-lengthContent"/&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;optional&gt;
        &lt;element name="device"&gt;
          &lt;ref name="deviceContent"/&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;optional&gt;
        &lt;element name="gender"&gt;
          &lt;ref name="genderContent"/&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;zeroOrMore&gt;
        &lt;element name="verification-score"&gt;
          &lt;ref name="verification-scoreContent"/&gt;
        &lt;/element&gt;
      &lt;/zeroOrMore&gt;
    &lt;/interleave&gt;
  &lt;/define&gt;

  &lt;define name="restCommonContent"&gt;
    &lt;interleave&gt;
      &lt;optional&gt;
        &lt;element name="decision"&gt;
          &lt;ref name="decisionContent"/&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;optional&gt;
        &lt;element name="device"&gt;
          &lt;ref name="deviceContent"/&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
      &lt;optional&gt;
        &lt;element name="gender"&gt;
          &lt;ref name="genderContent"/&gt;
        &lt;/element&gt;
      &lt;/optional&gt;
     &lt;zeroOrMore&gt;
        &lt;element name="verification-score"&gt;
          &lt;ref name="verification-scoreContent"/&gt;
        &lt;/element&gt;
     &lt;/zeroOrMore&gt;
     &lt;/interleave&gt;
  &lt;/define&gt;

  &lt;define name="decisionContent"&gt;
    &lt;choice&gt;
      &lt;value&gt;accepted&lt;/value&gt;
      &lt;value&gt;rejected&lt;/value&gt;
      &lt;value&gt;undecided&lt;/value&gt;
    &lt;/choice&gt;
  &lt;/define&gt;

  &lt;define name="needmoredataContent"&gt;
    &lt;data type="boolean"/&gt;
  &lt;/define&gt;

  &lt;define name="utterance-lengthContent"&gt;
    &lt;data type="nonNegativeInteger"/&gt;
  &lt;/define&gt;

  &lt;define name="deviceContent"&gt;
    &lt;choice&gt;
      &lt;value&gt;cellular-phone&lt;/value&gt;
      &lt;value&gt;electret-phone&lt;/value&gt;
      &lt;value&gt;carbon-button-phone&lt;/value&gt;
      &lt;value&gt;unknown&lt;/value&gt;
    &lt;/choice&gt;
  &lt;/define&gt;

  &lt;define name="genderContent"&gt;
    &lt;choice&gt;
      &lt;value&gt;male&lt;/value&gt;
      &lt;value&gt;female&lt;/value&gt;
      &lt;value&gt;unknown&lt;/value&gt;
    &lt;/choice&gt;
  &lt;/define&gt;

  &lt;define name="verification-scoreContent"&gt;
    &lt;data type="float"&gt;
      &lt;param name="minInclusive"&gt;-1&lt;/param&gt;
      &lt;param name="maxInclusive"&gt;1&lt;/param&gt;
    &lt;/data&gt;
  &lt;/define&gt;

&lt;/grammar&gt;
</pre></div>
</div></section></section><references id="section-17"><h2 id="name-references"><a href="#name-references" class="section-name selfRef">References</a></h2>
<references id="section-17.1"><h3 id="name-normative-references"><a href="#name-normative-references" class="section-name selfRef">Normative References</a></h3>
<reference id="ISO.8859-1.1987"><front><span class="refTitle">Information technology - 8-bit single byte coded graphic - character sets - Part 1: Latin alphabet No. 1, JTC1/SC2</span><seriesInfo></seriesInfo><author><organization>International Organization for Standardization</organization></author><time datetime="1987">1987</time></front></reference><reference id="RFC0793"><front><span class="refTitle">Transmission Control Protocol</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization>University of Southern California (USC)/Information Sciences Institute</organization><address><postal><street>4676 Admiralty Way</street><city>Marina del Rey</city><region>CA</region><code>90291</code><country>US</country></postal></address></author><time datetime="1981-09-01">September 1, 1981</time></front></reference><reference id="RFC1035"><front><span class="refTitle">Domain names - implementation and specification</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization>USC/ISI</organization><address>
<postal><street>4676 Admiralty Way</street><city>Marina del Rey</city><region>CA</region><code>90291</code><country>US</country></postal><phone>+1 213 822 1511</phone>
</address></author><time datetime="1987-11-01">November 1, 1987</time></front></reference><reference id="RFC2119"><front><span class="refTitle">Key words for use in RFCs to Indicate Requirement Levels</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="1997-03">March 1997</time></front></reference><reference id="RFC2326"><front><span class="refTitle">Real Time Streaming Protocol (RTSP)</span><seriesInfo></seriesInfo><author><organization>Columbia University, Dept. of Computer Science</organization><address>
<postal><street>1214 Amsterdam Avenue</street><city>New York</city><region>NY</region><code>10027</code><country>US</country></postal><email>schulzrinne@cs.columbia.edu</email>
</address></author><author><organization>Netscape Communications Corp.</organization><address>
<postal><street>501 E. Middlefield Road</street><city>Mountain View</city><region>CA</region><code>94043</code><country>US</country></postal><email>anup@netscape.com</email>
</address></author><author><organization>RealNetworks</organization><address>
<postal><street>1111 Third Avenue</street><street>Suite 2900</street><city>Seattle</city><region>WA</region><code>98101</code><country>US</country></postal><email>robla@real.com</email>
</address></author><time datetime="1998-04">April 1998</time></front></reference><reference id="RFC2392"><front><span class="refTitle">Content-ID and Message-ID Uniform Resource Locators</span><seriesInfo></seriesInfo><author><organization></organization><address>
<postal><street>47 Clive Street</street><street>Metuchen</street><street>NJ  08840-1060</street><country>USA</country></postal><phone>+1 908 549 3716</phone><email>XIson@cnj.digex.net</email>
</address></author><time datetime="1998-08">August 1998</time><area>
<keyword>content-type</keyword><keyword>encapsulate</keyword><keyword>hypertext markup language</keyword><keyword>multipurpose internet mail extensions</keyword><keyword>uniform resource</keyword></front></reference><reference id="RFC2483"><front><span class="refTitle">URI Resolution Services Necessary for URN Resolution</span><seriesInfo></seriesInfo><author><organization>Network Solutions</organization><address>
<postal><street>505 Huntmar Park Drive</street><city>Herndon</city><region>VA</region><code>22070</code><country>USA</country></postal><phone>+1 703 742 0400</phone><email>michaelm@rwhois.net</email>
</address></author><author><organization>Los Alamos National Laboratory, ,Advanced Computing Lab</organization><address>
<postal><street>MS B287</street><city>Los Alamos</city><region>NM</region><code>87545</code><country>USA</country></postal><phone>+1 505 665 0597</phone><email>rdaniel@lanl.gov</email>
</address></author><time datetime="1999-01">January 1999</time><area>
<keyword>uniform resource identifier</keyword><keyword>URI</keyword></front></reference><reference id="RFC2616"><front><span class="refTitle">Hypertext Transfer Protocol -- HTTP/1.1</span><seriesInfo></seriesInfo><author><organization>Department of Information and Computer Science</organization><address>
<postal><street>University of California, Irvine</street><city>Irvine</city><region>CA</region><code>92697-3425</code></postal><email>fielding@ics.uci.edu</email>
</address></author><author><organization>World Wide Web Consortium</organization><address>
<postal><street>MIT Laboratory for Computer Science, NE43-356</street><street>545 Technology Square</street><city>Cambridge</city><region>MA</region><code>02139</code></postal><email>jg@w3.org</email>
</address></author><author><organization>Compaq Computer Corporation</organization><address>
<postal><street>Western Research Laboratory</street><street>250 University Avenue</street><city>Palo Alto</city><region>CA</region><code>94305</code></postal><email>mogul@wrl.dec.com</email>
</address></author><author><organization>World Wide Web Consortium</organization><address>
<postal><street>MIT Laboratory for Computer Science, NE43-356</street><street>545 Technology Square</street><city>Cambridge</city><region>MA</region><code>02139</code></postal><email>frystyk@w3.org</email>
</address></author><author><organization>Xerox Corporation</organization><address>
<postal><street>MIT Laboratory for Computer Science, NE43-356</street><street>3333 Coyote Hill Road</street><city>Palo Alto</city><region>CA</region><code>94034</code></postal><email>masinter@parc.xerox.com</email>
</address></author><author><organization>Microsoft Corporation</organization><address>
<postal><street>1 Microsoft Way</street><city>Redmond</city><region>WA</region><code>98052</code></postal><email>paulle@microsoft.com</email>
</address></author><author><organization>World Wide Web Consortium</organization><address>
<postal><street>MIT Laboratory for Computer Science, NE43-356</street><street>545 Technology Square</street><city>Cambridge</city><region>MA</region><code>02139</code></postal><email>timbl@w3.org</email>
</address></author><time datetime="1999-06">June 1999</time></front></reference><reference id="RFC3023"><front><span class="refTitle">XML Media Types</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2001-01">January 2001</time></front></reference><reference id="RFC3261"><front><span class="refTitle">SIP: Session Initiation Protocol</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2002-06">June 2002</time></front></reference><reference id="RFC3264"><front><span class="refTitle">An Offer/Answer Model with Session Description Protocol (SDP)</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2002-06">June 2002</time></front></reference><reference id="RFC3550"><front><span class="refTitle">RTP: A Transport Protocol for Real-Time Applications</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2003-07">July 2003</time></front></reference><reference id="RFC3629"><front><span class="refTitle">UTF-8, a transformation format of ISO 10646</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2003-11">November 2003</time></front></reference><reference id="RFC3688"><front><span class="refTitle">The IETF XML Registry</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2004-01">January 2004</time></front></reference><reference id="RFC3711"><front><span class="refTitle">The Secure Real-time Transport Protocol (SRTP)</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2004-03">March 2004</time></front></reference><reference id="RFC3986"><front><span class="refTitle">Uniform Resource Identifier (URI): Generic Syntax</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2005-01">January 2005</time></front></reference><reference id="RFC4145"><front><span class="refTitle">TCP-Based Media Transport in the Session Description Protocol (SDP)</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2005-09">September 2005</time></front></reference><reference id="RFC4288"><front><span class="refTitle">Media Type Specifications and Registration Procedures</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2005-12">December 2005</time></front></reference><reference id="RFC4566"><front><span class="refTitle">SDP: Session Description Protocol</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2006-07">July 2006</time></front></reference><reference id="RFC4568"><front><span class="refTitle">Session Description Protocol (SDP) Security Descriptions for Media Streams</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2006-07">July 2006</time></front></reference><reference id="RFC4572"><front><span class="refTitle">Connection-Oriented Media Transport over the Transport Layer Security (TLS) Protocol in the Session Description Protocol (SDP)</span><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2006-07">July 2006</time></front></reference><reference id="RFC5226"><front><span class="refTitle">Guidelines for Writing an IANA Considerations Section in RFCs</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2008-05">May 2008</time></front></reference><reference id="RFC5234"><front><span class="refTitle">Augmented BNF for Syntax Specifications: ABNF</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2008-01">January 2008</time></front></reference><reference id="RFC5246"><front><span class="refTitle">The Transport Layer Security (TLS) Protocol Version 1.2</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2008-08">August 2008</time></front></reference><reference id="RFC5322"><front><span class="refTitle">Internet Message Format</span><seriesInfo></seriesInfo><author><organization>Qualcomm Incorporated</organization><address>
<postal><street>5775 Morehouse Drive</street><city>San Diego</city><region>CA</region><code>92121-1714</code><country>US</country></postal><phone>+1 858 651 4478</phone><email>presnick@qualcomm.com</email><uri>http://www.qualcomm.com/~presnick/</uri>
</address></author><time datetime="2008-10">October 2008</time></front></reference><reference id="RFC5646"><front><span class="refTitle">Tags for Identifying Languages</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2009-09">September 2009</time></front></reference><reference id="RFC5888"><front><span class="refTitle">The Session Description Protocol (SDP) Grouping Framework</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2010-06">June 2010</time></front></reference><reference id="RFC5905"><front><span class="refTitle">Network Time Protocol Version 4: Protocol and Algorithms Specification</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2010-06">June 2010</time></front></reference><reference id="RFC5922"><front><span class="refTitle">Domain Certificates in the Session Initiation Protocol (SIP)</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2010-06">June 2010</time></front></reference><reference id="RFC6265"><front><span class="refTitle">HTTP State Management Mechanism</span><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2011-04">April 2011</time></front></reference><reference id="W3C.REC-semantic-interpretation-20070405"><front><span class="refTitle">Semantic Interpretation for Speech Recognition (SISR) Version
          1.0</span><seriesInfo></seriesInfo><author><organization>Nuance Communications</organization></author><author><organization>VoxPilot</organization></author><time datetime="2007-04-05">April 5, 2007</time></front></reference><reference id="W3C.REC-speech-grammar-20040316"><front><span class="refTitle">Speech Recognition Grammar Specification Version 1.0</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2004-03-16">March 16, 2004</time></front></reference><reference id="W3C.REC-speech-synthesis-20040907"><front><span class="refTitle">Speech Synthesis Markup Language (SSML) Version 1.0</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2004-09-07">September 7, 2004</time></front></reference><reference id="W3C.REC-xml-names11-20040204"><front><span class="refTitle">Namespaces in XML 1.1</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2004-02-04">February 4, 2004</time></front></reference></references><references id="section-17.2"><h3 id="name-informative-references"><a href="#name-informative-references" class="section-name selfRef">Informative References</a></h3>
<reference id="ISO.8601.1988"><front><span class="refTitle">Data elements and interchange formats - Information interchange - Representation of dates and times</span><seriesInfo></seriesInfo><author><organization>International Organization for Standardization</organization></author><time datetime="1988-06">June 1988</time></front></reference><reference id="Q.23"><front><span class="refTitle">Technical Features of Push-Button Telephone Sets</span><seriesInfo></seriesInfo><author><organization>International Telecommunications
            Union</organization></author><time datetime="1993">1993</time></front></reference><reference id="refs.javaSpeechGrammarFormat"><front><span class="refTitle">Java Speech Grammar Format Version 1.0</span><author><organization>Sun Microsystems</organization></author><time datetime="1998-10-26">October 26, 1998</time></front></reference><reference id="RFC2046"><front><span class="refTitle">Multipurpose Internet Mail Extensions (MIME) Part Two: Media Types</span><seriesInfo></seriesInfo><author><organization>Innosoft International, Inc.</organization><address>
<postal><street>1050 East Garvey Avenue South</street><city>West Covina</city><region>CA</region><code>91790</code><country>US</country></postal><phone>+1 818 919 3600</phone><email>ned@innosoft.com</email>
</address></author><author><organization>First Virtual Holdings</organization><address>
<postal><street>25 Washington Avenue</street><city>Morristown</city><region>NJ</region><code>07960</code><country>US</country></postal><phone>+1 201 540 8967</phone><email>nsb@nsb.fv.com</email>
</address></author><time datetime="1996-11">November 1996</time></front></reference><reference id="RFC2818"><front><span class="refTitle">HTTP Over TLS</span><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2000-05">May 2000</time></front></reference><reference id="RFC4217"><front><span class="refTitle">Securing FTP with TLS</span><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2005-10">October 2005</time></front></reference><reference id="RFC4267"><front><span class="refTitle">The W3C Speech Interface Framework Media Types: application/voicexml+xml, application/ssml+xml, application/srgs, application/srgs+xml, application/ccxml+xml, and application/pls+xml</span><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2005-11">November 2005</time></front></reference><reference id="RFC4301"><front><span class="refTitle">Security Architecture for the Internet Protocol</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2005-12">December 2005</time></front></reference><reference id="RFC4313"><front><span class="refTitle">Requirements for Distributed Control of Automatic Speech Recognition (ASR), Speaker Identification/Speaker Verification (SI/SV), and Text-to-Speech (TTS) Resources</span><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2005-12">December 2005</time></front></reference><reference id="RFC4395"><front><span class="refTitle">Guidelines and Registration Procedures for New URI Schemes</span><seriesInfo></seriesInfo><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2006-02">February 2006</time></front></reference><reference id="RFC4463"><front><span class="refTitle">A Media Resource Control Protocol (MRCP) Developed by Cisco, Nuance, and Speechworks</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2006-04">April 2006</time></front></reference><reference id="RFC4467"><front><span class="refTitle">Internet Message Access Protocol (IMAP) - URLAUTH Extension</span><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2006-05">May 2006</time></front></reference><reference id="RFC4733"><front><span class="refTitle">RTP Payload for DTMF Digits, Telephony Tones, and Telephony Signals</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><time datetime="2006-12">December 2006</time></front></reference><reference id="RFC4960"><front><span class="refTitle">Stream Control Transmission Protocol</span><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2007-09">September 2007</time></front></reference><reference id="RFC6454"><front><span class="refTitle">The Web Origin Concept</span><seriesInfo></seriesInfo><author><organization></organization></author><time datetime="2011-12">December 2011</time></front></reference><reference id="W3C.REC-emma-20090210"><front><span class="refTitle">EMMA: Extensible MultiModal Annotation markup
          language</span><seriesInfo></seriesInfo><author><organization>AT&amp;T</organization></author><author><organization>Loquendo</organization></author><author><organization>Nuance</organization></author><author><organization>Nuance</organization></author><author><organization>Invited Expert</organization></author><author><organization>IBM</organization></author><author><organization>W3C</organization></author><time datetime="2009-02-10">February 10, 2009</time></front></reference><reference id="W3C.REC-pronunciation-lexicon-20081014"><front><span class="refTitle">Pronunciation Lexicon Specification (PLS)</span><seriesInfo></seriesInfo><author><organization>Loquendo</organization></author><author><organization>France Telecom</organization></author><author><organization>Voxeo</organization></author><author><organization>Nuance</organization></author><author><organization>BT</organization></author><time datetime="2008-10-14">October 14, 2008</time></front></reference><reference id="W3C.REC-voicexml20-20040316"><front><span class="refTitle">Voice Extensible Markup Language (VoiceXML) Version 2.0</span><seriesInfo></seriesInfo><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><author><organization></organization></author><time datetime="2004-03-16">March 16, 2004</time></front></reference></references></references><section id="section-appendix.a"><h2 id="name-contributors">
<a href="#section-appendix.a" class="section-number selfRef">appendix.a.Â </a><a href="#name-contributors" class="section-name selfRef">Contributors</a>
</h2>
<div id="section-appendix.a-1" class="artwork art-text" text-align="left"><pre>
Pierre Forgues 
Nuance Communications Ltd. 
1500 University Street
Suite 935
Montreal, Quebec 
Canada H3A 3S7 
         
EMail:  forgues@nuance.com 


Charles Galles 
Intervoice, Inc. 
17811 Waterview Parkway 
Dallas, Texas 75252 
USA        
 
EMail:  charles.galles@intervoice.com 


Klaus Reifenrath
Scansoft, Inc
Guldensporenpark 32
Building D
9820 Merelbeke
Belgium

EMail: klaus.reifenrath@scansoft.com 
                </pre></div></section><section id="section-appendix.b"><h2 id="name-acknowledgements">
<a href="#section-appendix.b" class="section-number selfRef">appendix.b.Â </a><a href="#name-acknowledgements" class="section-name selfRef">Acknowledgements</a>
</h2>
<div id="section-appendix.b-1" class="artwork art-text" text-align="left"><pre>
Andre Gillet (Nuance Communications)
Andrew Hunt (ScanSoft)
Andrew Wahbe (Genesys)
Aaron Kneiss (ScanSoft)
Brian Eberman (ScanSoft)
Corey Stohs (Cisco Systems, Inc.)
Dave Burke (VoxPilot)
Jeff Kusnitz (IBM Corp)
Ganesh N. Ramaswamy (IBM Corp)
Klaus Reifenrath (ScanSoft)
Kristian Finlator (ScanSoft)
Magnus Westerlund (Ericsson)
Martin Dragomirecky (Cisco Systems, Inc.)
Paolo Baggia (Loquendo)
Peter Monaco (Nuance Communications)
Pierre Forgues (Nuance Communications)
Ran Zilca (IBM Corp)
Suresh Kaliannan (Cisco Systems, Inc.)
Skip Cave (Intervoice, Inc.)
Thomas Gal (LumenVox)
         </pre></div>
<p id="section-appendix.b-2">The chairs of the SPEECHSC work group are Eric Burger (Georgetown
      University) and Dave Oran (Cisco Systems, Inc.).</p>
<p id="section-appendix.b-3">Many thanks go in particular to Robert Sparks, Alex Agranovsky, and
      Henry Phan, who were there at the end to dot all the i's and cross all
      the t's.</p></section><section id="section-appendix.c"><div id="authors-addresses">
<h2 id="name-authors-addresses"><a href="#name-authors-addresses" class="section-name selfRef">Authors' Addresses</a></h2>
<author><organization>Voxeo</organization><address>
<postal><street>189 South Orange Avenue #1000</street><city>Orlando</city><region>FL</region><code>32801</code><country>USA</country></postal><email>dburnett@voxeo.com</email>
</address></author><author><organization>Cisco Systems, Inc.</organization><address>
<postal><street>170 W. Tasman Dr.</street><city>San Jose</city><region>CA</region><code>95134</code><country>USA</country></postal><email>sarvi@cisco.com</email>
</address></author>
</div></section><script type="text/javascript">var toc = document.getElementById("toc");
var tocToggle = toc.querySelector("h2");
var tocNav = toc.querySelector("nav");

// mobile menu toggle
tocToggle.onclick = function(event) {
    if (window.innerWidth < 1024) {
 var tocNavDisplay = tocNav.currentStyle ? tocNav.currentStyle.display : getComputedStyle(tocNav, null).display;
 if (tocNavDisplay == "none") {
     tocNav.style.display = "block";
 } else {
     tocNav.style.display = "none";
 }
    }
}

// toc anchor scroll to anchor
tocNav.addEventListener("click", function (event) {
    event.preventDefault();
    if (event.target.nodeName == 'A') {
 if (window.innerWidth < 1024) {
     tocNav.style.display = "none";
 }
 var href = event.target.getAttribute("href");
 var anchorId = href.substr(1);
 var anchor =  document.getElementById(anchorId);
 anchor.scrollIntoView(true);
 window.history.pushState("","",href);
    }
});

// switch toc mode when window resized
window.onresize = function () {
    if (window.innerWidth < 1024) {
 tocNav.style.display = "none";
    } else {
 tocNav.style.display = "block";
    }
}
</script>
</body>
</html>
